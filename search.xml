<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】</title>
      <link href="/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/"/>
      <url>/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】"><a href="#昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】" class="headerlink" title="昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】"></a>昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】</h1><p>本项目是”昇腾AI创新算子挑战赛（S4赛季）【基础性能命题】”的开源代码。</p><h2 id="赛题列表"><a href="#赛题列表" class="headerlink" title="赛题列表"></a>赛题列表</h2><p>以下是本次挑战赛的五个赛题：</p><ul><li>[ ] Reshape</li><li>[ ] RmsNorm</li><li>[x] SelectV2</li><li>[x] Pows</li><li>[ ] Gather</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>针对已完成的算子，后续的优化方向包括：</p><ul><li><strong>SelectV2 &amp; Pows</strong>:<ul><li>细分广播与非广播场景的实现，进行针对性优化。</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li></ul><hr><h2 id="Pows算子实现详解"><a href="#Pows算子实现详解" class="headerlink" title="Pows算子实现详解"></a>Pows算子实现详解</h2><h3 id="算子概述"><a href="#算子概述" class="headerlink" title="算子概述"></a>算子概述</h3><p>Pows算子实现了幂运算功能，即计算<code>y = x1^x2</code>，其中x1为底数，x2为指数。该算子需支持广播机制，能够处理不同形状的输入张量。</p><p>算法实现原理：<code>pow(x1, x2) = exp(x2 * ln(x1))</code></p><h3 id="kernel侧实现"><a href="#kernel侧实现" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h3><ol><li>完成pow.cpp文件,这里是算子的入口</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 引入必要的头文件</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span>  <span class="comment">// AscendC核心算子开发框架</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pow.h&quot;</span>              <span class="comment">// 非广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;powb.h&quot;</span>             <span class="comment">// 广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 算子入口函数，使用extern &quot;C&quot;确保C++函数能被C代码调用</span></span><br><span class="line"><span class="comment">// __global__表示这是一个设备端函数，__aicore__表示运行在AI Core上</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">pows</span><span class="params">(GM_ADDR x1,GM_ADDR x2, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR y, GM_ADDR workspace, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;  <span class="comment">// 这里有个细节，建议在最开始就定义好pipe对象，然后通过传参数</span></span><br><span class="line">                 <span class="comment">//  再进到Init中，有一定性能优化</span></span><br><span class="line">    <span class="comment">// 根据tiling key选择不同的实现策略</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">1</span>))&#123; <span class="comment">// tiling key为1：非广播场景</span></span><br><span class="line">        KernelPows op;  <span class="comment">// 创建非广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">2</span>))&#123; <span class="comment">// tiling key为2：广播场景</span></span><br><span class="line">        KernelPowsBroadCast op;  <span class="comment">// 创建广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 以下是针对不同数据类型的扩展实现（当前注释掉）</span></span><br><span class="line">    <span class="comment">// 可以根据需要细分fp16和fp32的非广播和广播实现</span></span><br><span class="line">    <span class="comment">// if(TILING_KEY_IS(1))&#123; // fp16非广播</span></span><br><span class="line">    <span class="comment">//     KernelPows op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(2))&#123; // fp32非广播</span></span><br><span class="line">    <span class="comment">//      op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(3))&#123; // fp16广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastB op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(4))&#123; // fp32广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastBB op;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>非广播场景实现 (pow.h)</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;  <span class="comment">// 双缓冲机制，提高数据传输效率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非广播场景的Pows算子实现类（tiling key 1）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPows</span>&#123; </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPows</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化tiling参数，从host侧传递的tiling数据中获取分块信息</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);  <span class="comment">// 获取tiling数据结构</span></span><br><span class="line">            totalLength = tiling_data.totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;    <span class="comment">// 每个tile的长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;      <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;          <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化算子，设置全局内存地址和缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);  <span class="comment">// 初始化tiling参数</span></span><br><span class="line">    </span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);  <span class="comment">// 确保block数量不为0</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，将GM地址转换为GlobalTensor</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;  <span class="comment">// 保存pipe指针</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化输入输出队列，使用双缓冲提高效率</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX1, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX2, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 对于half类型，把half转成float，要不然精度不够</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 主处理函数，按tile进行循环处理</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 处理完整的tile</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(i,  <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将数据从GM拷贝到UB</span></span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 在UB中进行计算</span></span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将结果从UB拷回GM</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余的不足一个tile的数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 数据输入函数：从全局内存拷贝数据到本地缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 分配本地tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 从全局内存拷贝数据到本地tensor</span></span><br><span class="line">            <span class="built_in">DataCopy</span>(x1Local, x1Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            <span class="built_in">DataCopy</span>(x2Local, x2Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将tensor加入队列</span></span><br><span class="line">            inQueueX<span class="number">1.</span><span class="built_in">EnQue</span>(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.</span><span class="built_in">EnQue</span>(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算函数：执行幂运算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 从队列中取出输入tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">DeQue</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">DeQue</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型选择不同的计算方法</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length);  <span class="comment">// float类型直接计算</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);     <span class="comment">// 半精度类型需要类型转换</span></span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 释放输入tensor</span></span><br><span class="line">            inQueueX<span class="number">1.F</span>reeTensor(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.F</span>reeTensor(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现：pow(x1, x2) = exp(x2 * ln(x1))</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// 计算ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// 计算x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// 计算exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现：需要先转换为float进行计算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时float缓冲区</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将半精度数据转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 在float精度下进行幂运算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将结果转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 数据输出函数：将计算结果从本地缓冲区拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 队列和缓冲区定义</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX1;   <span class="comment">// 输入x1队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX2;   <span class="comment">// 输入x2队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;  <span class="comment">// 输出y队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时缓冲区（用于半精度计算）</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 管道和参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;   <span class="comment">// 每个tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;    <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;      <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>广播场景实现 (powb.h)<br>广播场景的实现更加复杂，需要处理不同形状的输入张量。主要特点：</li></ol><ul><li>支持多维张量的广播机制</li><li>动态计算每个输出元素对应的输入元素索引</li><li>逐元素计算，适用于形状不匹配的情况</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 广播场景的Pows算子实现类（tiling key 2）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPowsBroadCast</span>&#123;  </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPowsBroadCast</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播相关的tiling参数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling); </span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输出张量的维度信息</span></span><br><span class="line">            y_dimensional = tiling_data.y_dimensional;  <span class="comment">// 输出张量维度数</span></span><br><span class="line">            y_ndarray = tiling_data.y_ndarray;          <span class="comment">// 输出张量各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输入张量的维度信息</span></span><br><span class="line">            x1_ndarray = tiling_data.x1_ndarray;        <span class="comment">// 输入x1各维度大小</span></span><br><span class="line">            x2_ndarray = tiling_data.x2_ndarray;        <span class="comment">// 输入x2各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 累积维度信息，用于索引计算</span></span><br><span class="line">            y_sumndarray = tiling_data.y_sumndarray;    <span class="comment">// 输出张量累积维度</span></span><br><span class="line">            x1_sumndarray = tiling_data.x1_sumndarray;  <span class="comment">// 输入x1累积维度</span></span><br><span class="line">            x2_sumndarray = tiling_data.x2_sumndarray;  <span class="comment">// 输入x2累积维度</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 张量长度信息</span></span><br><span class="line">            x1TotalLength = tiling_data.x1TotalLength;  <span class="comment">// x1总长度</span></span><br><span class="line">            x2TotalLength = tiling_data.x2TotalLength;  <span class="comment">// x2总长度</span></span><br><span class="line">            x1Size = tiling_data.x1Size;                <span class="comment">// x1大小</span></span><br><span class="line">            x2Size = tiling_data.x2Size;                <span class="comment">// x2大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 分块信息</span></span><br><span class="line">            totalLength = tiling_data.totalLength;      <span class="comment">// 输出总长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;        <span class="comment">// 每个tile长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;          <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;              <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播算子</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，注意x1和x2的长度可能不同</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1, x1TotalLength);  </span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X2*)x2, x2TotalLength); </span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y, totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化临时缓冲区（广播场景不使用队列，而是直接使用缓冲区）</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 半精度类型需要额外的float缓冲区</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 广播场景的主处理函数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时缓冲区用于存储广播后的数据</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = tmpBufferX<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = tmpBufferX<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 按tile处理数据</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;                   </span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength,x1Local,x2Local);           </span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum,x1Local,x2Local);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 广播场景的计算函数：逐元素计算广播索引</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length,LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local)</span> </span>&#123; </span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 逐元素处理，计算每个输出元素对应的输入元素索引</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">uint32_t</span> j = <span class="number">0</span>;j &lt; length;j ++)&#123;</span><br><span class="line">                <span class="type">uint32_t</span> x1_start = <span class="number">0</span>;  <span class="comment">// x1的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> x2_start = <span class="number">0</span>;  <span class="comment">// x2的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> index = j + progress * <span class="keyword">this</span>-&gt;tileLength;  <span class="comment">// 当前输出元素的全局索引</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 根据广播规则计算输入索引</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">uint32_t</span> k = <span class="number">0</span>; k &lt; <span class="keyword">this</span>-&gt;y_dimensional; k++)&#123;</span><br><span class="line">                    <span class="comment">// 如果x1在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;x1_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x1_start += <span class="keyword">this</span>-&gt;x1_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 如果x2在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span>(<span class="keyword">this</span>-&gt;x2_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x2_start += <span class="keyword">this</span>-&gt;x2_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);  </span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 从全局内存获取对应位置的值</span></span><br><span class="line">                <span class="keyword">auto</span> x1 = x1Gm.<span class="built_in">GetValue</span>(x1_start); </span><br><span class="line">                <span class="keyword">auto</span> x2 = x2Gm.<span class="built_in">GetValue</span>(x2_start);</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 将值设置到本地tensor中</span></span><br><span class="line">                x1Local.<span class="built_in">SetValue</span>(j,x1);</span><br><span class="line">                x2Local.<span class="built_in">SetValue</span>(j,x2);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型执行计算</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length); </span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// float精度计算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出函数：将结果拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 输出队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时计算缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX1;  <span class="comment">// x1临时缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX2;  <span class="comment">// x2临时缓冲区</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 管道和基本参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;   <span class="comment">// 输出总长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;    <span class="comment">// tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;     <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;       <span class="comment">// 剩余长度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 广播相关参数</span></span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional;     <span class="comment">// 输出维度数</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_sumndarray;    <span class="comment">// x1累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_sumndarray;    <span class="comment">// x2累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_ndarray;        <span class="comment">// 输出各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_ndarray;       <span class="comment">// x1各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_ndarray;       <span class="comment">// x2各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_sumndarray;     <span class="comment">// 输出累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> x1TotalLength;     <span class="comment">// x1总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x2TotalLength;     <span class="comment">// x2总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x1Size;            <span class="comment">// x1大小</span></span><br><span class="line">        <span class="type">uint32_t</span> x2Size;            <span class="comment">// x2大小</span></span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><h3 id="host侧实现"><a href="#host侧实现" class="headerlink" title="host侧实现"></a>host侧实现</h3><p>host侧主要负责算子的注册、形状推理、tiling策略计算等功能。包含以下几个关键部分：</p><ol><li><p>Tiling数据结构定义 (pows_tiling.h)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">// 定义Pows算子的tiling数据结构</span></span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(PowsTilingData)</span><br><span class="line">  <span class="comment">// 基础分块参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);    <span class="comment">// 总数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);      <span class="comment">// 循环次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);        <span class="comment">// 剩余数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);     <span class="comment">// 每个tile的长度</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 广播相关参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, y_dimensional);  <span class="comment">// 输出张量维度数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1TotalLength);  <span class="comment">// x1总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2TotalLength);  <span class="comment">// x2总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1Size);         <span class="comment">// x1大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2Size);         <span class="comment">// x2大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 维度数组（最大支持20维）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_ndarray);   <span class="comment">// 输出各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_ndarray);  <span class="comment">// x1各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_ndarray);  <span class="comment">// x2各维度大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 累积维度数组（用于索引计算）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_sumndarray);  <span class="comment">// 输出累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_sumndarray); <span class="comment">// x1累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_sumndarray); <span class="comment">// x2累积维度</span></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册tiling数据类</span></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(Pows, PowsTilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Tiling策略计算 (pows_tiling.cpp)</p></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pows_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向上32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32U</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>) / DataType;  <span class="comment">// 向上对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向下32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">31</span>) / DataType;      <span class="comment">// 向下对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="type">const</span> <span class="type">uint32_t</span> BLOCK_SIZE = <span class="number">32</span>;      <span class="comment">// 块大小常量</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;    <span class="comment">// 双缓冲数量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PowsTilingData tiling;  <span class="comment">// 创建tiling数据结构</span></span><br><span class="line">    <span class="type">uint64_t</span> sizeofdatatype;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取平台信息</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> socVersion = ascendcPlatform.<span class="built_in">GetSocVersion</span>();  <span class="comment">// 获取SoC版本</span></span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);  <span class="comment">// 获取UB大小</span></span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNum</span>();  <span class="comment">// 获取核心数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入数据信息</span></span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// 数据总长度</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();  <span class="comment">// 获取数据类型</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 根据数据类型确定字节大小</span></span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;  <span class="comment">// 半精度类型占2字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;  <span class="comment">// 单精度类型占4字节</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="type">uint32_t</span> x2Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="keyword">if</span> (x1Size != x2Size)&#123;  <span class="comment">// 长度不一就广播，广播部分采用论坛中的广播样例</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(3);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(4);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 定义维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> y_ndarray[<span class="number">20</span>], x1_ndarray[<span class="number">20</span>], x2_ndarray[<span class="number">20</span>];</span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional, x1_dimensional, x2_dimensional;</span><br><span class="line">        <span class="comment">// 获取张量形状信息</span></span><br><span class="line">        <span class="keyword">auto</span> shape_y  = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x1 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x2 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="comment">// 获取各张量的维度数</span></span><br><span class="line">        y_dimensional  = shape_y.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        x1_dimensional = shape_x<span class="number">1.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        x2_dimensional = shape_x<span class="number">2.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> max_dimensional = y_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x1_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x1_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x2_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x2_dimensional;</span><br><span class="line">        <span class="comment">// 初始化维度数组，处理维度对齐</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; max_dimensional; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; y_dimensional) &#123;</span><br><span class="line">                y_ndarray[y_dimensional - i - <span class="number">1</span>] = shape_y.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                y_ndarray[i] = <span class="number">1</span>; <span class="comment">// 不足的维度补1</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x1_dimensional) &#123;</span><br><span class="line">                x1_ndarray[x1_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">1.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x1_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x2_dimensional) &#123;</span><br><span class="line">                x2_ndarray[x2_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">2.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x2_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_dimensional</span>(max_dimensional);</span><br><span class="line">        tiling.<span class="built_in">set_y_ndarray</span>(y_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_ndarray</span>(x1_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_ndarray</span>(x2_ndarray);</span><br><span class="line">        <span class="comment">// 计算累积维度数组（用于索引计算）</span></span><br><span class="line">        <span class="type">uint32_t</span> y_sumndarray[<span class="number">20</span>], x1_sumndarray[<span class="number">20</span>], x2_sumndarray[<span class="number">20</span>];</span><br><span class="line">        y_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x1_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x2_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">1</span>; i &lt;= max_dimensional; i++)&#123;</span><br><span class="line">            y_sumndarray[i]   = y_sumndarray[i - <span class="number">1</span>]   * y_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x1_sumndarray[i]  = x1_sumndarray[i - <span class="number">1</span>]  * x1_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x2_sumndarray[i]  = x2_sumndarray[i - <span class="number">1</span>]  * x2_ndarray[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_sumndarray</span>(y_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_sumndarray</span>(x1_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_sumndarray</span>(x2_sumndarray);</span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(y_sumndarray[max_dimensional],sizeofdatatype); </span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_x1TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x2TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x1Size</span>(x1Size);</span><br><span class="line">        tiling.<span class="built_in">set_x2Size</span>(x2Size);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength);</span><br><span class="line">        <span class="comment">// 这里比较关键，这个24是通过实际需要使用多少块空间来计算的</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     </span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;y_dimensional: %d\n&quot;, max_dimensional);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1Size: %d\n&quot;, x1Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2Size: %d\n&quot;, x2Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123; <span class="comment">// 非广播场景</span></span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(totalLength,sizeofdatatype);</span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(1);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(2);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 这里恰好half的分块数与float一致，感兴趣的可以自己算一下试试看</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     <span class="comment">//向下32对齐的最大长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// Gm总地址32B对齐</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);  </span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);     </span><br><span class="line">    *y_shape = *x1_shape;  </span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pows</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Pows</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="comment">// 定义第一个输入x1（底数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)  <span class="comment">// 支持的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)  <span class="comment">// 支持的数据格式</span></span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);  </span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义第二个输入x2（指数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义输出y</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置形状推理函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置AI Core实现</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);  <span class="comment">// 设置tiling函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>);  <span class="comment">// 添加支持的硬件配置</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(Pows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报2.0</title>
      <link href="/2025/06/07/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A52.0/"/>
      <url>/2025/06/07/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A52.0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-项目背景"><a href="#1-项目背景" class="headerlink" title="1. 项目背景"></a>1. 项目背景</h1><ul><li><strong>任务</strong>：利用强化学习提升基于多通道的睡眠阶段数据分类模型的性能遇到瓶颈  </li><li><strong>睡眠阶段</strong>：W, N1, N2, N3, REM  </li><li><strong>挑战</strong>：  <ul><li>大部份预测错误都出现在W-&gt;N1,N1-&gt;N2转换的时候</li><li>模型很容易将N1误判成W或者N2</li><li>强化学习奖励不及预期</li></ul></li></ul><h1 id="2-数据集概况"><a href="#2-数据集概况" class="headerlink" title="2. 数据集概况"></a>2. 数据集概况</h1><h2 id="2-1-数据规模"><a href="#2-1-数据规模" class="headerlink" title="2.1 数据规模"></a>2.1 数据规模</h2><ul><li><strong>总样本数</strong>：8,549个睡眠epoch</li><li><strong>受试者数量</strong>：10人（采用10-fold交叉验证）</li><li><strong>数据分布</strong>：每个fold包含790-966个样本不等</li><li><strong>全局变化率</strong>：19.08%（睡眠阶段转换频率）</li></ul><h2 id="2-2-睡眠阶段分布分析"><a href="#2-2-睡眠阶段分布分析" class="headerlink" title="2.2 睡眠阶段分布分析"></a>2.2 睡眠阶段分布分析</h2><h3 id="全局阶段分布"><a href="#全局阶段分布" class="headerlink" title="全局阶段分布"></a>全局阶段分布</h3><p>基于8,549个样本的统计分析：</p><div class="table-container"><table><thead><tr><th>睡眠阶段</th><th>样本数</th><th>占比</th><th>特征描述</th></tr></thead><tbody><tr><td>W (清醒)</td><td>1,651</td><td>19.3%</td><td>清醒状态，通常出现在睡眠开始和结束</td></tr><tr><td>N1 (浅睡)</td><td>1,215</td><td>14.2%</td><td>入睡过渡期，持续时间短</td></tr><tr><td>N2 (轻睡)</td><td>2,609</td><td>30.5%</td><td><strong>主要睡眠阶段</strong>，占比最高</td></tr><tr><td>N3 (深睡)</td><td>2,014</td><td>23.6%</td><td>深度睡眠，恢复性睡眠</td></tr><tr><td>REM (快眼动)</td><td>1,060</td><td>12.4%</td><td>做梦阶段，认知功能重要</td></tr></tbody></table></div><p><strong>关键发现</strong>：</p><ul><li>N2阶段占主导地位（30.5%），符合正常睡眠结构</li><li>N1阶段占比相对较低（14.2%），这解释了为什么N1容易被误分类</li><li>各阶段分布符合健康成人睡眠模式</li></ul><h2 id="2-3-睡眠阶段转换模式分析"><a href="#2-3-睡眠阶段转换模式分析" class="headerlink" title="2.3 睡眠阶段转换模式分析"></a>2.3 睡眠阶段转换模式分析</h2><h3 id="转换矩阵统计"><a href="#转换矩阵统计" class="headerlink" title="转换矩阵统计"></a>转换矩阵统计</h3><p>基于全局转换概率矩阵的关键发现：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>77.7%</td><td>18.4%</td><td>3.3%</td><td>0.2%</td><td>0.2%</td></tr><tr><td><strong>N1</strong></td><td>12.6%</td><td>53.5%</td><td>25.8%</td><td>0.1%</td><td>8.1%</td></tr><tr><td><strong>N2</strong></td><td>5.0%</td><td>6.4%</td><td><strong>83.0%</strong></td><td>4.2%</td><td>1.4%</td></tr><tr><td><strong>N3</strong></td><td>1.6%</td><td>0.3%</td><td>3.4%</td><td><strong>94.4%</strong></td><td>0.2%</td></tr><tr><td><strong>REM</strong></td><td>4.0%</td><td>8.5%</td><td>0.9%</td><td>0.0%</td><td><strong>86.7%</strong></td></tr></tbody></table></div><p><strong>转换模式特征</strong>：</p><ol><li><strong>高稳定性阶段</strong>：N3（94.4%）和REM（86.7%）具有很高的自转换概率</li><li><strong>过渡性阶段</strong>：N1的自转换概率较低（53.5%），容易向其他阶段转换</li><li><strong>问题转换</strong>：<ul><li>W→N1：18.4%的转换概率</li><li>N1→N2：25.8%的转换概率</li><li>N1→W：12.6%的反向转换</li></ul></li></ol><h3 id="最频繁转换统计"><a href="#最频繁转换统计" class="headerlink" title="最频繁转换统计"></a>最频繁转换统计</h3><ul><li><strong>N2→N2</strong>：2,163次（最稳定的睡眠阶段）</li><li><strong>N3→N3</strong>：1,899次（深睡眠的连续性）</li><li><strong>REM→REM</strong>：917次（快眼动期的持续性）</li><li><strong>W→W</strong>：1,282次（清醒状态的维持）</li></ul><h2 id="2-4-睡眠阶段持续时间分析"><a href="#2-4-睡眠阶段持续时间分析" class="headerlink" title="2.4 睡眠阶段持续时间分析"></a>2.4 睡眠阶段持续时间分析</h2><h3 id="各阶段持续时间统计（单位：epoch）"><a href="#各阶段持续时间统计（单位：epoch）" class="headerlink" title="各阶段持续时间统计（单位：epoch）"></a>各阶段持续时间统计（单位：epoch）</h3><div class="table-container"><table><thead><tr><th>阶段</th><th>平均值</th><th>标准差</th><th>中位数</th><th>最小值</th><th>最大值</th><th>四分位距</th></tr></thead><tbody><tr><td>W</td><td>4.47</td><td>10.60</td><td>1.0</td><td>1</td><td>145</td><td>1.0-3.0</td></tr><tr><td>N1</td><td>2.15</td><td>1.83</td><td>1.0</td><td>1</td><td>18</td><td>1.0-3.0</td></tr><tr><td>N2</td><td>5.85</td><td>7.08</td><td>3.0</td><td>1</td><td>51</td><td>1.0-7.0</td></tr><tr><td>N3</td><td>17.51</td><td>22.17</td><td>7.0</td><td>1</td><td>96</td><td>2.0-22.0</td></tr><tr><td>REM</td><td>7.41</td><td>10.15</td><td>4.0</td><td>1</td><td>66</td><td>2.0-8.0</td></tr></tbody></table></div><p><strong>持续时间特征</strong>：</p><ol><li><strong>N3阶段持续时间最长</strong>：平均17.5个epoch，体现深睡眠的连续性</li><li><strong>N1阶段持续时间最短</strong>：平均2.15个epoch，证实其过渡性质</li><li><strong>高变异性</strong>：所有阶段都显示较大的标准差，表明个体差异显著</li><li><strong>极值分析</strong>：W阶段最大持续145个epoch，可能对应长时间清醒期</li></ol><h2 id="2-5-个体差异分析"><a href="#2-5-个体差异分析" class="headerlink" title="2.5 个体差异分析"></a>2.5 个体差异分析</h2><h3 id="跨受试者变异性"><a href="#跨受试者变异性" class="headerlink" title="跨受试者变异性"></a>跨受试者变异性</h3><p>通过10-fold数据分析发现显著的个体差异：</p><p><strong>阶段分布差异示例</strong>：</p><ul><li>Fold 4：W占比高达32.9%（可能的睡眠障碍个体）</li><li>Fold 5：W占比仅6.7%（良好睡眠质量个体）</li><li>Fold 7：W占比38.6%（另一个高清醒比例个体）</li></ul><p><strong>变化率差异</strong>：</p><ul><li>最低变化率：11.5%（Fold 7）</li><li>最高变化率：20.4%（Fold 2）</li><li>平均变化率：19.08%</li></ul><h2 id="2-6-数据预处理挑战与策略"><a href="#2-6-数据预处理挑战与策略" class="headerlink" title="2.6 数据预处理挑战与策略"></a>2.6 数据预处理挑战与策略</h2><h3 id="主要挑战"><a href="#主要挑战" class="headerlink" title="主要挑战"></a>主要挑战</h3><ol><li><p><strong>类别不平衡</strong>：</p><ul><li>N2阶段样本过多（30.5%）</li><li>N1阶段样本相对较少（14.2%）</li><li>需要采用平衡策略</li></ul></li><li><p><strong>边界模糊性</strong>：</p><ul><li>W↔N1转换：31.0%的双向转换概率</li><li>N1↔N2转换：32.2%的双向转换概率</li><li>这些转换是分类错误的主要来源</li></ul></li><li><p><strong>个体差异</strong>：</p><ul><li>睡眠模式个体差异显著</li><li>需要个性化的特征提取策略</li></ul></li></ol><h3 id="预处理策略"><a href="#预处理策略" class="headerlink" title="预处理策略"></a>预处理策略</h3><ol><li><p><strong>数据增强</strong>：</p><ul><li>针对N1阶段进行过采样</li><li>使用SMOTE等技术平衡类别分布</li></ul></li><li><p><strong>特征工程</strong>：</p><ul><li>提取转换上下文特征</li><li>计算阶段持续时间特征</li><li>引入时序依赖性特征</li></ul></li><li><p><strong>标注质量控制</strong>：</p><ul><li>重点关注W-N1-N2边界区域</li><li>建立专家一致性检查机制</li></ul></li></ol><h2 id="2-7-对强化学习模型的启示"><a href="#2-7-对强化学习模型的启示" class="headerlink" title="2.7 对强化学习模型的启示"></a>2.7 对强化学习模型的启示</h2><p>基于数据分析结果，为强化学习模型设计提供以下指导：</p><ol><li><p><strong>奖励函数设计</strong>：</p><ul><li>对N1正确分类给予更高奖励</li><li>对W↔N1、N1↔N2错误转换给予更大惩罚</li></ul></li><li><p><strong>状态空间设计</strong>：</p><ul><li>包含前序睡眠阶段信息</li><li>考虑阶段持续时间特征</li><li>引入个体差异参数</li></ul></li><li><p><strong>动作空间优化</strong>：</p><ul><li>设计渐进式分类策略</li><li>优先处理高置信度分类</li><li>对边界案例采用保守策略</li></ul></li></ol><h1 id="3-详细数据分析"><a href="#3-详细数据分析" class="headerlink" title="3. 详细数据分析"></a>3. 详细数据分析</h1><h2 id="3-1-个体转移概率矩阵分析"><a href="#3-1-个体转移概率矩阵分析" class="headerlink" title="3.1 个体转移概率矩阵分析"></a>3.1 个体转移概率矩阵分析</h2><p>基于10个受试者的睡眠数据，以下是每个个体的详细转移概率矩阵分析，重点关注问题转换区域：</p><h3 id="受试者1-Fold-0-样本数：920"><a href="#受试者1-Fold-0-样本数：920" class="headerlink" title="受试者1 (Fold 0) - 样本数：920"></a>受试者1 (Fold 0) - 样本数：920</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>74.4%</td><td>24.4%</td><td>1.3%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>13.2%</td><td>51.8%</td><td>28.9%</td><td>0.0%</td><td>6.1%</td></tr><tr><td><strong>N2</strong></td><td>4.1%</td><td>2.5%</td><td><strong>88.8%</strong></td><td>3.6%</td><td>1.1%</td></tr><tr><td><strong>N3</strong></td><td>3.4%</td><td>0.0%</td><td>3.9%</td><td><strong>92.7%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.0%</td><td>6.9%</td><td>0.0%</td><td>0.0%</td><td><strong>89.1%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换率24.4%（高于平均）</li><li>N1自维持率51.8%（低于平均）</li><li>N2稳定性88.8%（高于平均）</li></ul><h3 id="受试者2-Fold-1-样本数：907"><a href="#受试者2-Fold-1-样本数：907" class="headerlink" title="受试者2 (Fold 1) - 样本数：907"></a>受试者2 (Fold 1) - 样本数：907</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>70.4%</td><td>24.5%</td><td>5.1%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>8.5%</td><td>53.2%</td><td>24.8%</td><td>0.0%</td><td>13.5%</td></tr><tr><td><strong>N2</strong></td><td>3.4%</td><td>6.5%</td><td><strong>84.5%</strong></td><td>3.7%</td><td>1.9%</td></tr><tr><td><strong>N3</strong></td><td>1.0%</td><td>0.0%</td><td>4.6%</td><td><strong>93.9%</strong></td><td>0.5%</td></tr><tr><td><strong>REM</strong></td><td>2.0%</td><td>14.3%</td><td>0.7%</td><td>0.0%</td><td><strong>83.0%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N2直接转换5.1%（异常高）</li><li>N1→REM转换13.5%（显著高于平均）</li><li>REM→N1转换14.3%（异常高）</li></ul><h3 id="受试者3-Fold-2-样本数：790"><a href="#受试者3-Fold-2-样本数：790" class="headerlink" title="受试者3 (Fold 2) - 样本数：790"></a>受试者3 (Fold 2) - 样本数：790</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>51.3%</td><td>23.1%</td><td>21.8%</td><td>2.6%</td><td>1.3%</td></tr><tr><td><strong>N1</strong></td><td>10.9%</td><td>43.8%</td><td>35.9%</td><td>0.0%</td><td>9.4%</td></tr><tr><td><strong>N2</strong></td><td>8.0%</td><td>4.8%</td><td><strong>81.1%</strong></td><td>3.6%</td><td>2.4%</td></tr><tr><td><strong>N3</strong></td><td>1.7%</td><td>0.0%</td><td>1.7%</td><td><strong>96.6%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.9%</td><td>5.8%</td><td>1.9%</td><td>0.0%</td><td><strong>87.4%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W自维持率仅51.3%（最低）</li><li>W→N2转换21.8%（异常高）</li><li>N1→N2转换35.9%（最高）</li><li>该个体睡眠转换最不稳定</li></ul><h3 id="受试者4-Fold-3-样本数：760"><a href="#受试者4-Fold-3-样本数：760" class="headerlink" title="受试者4 (Fold 3) - 样本数：760"></a>受试者4 (Fold 3) - 样本数：760</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>83.5%</td><td>15.1%</td><td>0.7%</td><td>0.0%</td><td>0.7%</td></tr><tr><td><strong>N1</strong></td><td>7.3%</td><td>53.3%</td><td>27.7%</td><td>0.7%</td><td>10.9%</td></tr><tr><td><strong>N2</strong></td><td>2.6%</td><td>11.1%</td><td><strong>80.3%</strong></td><td>5.1%</td><td>0.9%</td></tr><tr><td><strong>N3</strong></td><td>1.3%</td><td>1.9%</td><td>4.4%</td><td><strong>91.8%</strong></td><td>0.6%</td></tr><tr><td><strong>REM</strong></td><td>5.6%</td><td>15.6%</td><td>0.0%</td><td>0.0%</td><td><strong>78.9%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性83.5%（较高）</li><li>N2→N1转换11.1%（异常高）</li><li>REM→N1转换15.6%（最高）</li></ul><h3 id="受试者5-Fold-4-样本数：910"><a href="#受试者5-Fold-4-样本数：910" class="headerlink" title="受试者5 (Fold 4) - 样本数：910"></a>受试者5 (Fold 4) - 样本数：910</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>86.9%</td><td>9.4%</td><td>3.7%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>15.7%</td><td>34.3%</td><td>32.9%</td><td>0.0%</td><td>17.1%</td></tr><tr><td><strong>N2</strong></td><td>6.4%</td><td>3.4%</td><td><strong>85.3%</strong></td><td>3.8%</td><td>1.1%</td></tr><tr><td><strong>N3</strong></td><td>2.1%</td><td>0.5%</td><td>2.6%</td><td><strong>94.9%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>8.6%</td><td>9.9%</td><td>0.0%</td><td>0.0%</td><td><strong>81.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性86.9%（最高）</li><li>N1自维持率仅34.3%（最低）</li><li>N1→REM转换17.1%（最高）</li><li>该个体W阶段占比32.9%，可能存在睡眠障碍</li></ul><h3 id="受试者6-Fold-5-样本数：819"><a href="#受试者6-Fold-5-样本数：819" class="headerlink" title="受试者6 (Fold 5) - 样本数：819"></a>受试者6 (Fold 5) - 样本数：819</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>38.2%</td><td>52.7%</td><td>9.1%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>12.1%</td><td>51.5%</td><td>25.0%</td><td>0.0%</td><td>11.4%</td></tr><tr><td><strong>N2</strong></td><td>4.5%</td><td>6.3%</td><td><strong>82.6%</strong></td><td>4.9%</td><td>1.7%</td></tr><tr><td><strong>N3</strong></td><td>0.8%</td><td>0.0%</td><td>4.9%</td><td><strong>94.3%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>2.1%</td><td>17.7%</td><td>1.0%</td><td>0.0%</td><td><strong>79.2%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换52.7%（最高）</li><li>W自维持率仅38.2%（第二低）</li><li>REM→N1转换17.7%（第二高）</li><li>该个体入睡转换非常活跃</li></ul><h3 id="受试者7-Fold-6-样本数：780"><a href="#受试者7-Fold-6-样本数：780" class="headerlink" title="受试者7 (Fold 6) - 样本数：780"></a>受试者7 (Fold 6) - 样本数：780</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>79.4%</td><td>14.7%</td><td>4.9%</td><td>0.5%</td><td>0.5%</td></tr><tr><td><strong>N1</strong></td><td>33.9%</td><td>35.5%</td><td>21.0%</td><td>0.0%</td><td>9.7%</td></tr><tr><td><strong>N2</strong></td><td>7.1%</td><td>3.2%</td><td><strong>75.5%</strong></td><td>12.9%</td><td>1.3%</td></tr><tr><td><strong>N3</strong></td><td>1.9%</td><td>0.0%</td><td>5.3%</td><td><strong>92.0%</strong></td><td>0.8%</td></tr><tr><td><strong>REM</strong></td><td>4.2%</td><td>6.3%</td><td>1.0%</td><td>0.0%</td><td><strong>88.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>N1→W反向转换33.9%（最高）</li><li>N1自维持率35.5%（第二低）</li><li>N2→N3转换12.9%（最高）</li><li>该个体N1阶段极不稳定</li></ul><h3 id="受试者8-Fold-7-样本数：966"><a href="#受试者8-Fold-7-样本数：966" class="headerlink" title="受试者8 (Fold 7) - 样本数：966"></a>受试者8 (Fold 7) - 样本数：966</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>92.8%</td><td>7.2%</td><td>0.0%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>10.1%</td><td>60.6%</td><td>22.9%</td><td>0.0%</td><td>6.4%</td></tr><tr><td><strong>N2</strong></td><td>3.6%</td><td>7.2%</td><td><strong>85.6%</strong></td><td>2.6%</td><td>1.0%</td></tr><tr><td><strong>N3</strong></td><td>1.4%</td><td>0.0%</td><td>2.1%</td><td><strong>96.5%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.1%</td><td>1.4%</td><td>0.0%</td><td>0.0%</td><td><strong>94.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性92.8%（最高）</li><li>N3稳定性96.5%（最高）</li><li>REM稳定性94.5%（最高）</li><li>该个体睡眠结构最稳定，W占比38.6%</li></ul><h3 id="受试者9-Fold-8-样本数：935"><a href="#受试者9-Fold-8-样本数：935" class="headerlink" title="受试者9 (Fold 8) - 样本数：935"></a>受试者9 (Fold 8) - 样本数：935</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>60.8%</td><td>35.8%</td><td>1.7%</td><td>0.8%</td><td>0.8%</td></tr><tr><td><strong>N1</strong></td><td>10.2%</td><td>48.5%</td><td>35.9%</td><td>0.0%</td><td>5.4%</td></tr><tr><td><strong>N2</strong></td><td>5.6%</td><td>9.5%</td><td><strong>81.1%</strong></td><td>3.1%</td><td>0.8%</td></tr><tr><td><strong>N3</strong></td><td>1.8%</td><td>0.9%</td><td>2.2%</td><td><strong>94.7%</strong></td><td>0.4%</td></tr><tr><td><strong>REM</strong></td><td>7.9%</td><td>11.1%</td><td>3.2%</td><td>0.0%</td><td><strong>77.8%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换35.8%（第二高）</li><li>N1→N2转换35.9%（第二高）</li><li>N2→N1转换9.5%（较高）</li><li>REM稳定性77.8%（最低）</li></ul><h3 id="受试者10-Fold-9-样本数：762"><a href="#受试者10-Fold-9-样本数：762" class="headerlink" title="受试者10 (Fold 9) - 样本数：762"></a>受试者10 (Fold 9) - 样本数：762</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>62.1%</td><td>36.3%</td><td>1.6%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>15.1%</td><td>70.2%</td><td>13.8%</td><td>0.0%</td><td>0.9%</td></tr><tr><td><strong>N2</strong></td><td>6.4%</td><td>10.4%</td><td><strong>79.2%</strong></td><td>2.3%</td><td>1.7%</td></tr><tr><td><strong>N3</strong></td><td>0.9%</td><td>0.0%</td><td>1.8%</td><td><strong>97.3%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>0.7%</td><td>1.5%</td><td>1.5%</td><td>0.0%</td><td><strong>96.3%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>N1稳定性70.2%（最高）</li><li>N3稳定性97.3%（最高）</li><li>REM稳定性96.3%（第二高）</li><li>N1→N2转换仅13.8%（最低）</li><li>该个体N1阶段占比28.6%（最高）</li></ul><h2 id="3-2-个体差异总结"><a href="#3-2-个体差异总结" class="headerlink" title="3.2 个体差异总结"></a>3.2 个体差异总结</h2><h3 id="转移模式分类"><a href="#转移模式分类" class="headerlink" title="转移模式分类"></a>转移模式分类</h3><p>基于转移概率特征，可将10个受试者分为以下类型：</p><p><strong>1. 稳定型（Fold 7, Fold 9）</strong>：</p><ul><li>各阶段自维持概率高</li><li>转换相对保守</li><li>睡眠结构规律</li></ul><p><strong>2. 过渡型（Fold 2, Fold 8）</strong>：</p><ul><li>W-N1-N2转换频繁</li><li>睡眠阶段边界模糊</li><li>分类难度最高</li></ul><p><strong>3. 清醒主导型（Fold 4, Fold 7）</strong>：</p><ul><li>W阶段占比异常高（&gt;30%）</li><li>可能存在睡眠障碍</li><li>需要特殊处理策略</li></ul><p><strong>4. 平衡型（Fold 0, Fold 1, Fold 3, Fold 5, Fold 6）</strong>：</p><ul><li>各阶段分布相对均衡</li><li>转移模式接近群体平均</li><li>代表典型睡眠模式</li></ul><h3 id="对模型训练的影响"><a href="#对模型训练的影响" class="headerlink" title="对模型训练的影响"></a>对模型训练的影响</h3><p><strong>1. 数据不平衡问题</strong>：</p><ul><li>个体间W阶段占比差异巨大（6.7%-38.6%）</li><li>N1阶段个体差异显著（7.7%-28.6%）</li><li>需要个体化的采样策略</li></ul><p><strong>2. 转移模式多样性</strong>：</p><ul><li>W→N1转换率：7.2%-52.7%</li><li>N1→N2转换率：13.8%-35.9%</li><li>需要多样化的特征表示</li></ul><p><strong>3. 模型泛化挑战</strong>：</p><ul><li>个体睡眠模式差异巨大</li><li>单一模型难以适应所有个体</li><li>建议采用个体适应或元学习方法</li></ul><hr><h1 id="4-模型改进方案：多专家模型架构"><a href="#4-模型改进方案：多专家模型架构" class="headerlink" title="4. 模型改进方案：多专家模型架构"></a>4. 模型改进方案：多专家模型架构</h1><h2 id="4-1-问题分析与改进动机"><a href="#4-1-问题分析与改进动机" class="headerlink" title="4.1 问题分析与改进动机"></a>4.1 问题分析与改进动机</h2><h3 id="现有模型性能特征"><a href="#现有模型性能特征" class="headerlink" title="现有模型性能特征"></a>现有模型性能特征</h3><p>基于数据分析发现，当前睡眠阶段分类模型存在明显的性能不均衡：</p><p><strong>优势阶段</strong>：</p><ul><li><strong>N3（深睡）</strong>：自维持概率94.4%，分类准确率高</li><li><strong>REM（快眼动）</strong>：自维持概率86.7%，特征相对明确</li></ul><p><strong>困难阶段</strong>：</p><ul><li><strong>W（清醒）</strong>：与N1混淆严重，个体差异大（占比6.7%-38.6%）</li><li><strong>N1（浅睡）</strong>：过渡性强，自维持概率仅53.5%</li><li><strong>N2（轻睡）</strong>：虽然稳定性较好（83.0%），但与N1边界模糊</li></ul><h3 id="核心问题识别"><a href="#核心问题识别" class="headerlink" title="核心问题识别"></a>核心问题识别</h3><ol><li><strong>阶段特征差异性</strong>：稳定阶段（N3、REM）与过渡阶段（W、N1、N2）具有本质不同的特征模式</li><li><strong>转换复杂性</strong>：W↔N1↔N2之间的频繁转换（18.4%、25.8%、12.6%）增加了分类难度</li><li><strong>个体差异性</strong>：不同受试者在过渡阶段表现出巨大差异，单一模型难以兼顾</li></ol><h2 id="4-2-多专家模型设计方案"><a href="#4-2-多专家模型设计方案" class="headerlink" title="4.2 多专家模型设计方案"></a>4.2 多专家模型设计方案</h2><h3 id="4-2-1-架构设计理念"><a href="#4-2-1-架构设计理念" class="headerlink" title="4.2.1 架构设计理念"></a>4.2.1 架构设计理念</h3><p>借鉴大语言模型中的混合专家（Mixture of Experts, MOE）思想，设计层次化的多专家睡眠阶段分类系统：</p><p><strong>核心思想</strong>：</p><ul><li>让每个专家模型专注于特定类型睡眠阶段的识别</li><li>避免”一刀切”模型在不同阶段上的性能妥协</li><li>实现”因材施教”的个性化分类策略</li></ul><h3 id="4-2-2-层次化分类架构"><a href="#4-2-2-层次化分类架构" class="headerlink" title="4.2.2 层次化分类架构"></a>4.2.2 层次化分类架构</h3><p><strong>第一层：粗分类器（阶段类型识别）</strong></p><ul><li><strong>目标</strong>：区分稳定阶段 vs 过渡阶段</li><li><strong>输入</strong>：原始多通道睡眠信号特征</li><li><strong>输出</strong>：二分类结果<ul><li>类别A：稳定阶段（N3、REM）</li><li>类别B：过渡阶段（W、N1、N2）</li></ul></li></ul><p><strong>第二层：专家分类器（细粒度识别）</strong></p><ul><li><strong>稳定阶段专家</strong>：专门区分N3 vs REM<ul><li>利用两阶段的高稳定性特征</li><li>重点关注深睡眠与快眼动的生理差异</li></ul></li><li><strong>过渡阶段专家</strong>：专门处理W vs N1 vs N2<ul><li>针对性处理高混淆的三分类问题</li><li>集成个体差异适应机制</li></ul></li></ul><h3 id="4-2-3-专家模型特化策略"><a href="#4-2-3-专家模型特化策略" class="headerlink" title="4.2.3 专家模型特化策略"></a>4.2.3 专家模型特化策略</h3><p><strong>稳定阶段专家优化</strong>：</p><ul><li><strong>特征选择</strong>：重点关注脑电波频域特征、肌电信号强度</li><li><strong>训练策略</strong>：利用高纯度样本进行对比学习</li></ul><p><strong>过渡阶段专家优化</strong>：</p><ul><li><strong>特征工程</strong>：增强时序特征、上下文信息</li><li><strong>数据增强</strong>：针对N1稀少样本进行合成</li><li><strong>个体适应</strong>：集成个体睡眠模式先验知识</li></ul><h2 id="4-3-实施策略与技术路线"><a href="#4-3-实施策略与技术路线" class="headerlink" title="4.3 实施策略与技术路线"></a>4.3 实施策略与技术路线</h2><h3 id="4-3-1-数据划分策略"><a href="#4-3-1-数据划分策略" class="headerlink" title="4.3.1 数据划分策略"></a>4.3.1 数据划分策略</h3><p><strong>训练数据重组</strong>：</p><ul><li><strong>粗分类器训练集</strong>：使用全部8,549个样本，标签重新编码为稳定/过渡</li><li><strong>稳定专家训练集</strong>：3,074个样本（N3: 2,014 + REM: 1,060）</li><li><strong>过渡专家训练集</strong>：5,475个样本（W: 1,651 + N1: 1,215 + N2: 2,609）</li></ul><p><strong>交叉验证适配</strong>：</p><ul><li>保持10-fold结构，确保个体差异的充分表示</li><li>每个fold内同时训练三个子模型</li><li>使用集成学习融合不同fold的专家知识</li></ul><h3 id="4-3-2-模型训练流程"><a href="#4-3-2-模型训练流程" class="headerlink" title="4.3.2 模型训练流程"></a>4.3.2 模型训练流程</h3><p><strong>阶段一：粗分类器训练</strong></p><ol><li>特征提取：使用现有的多通道特征工程</li><li>标签转换：将5分类转换为2分类</li><li>评估指标：重点关注召回率平衡</li></ol><p><strong>阶段二：专家模型训练</strong></p><ol><li><strong>稳定专家</strong>：<ul><li>深度特征学习，关注频域稳定性</li><li>对比学习增强N3与REM的区分度</li></ul></li><li><strong>过渡专家</strong>：<ul><li>序列建模，捕获W-N1-N2转换模式</li><li>注意力机制突出关键时间窗口</li><li>元学习适应个体差异</li></ul></li></ol><p><strong>阶段三：端到端优化</strong></p><ol><li>联合训练微调整体系统</li><li>损失函数设计：加权多任务学习</li><li>推理优化：级联推理加速</li></ol><h3 id="4-3-3-评估与验证"><a href="#4-3-3-评估与验证" class="headerlink" title="4.3.3 评估与验证"></a>4.3.3 评估与验证</h3><p><strong>分层评估策略</strong>：</p><ul><li><strong>粗分类性能</strong>：稳定vs过渡的二分类准确率</li><li><strong>专家性能</strong>：各专家在对应子任务上的表现</li><li><strong>整体性能</strong>：端到端5分类的综合指标</li></ul><p><strong>关键指标</strong>：</p><ul><li>整体准确率提升幅度</li><li>困难阶段（W、N1、N2）的F1-score改善</li><li>个体间性能方差减小</li><li>推理速度与计算开销</li></ul><h2 id="4-4-预期效果与优势分析"><a href="#4-4-预期效果与优势分析" class="headerlink" title="4.4 预期效果与优势分析"></a>4.4 预期效果与优势分析</h2><h3 id="4-4-1-方法优势"><a href="#4-4-1-方法优势" class="headerlink" title="4.4.1 方法优势"></a>4.4.1 方法优势</h3><p><strong>技术优势</strong>：</p><ol><li><strong>专业化分工</strong>：每个模型专注于最擅长的任务</li><li><strong>个体适应性</strong>：过渡专家可针对不同睡眠模式优化</li><li><strong>可解释性</strong>：层次化决策过程更易理解和调试</li><li><strong>扩展性</strong>：可根据新数据灵活调整专家配置</li></ol><p><strong>实用优势</strong>：</p><ol><li><strong>鲁棒性提升</strong>：减少单点故障风险</li><li><strong>部署灵活性</strong>：可根据计算资源选择性部署专家</li><li><strong>持续优化</strong>：可独立优化各专家而不影响整体</li></ol><h3 id="4-4-2-潜在挑战与解决方案"><a href="#4-4-2-潜在挑战与解决方案" class="headerlink" title="4.4.2 潜在挑战与解决方案"></a>4.4.2 潜在挑战与解决方案</h3><p><strong>挑战1：计算复杂度增加</strong></p><ul><li>解决方案：模型压缩、知识蒸馏、边缘计算优化</li></ul><p><strong>挑战2：粗分类器错误传播</strong></p><ul><li>解决方案：置信度阈值、软决策融合、错误纠正机制</li></ul><p><strong>挑战3：数据不平衡加剧</strong></p><ul><li>解决方案：专门的采样策略、生成式数据增强</li></ul><hr><h1 id="5-总结与展望"><a href="#5-总结与展望" class="headerlink" title="5. 总结与展望"></a>5. 总结与展望</h1><p>本项目通过对8,549个睡眠epoch的深入分析，揭示了睡眠阶段分类中的关键挑战和改进机会。多专家模型架构为解决现有模型在不同睡眠阶段上的性能不均衡问题提供了一个有前景的解决方案。</p><p><strong>核心贡献</strong>：</p><ol><li>系统分析了10个受试者的睡眠模式差异和转移特征</li><li>识别了W-N1-N2过渡阶段的分类难点</li><li>提出了基于MOE思想的层次化多专家分类架构</li><li>设计了完整的实施策略和评估方案</li></ol><p><strong>创新价值</strong>：</p><ul><li>将大模型领域的专家混合思想引入睡眠医学</li><li>提供了个体化睡眠分析的新思路</li><li>为睡眠障碍诊断提供了技术支撑</li></ul><p>通过这种”因材施教”的专家模型设计，我们有望显著提升睡眠阶段分类的准确性，特别是在困难的过渡阶段，为睡眠健康监测和临床诊断提供更可靠的技术支持。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>楼道数据分析</title>
      <link href="/2025/05/23/%E6%A5%BC%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2025/05/23/%E6%A5%BC%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><strong>5. 模型比较与分析</strong>  </p><p>在相同数据集和训练设置下，对比 LeNet-5、AlexNet、VGG 系列、MobileNet 系列和 ResNet 系列等模型的关键指标，可以得到以下结论：</p><div class="table-container"><table><thead><tr><th style="text-align:center">模型</th><th style="text-align:center">平均准确率</th><th style="text-align:center">平均精确率</th><th style="text-align:center">平均召回率</th><th style="text-align:center">平均 F1 分数</th><th style="text-align:center">参数量（≈）</th><th style="text-align:center">推理速度（≈）</th></tr></thead><tbody><tr><td style="text-align:center">LeNet-5</td><td style="text-align:center">59.41%</td><td style="text-align:center">46.30%</td><td style="text-align:center">58.10%</td><td style="text-align:center">44.35%</td><td style="text-align:center">~0.06M</td><td style="text-align:center">非常快（N=1ms）</td></tr><tr><td style="text-align:center">AlexNet</td><td style="text-align:center">67.82%</td><td style="text-align:center">62.00%</td><td style="text-align:center">65.97%</td><td style="text-align:center">62.16%</td><td style="text-align:center">~60M</td><td style="text-align:center">较快（10ms）</td></tr><tr><td style="text-align:center">VGG16</td><td style="text-align:center">73.02%</td><td style="text-align:center">72.01%</td><td style="text-align:center">73.40%</td><td style="text-align:center">70.80%</td><td style="text-align:center">~138M</td><td style="text-align:center">慢（20ms）</td></tr><tr><td style="text-align:center">VGG19</td><td style="text-align:center">74.00%</td><td style="text-align:center">71.83%</td><td style="text-align:center">72.66%</td><td style="text-align:center">70.55%</td><td style="text-align:center">~143M</td><td style="text-align:center">很慢（25ms）</td></tr><tr><td style="text-align:center">MobileNetV2</td><td style="text-align:center">62.82%</td><td style="text-align:center">49.79%</td><td style="text-align:center">60.92%</td><td style="text-align:center">52.19%</td><td style="text-align:center">~3.4M</td><td style="text-align:center">快（5ms）</td></tr><tr><td style="text-align:center">MobileNetV3</td><td style="text-align:center">58.90%</td><td style="text-align:center">34.39%</td><td style="text-align:center">58.25%</td><td style="text-align:center">43.25%</td><td style="text-align:center">~5.4M</td><td style="text-align:center">快（5ms）</td></tr><tr><td style="text-align:center">ResNet34</td><td style="text-align:center">73.97%</td><td style="text-align:center">73.55%</td><td style="text-align:center">75.19%</td><td style="text-align:center">73.31%</td><td style="text-align:center">~21.8M</td><td style="text-align:center">中等（15ms）</td></tr><tr><td style="text-align:center">ResNet50</td><td style="text-align:center">74.15%</td><td style="text-align:center">73.63%</td><td style="text-align:center">74.29%</td><td style="text-align:center">71.72%</td><td style="text-align:center">~25.6M</td><td style="text-align:center">中等（18ms）</td></tr></tbody></table></div><ul><li><p><strong>总体表现</strong>：</p><ul><li>VGG 与 ResNet 系列在准确率和召回率上表现最佳，ResNet50 以 74.15% 的平均准确率略胜 VGG19。</li><li>轻量级网络 MobileNetV2/V3 即便参数量小、推理快，但精确率和 F1 分数下降明显，表明在本任务中容量受限对分类性能影响较大。</li><li>经典浅层网络 LeNet-5 与 AlexNet 虽然推理速度快，但与更深、更复杂的模型相比，性能存在较大差距（相差约15–20个百分点）。</li></ul></li><li><p><strong>模型复杂度 vs. 性能</strong>：</p><ul><li>随着模型深度和参数量增加，准确率整体趋于提升，但边际效益递减——VGG19（143M 参数）相比 VGG16（138M 参数）增长仅≈0.98%。</li><li>ResNet 引入的残差结构，令更深网络仍能保持有效梯度传播，因此 ResNet34/50 在相似规模下性能优于同类非残差网络。</li></ul></li><li><p><strong>数据增强的作用</strong>：</p><ul><li>在基础几何和颜色变换之外，加入 MixUp、CutMix 与 Random Erasing 等高级增强后，所有模型的泛化能力均有明显提升。</li><li>尤其对轻量化模型（MobileNet 系列），高级增强帮助其在小模型容量下获得更稳定的决策边界，减少过拟合现象。</li></ul></li></ul><hr><h3 id="三、实验感悟和总结"><a href="#三、实验感悟和总结" class="headerlink" title="三、实验感悟和总结"></a>三、实验感悟和总结</h3><ol><li><p><strong>工具链与框架</strong></p><ul><li>熟练掌握了 PyTorch 的模型定义、数据加载（DataLoader）、训练与验证流程；</li><li>深入理解了 NumPy、matplotlib、PIL、OpenCV 在数据预处理与可视化中的配合与使用。</li></ul></li><li><p><strong>实验设计与迭代</strong></p><ul><li>从简单到复杂分阶段实施：先用 LeNet-5 快速验证流程，再逐步引入更深网络，避免从一开始就陷入长时间的训练等待；</li><li>比较不同网络结构、损失函数与优化器、学习率调度器对收敛速度与最终性能的影响，培养了科学实验的思路。</li></ul></li><li><p><strong>性能与资源权衡</strong></p><ul><li>在实际部署场景中，需要在准确率、模型大小与推理速度间进行折中；</li><li>轻量化模型在资源受限环境（如嵌入式设备）有明显优势，但在对性能要求高的场景下，需考虑使用中等规模的残差网络或裁剪／量化等技术。</li></ul></li><li><p><strong>团队合作与问题定位</strong></p><ul><li>多人协作实验中，通过版本管理与日志记录能更快地回溯错误；</li><li>在模型训练中遇到收敛缓慢、过拟合等问题时，通过可视化损失曲线和混淆矩阵，快速定位并调整超参数或增强策略。</li></ul></li></ol><hr><h3 id="四、思考题"><a href="#四、思考题" class="headerlink" title="四、思考题"></a>四、思考题</h3><p>（一）<strong>近年来目标检测方法和训练的趋势</strong></p><ol><li><strong>Transformer 与自注意力机制</strong><ul><li>DETR 系列将 Detection 转化为序列预测，无需手工设计 Anchor，简化了后处理流程；</li></ul></li><li><strong>Anchor-free 方法</strong><ul><li>如 FCOS、CenterNet 等，直接预测中心点或关键点，提高速度并简化设计；</li></ul></li><li><strong>多任务与统一架构</strong><ul><li>单一骨干网络同时输出分类、检测、分割结果，推动了通用视觉模型的发展；</li></ul></li><li><strong>自监督预训练</strong><ul><li>如 MoCo、SimCLR 为下游检测任务提供了更具泛化能力的预训练模型。</li></ul></li></ol><p>（二）<strong>几种基础大模型及其训练方案</strong></p><ol><li><strong>BERT（双向 Transformer）</strong><ul><li>预训练任务：Masked Language Modeling、Next Sentence Prediction；</li></ul></li><li><strong>GPT 系列（自回归 Transformer）</strong><ul><li>通过海量文本进行语言模型训练，生成式下游任务效果突出；</li></ul></li><li><strong>ViT（Vision Transformer）</strong><ul><li>将图像分割成 patch，按序列方式输入 Transformer，结合大规模数据与强正则化训练；</li></ul></li><li><strong>混合架构</strong><ul><li>如 ConvNext、Swin Transformer，将卷积与自注意力融合，兼顾效率与性能。</li></ul></li></ol><p>（三）<strong>感兴趣的前沿方向</strong></p><ul><li><strong>多模态学习</strong>：视觉语言预训练（如 CLIP、DALL·E）；</li><li><strong>自监督与无监督学习</strong>：减少标注依赖，探索更通用的表征；</li><li><strong>联邦学习与隐私保护</strong>：在数据不出设备前提下进行协同训练；</li><li><strong>神经架构搜索（NAS）</strong>：自动化设计轻量高效网络；</li><li><strong>图神经网络与时空建模</strong>：应用于视频理解及动态场景感知。</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报1.0</title>
      <link href="/2025/05/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A51.0/"/>
      <url>/2025/05/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A51.0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-项目背景"><a href="#1-项目背景" class="headerlink" title="1. 项目背景"></a>1. 项目背景</h1><ul><li><strong>任务</strong>：利用强化学习提升基于多通道的睡眠阶段数据分类模型的性能  </li><li><strong>睡眠阶段</strong>：W, N1, N2, N3, REM  </li><li><strong>挑战</strong>：  <ul><li>序列预测需保持时序平滑  </li><li>不同阶段在整夜睡眠中出现的时间分布不同  </li><li>阶段之间的转移概率有先验知识</li></ul></li></ul><h1 id="2-现有数据背景"><a href="#2-现有数据背景" class="headerlink" title="2. 现有数据背景"></a>2. 现有数据背景</h1><p>基于现有原始MVF模型，可以得到下列真值与预测值图像的对比如下<br><img src="/img/combined-1.png" alt="image.png"><br>可以观察到，绝大部分数据的错误点都在真值的拐点处，并且真实值的波动性较大，而实际值的图像较为平滑，所以选择了以下的方式构建了强化学习的奖励函数：</p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>cls</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mi mathvariant="normal">A</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">y</mi></mrow><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>sm</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>N</mi></munderover><mn mathvariant="bold">1</mn><mo stretchy="false">{</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo mathvariant="normal">≠</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">}</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>trans</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>N</mi></munderover><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>P</mi><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mtext> </mtext><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub></mrow></msub><mo>+</mo><mi>ϵ</mi><mo fence="true">)</mo></mrow><mo>+</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>time</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mn mathvariant="bold">1</mn><mrow><mo fence="true">(</mo><mi>t</mi><mi mathvariant="normal">/</mi><mi>N</mi><mo>∈</mo><mtext>期望时间区间</mtext><mo stretchy="false">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>R</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>α</mi><mtext> </mtext><msub><mi>r</mi><mtext>cls</mtext></msub><mo>+</mo><mi>β</mi><mtext> </mtext><msub><mi>r</mi><mtext>sm</mtext></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><msub><mi>r</mi><mtext>trans</mtext></msub><mo>+</mo><mi>δ</mi><mtext> </mtext><msub><mi>r</mi><mtext>time</mtext></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}r_\text{cls} &amp;= \mathrm{Accuracy}(y, \hat y) \\r_\text{sm}  &amp;= 1 - \frac{1}{N-1} \sum_{t=2}^N \mathbf{1}\{\hat y_t \neq \hat y_{t-1}\} \\r_\text{trans} &amp;= \frac{1}{N-1}\sum_{t=2}^N \log\left(P_{\hat y_{t-1},\,\hat y_t} + \epsilon\right) + 1 \\r_\text{time} &amp;= \frac{1}{N}\sum_{t=1}^N \mathbf{1}\left(t/N \in \text{期望时间区间}(\hat y_t)\right) \\R &amp;= \alpha\,r_\text{cls}    + \beta\,r_\text{sm}    + \gamma\,r_\text{trans}    + \delta\,r_\text{time}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:13.1863em;vertical-align:-6.3432em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.8432em;"><span style="top:-9.8315em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">cls</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-7.3432em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">sm</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9477em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">trans</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.5523em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">time</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:1.8548em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:6.3432em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.8432em;"><span style="top:-9.8315em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.01389em;">Accuracy</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-7.3432em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">1</span><span class="mopen">{</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span><span style="top:-3.9477em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2025em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2918em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-0.5523em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">1</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal">t</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord cjk_fallback">期望时间区间</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:1.8548em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">cls</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">sm</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">trans</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">time</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:6.3432em;"><span></span></span></span></span></span></span></span></span></span></span><h2 id="分别解释来说"><a href="#分别解释来说" class="headerlink" title="分别解释来说"></a>分别解释来说</h2><h3 id="1-对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性"><a href="#1-对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性" class="headerlink" title="1.对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性"></a>1.对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类精度奖励 r_cls</span></span><br><span class="line">r_cls = accuracy_score(targets, preds)</span><br></pre></td></tr></table></figure><h3 id="2-对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励"><a href="#2-对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励" class="headerlink" title="2.对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励"></a>2.对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 平滑度分量 r_sm</span></span><br><span class="line">r_sm = np.mean(preds[<span class="number">1</span>:] != preds[:-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="3-对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励"><a href="#3-对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励" class="headerlink" title="3.对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励"></a>3.对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># idx: 验证集真实标签序列的类别索引</span></span><br><span class="line">idx = vr_l.argmax(axis=<span class="number">1</span>)           <span class="comment"># e.g. shape (N,), 值在 [0, C-1]</span></span><br><span class="line"><span class="comment"># C: 类别数</span></span><br><span class="line">C = <span class="built_in">int</span>(idx.<span class="built_in">max</span>()) + <span class="number">1</span>              <span class="comment"># 类别编号从 0 开始</span></span><br><span class="line"><span class="comment"># 初始化转移计数矩阵</span></span><br><span class="line">P = np.zeros((C, C), dtype=<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 统计相邻标签的转移次数</span></span><br><span class="line"><span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(idx[:-<span class="number">1</span>], idx[<span class="number">1</span>:]):</span><br><span class="line">    P[a, b] += <span class="number">1</span></span><br><span class="line"><span class="comment"># 加入微小平滑因子，转换为概率</span></span><br><span class="line">P = (P + <span class="number">1e-6</span>) / (P.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) + <span class="number">1e-6</span>)</span><br><span class="line"><span class="comment"># 利用上面构建的转移矩阵 P, 从中提取对应的转移概率</span></span><br><span class="line">logs = np.log([P[preds[j-<span class="number">1</span>], preds[j]] + <span class="number">1e-8</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(preds))])</span><br><span class="line">r_trans = np.mean(logs) + <span class="number">1.0</span></span><br></pre></td></tr></table></figure><h3 id="4-对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中"><a href="#4-对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中" class="headerlink" title="4.对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中"></a>4.对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class_time = &#123;</span><br><span class="line">    <span class="number">0</span>: (<span class="number">0.0</span>, <span class="number">0.2</span>), <span class="number">1</span>: (<span class="number">0.2</span>, <span class="number">0.4</span>), <span class="number">2</span>: (<span class="number">0.4</span>, <span class="number">0.6</span>),</span><br><span class="line">    <span class="number">3</span>: (<span class="number">0.6</span>, <span class="number">0.8</span>), <span class="number">4</span>: (<span class="number">0.8</span>, <span class="number">1.0</span>)</span><br><span class="line">&#125;</span><br><span class="line">norm_t = np.arange(<span class="built_in">len</span>(preds)) / <span class="built_in">len</span>(preds)</span><br><span class="line">r_time = np.mean([</span><br><span class="line">    class_time[p][<span class="number">0</span>] &lt;= t &lt;= class_time[p][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> p, t <span class="keyword">in</span> <span class="built_in">zip</span>(preds, norm_t)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h3 id="其中各权重："><a href="#其中各权重：" class="headerlink" title="其中各权重："></a>其中各权重：</h3><pre><code>α（准确率权重）： 1.0β（平滑性）：    0.1γ（转移一致性）： 1.0δ（时间匹配）：   0.1</code></pre><h3 id="主要训练模块如下："><a href="#主要训练模块如下：" class="headerlink" title="主要训练模块如下："></a>主要训练模块如下：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于策略的梯度更新</span></span><br><span class="line">model.train()</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="keyword">for</span> feat_b, stft_b, label_b <span class="keyword">in</span> tr_loader:</span><br><span class="line">    feat_b = feat_b.to(device)</span><br><span class="line">    stft_b = stft_b.to(device)</span><br><span class="line">    logits = model(feat_b, stft_b)</span><br><span class="line">    dist = Categorical(logits=logits)</span><br><span class="line">    a = dist.sample()</span><br><span class="line">    lp = dist.log_prob(a)</span><br><span class="line">    <span class="comment"># per-sample update accumulation</span></span><br><span class="line">    loss = - lp.mean() * reward  </span><br><span class="line">    loss.backward()  <span class="comment"># free graph after each backward</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><h3 id="在针对fold8的微调中，性能从原始的0-61提升至0-71，但除了这一数据以外其余数据几乎不提升性能"><a href="#在针对fold8的微调中，性能从原始的0-61提升至0-71，但除了这一数据以外其余数据几乎不提升性能" class="headerlink" title="在针对fold8的微调中，性能从原始的0.61提升至0.71，但除了这一数据以外其余数据几乎不提升性能"></a>在针对fold8的微调中，性能从原始的0.61提升至0.71，但除了这一数据以外其余数据几乎不提升性能</h3><p><img src="/img/val_acc.png" alt="image.png"></p><h3 id="如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下"><a href="#如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下" class="headerlink" title="如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下"></a>如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下</h3><p><img src="/img/combined_acc.png" alt="image.png"></p><h2 id="推断情况可能如下："><a href="#推断情况可能如下：" class="headerlink" title="推断情况可能如下："></a>推断情况可能如下：</h2><h3 id="1-模型后期处于过拟合状态，无法泛化到测试集中"><a href="#1-模型后期处于过拟合状态，无法泛化到测试集中" class="headerlink" title="1.模型后期处于过拟合状态，无法泛化到测试集中"></a>1.模型后期处于过拟合状态，无法泛化到测试集中</h3><h3 id="2-参数组合还需要进一步调整"><a href="#2-参数组合还需要进一步调整" class="headerlink" title="2.参数组合还需要进一步调整"></a>2.参数组合还需要进一步调整</h3><h3 id="3-模型本身容量不够，需要增加模型的复杂度"><a href="#3-模型本身容量不够，需要增加模型的复杂度" class="headerlink" title="3.模型本身容量不够，需要增加模型的复杂度"></a>3.模型本身容量不够，需要增加模型的复杂度</h3><h3 id="4-奖励函数的机制还需要进一步设计"><a href="#4-奖励函数的机制还需要进一步设计" class="headerlink" title="4.奖励函数的机制还需要进一步设计"></a>4.奖励函数的机制还需要进一步设计</h3><h3 id="5-更换性能更好的算法，例如PPO"><a href="#5-更换性能更好的算法，例如PPO" class="headerlink" title="5.更换性能更好的算法，例如PPO"></a>5.更换性能更好的算法，例如PPO</h3><h2 id="下面是一些废案"><a href="#下面是一些废案" class="headerlink" title="下面是一些废案"></a>下面是一些废案</h2><h2 id="1-ActorCritic-算法部分"><a href="#1-ActorCritic-算法部分" class="headerlink" title="1. ActorCritic 算法部分"></a>1. ActorCritic 算法部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ActorCritic</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_model, hidden_dim, n_actions</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.base = base_model</span><br><span class="line">        feat_dim = <span class="number">5</span></span><br><span class="line">        <span class="comment"># Policy head</span></span><br><span class="line">        <span class="variable language_">self</span>.pi = nn.Sequential(</span><br><span class="line">            nn.Linear(feat_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, n_actions)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Value head</span></span><br><span class="line">        <span class="variable language_">self</span>.v = nn.Sequential(</span><br><span class="line">            nn.Linear(feat_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, feat, stft</span>):</span><br><span class="line">        <span class="comment"># 从 base_model 获得特征 embedding</span></span><br><span class="line">        emb = <span class="variable language_">self</span>.base(feat, stft)</span><br><span class="line">        <span class="comment"># 返回策略 logits 和状态值（去掉最后一维）</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.pi(emb), <span class="variable language_">self</span>.v(emb).squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><p><strong>结构说明</strong>  </p><ul><li><strong>base_model</strong>：预训练的睡眠网络（MVFSleepNet），用于提取状态表示。  </li><li><strong>策略网络（π）</strong>：输入维度 <code>feat_dim=5</code>，隐藏层维度 <code>hidden_dim</code>，输出维度等于动作数 <code>n_actions</code>，输出为 logits。  </li><li><strong>价值网络（V）</strong>：同样输入 <code>feat_dim</code>，隐藏维度 <code>hidden_dim</code>，输出为标量状态价值。  </li></ul></li><li><p><strong>前向过程</strong>  </p><ol><li>将原始特征 <code>feat</code> 与 STFT 特征 <code>stft</code> 输入 <code>base_model</code>，得到 embedding 向量 <code>emb</code>。  </li><li><code>pi(emb)</code> 生成每个动作的 logits，用于构造离散分布。  </li><li><code>v(emb)</code> 生成对应的状态价值，并用 <code>squeeze(-1)</code> 去除多余维度。</li></ol></li></ul><h2 id="2-collect-rollout-函数"><a href="#2-collect-rollout-函数" class="headerlink" title="2. collect_rollout 函数"></a>2. collect_rollout 函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collect_rollout</span>(<span class="params">ac_model, data_loader, P, device</span>):</span><br><span class="line">    ac_model.<span class="built_in">eval</span>()</span><br><span class="line">    states, actions, logps, values = [], [], [], []</span><br><span class="line">    rewards, dones = [], []</span><br><span class="line">    prev_act = <span class="literal">None</span></span><br><span class="line">    correct, total = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> feat_b, stft_b, label_b <span class="keyword">in</span> data_loader:</span><br><span class="line">            feat_b = feat_b.to(device)</span><br><span class="line">            stft_b = stft_b.to(device)</span><br><span class="line">            labels = label_b.argmax(dim=<span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向并采样动作</span></span><br><span class="line">            logits, value = ac_model(feat_b, stft_b)</span><br><span class="line">            dist = Categorical(logits=logits)</span><br><span class="line">            a = dist.sample()</span><br><span class="line">            lp = dist.log_prob(a)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 统计训练集预测准确率</span></span><br><span class="line">            correct += (a == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">            total += a.numel()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存状态、动作、LogProb、价值</span></span><br><span class="line">            states.append((feat_b, stft_b))</span><br><span class="line">            actions.append(a)</span><br><span class="line">            logps.append(lp)</span><br><span class="line">            values.append(value)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 逐样本计算奖励</span></span><br><span class="line">            y_true = labels.cpu().numpy()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(a.size(<span class="number">0</span>)):</span><br><span class="line">                r = compute_reward(a[i].item(), y_true[i], prev_act, P)</span><br><span class="line">                rewards.append(r)</span><br><span class="line">                dones.append(<span class="number">0</span>)</span><br><span class="line">                prev_act = a[i].item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接成张量</span></span><br><span class="line">    actions = torch.cat(actions).to(device)</span><br><span class="line">    logps   = torch.cat(logps).to(device)</span><br><span class="line">    values  = torch.cat(values).to(device)</span><br><span class="line">    rewards = torch.tensor(rewards, dtype=torch.float32, device=device)</span><br><span class="line">    dones   = torch.tensor(dones, dtype=torch.float32, device=device)</span><br><span class="line"></span><br><span class="line">    train_acc = correct / total</span><br><span class="line">    <span class="keyword">return</span> states, actions, logps, values, rewards, dones, train_acc</span><br></pre></td></tr></table></figure><ul><li><strong>主要功能</strong>  <ul><li>在环境（这里用的是静态数据集）中执行一次 rollout，采样一系列 <code>(状态, 动作)</code>，并计算相应的即时奖励。  </li><li><strong>输入</strong>  <ul><li><code>ac_model</code>：ActorCritic 模型  </li><li><code>data_loader</code>：训练数据迭代器（batch_size=1，逐样本执行）  </li><li><code>P</code>：状态转移概率矩阵，用于转移奖励计算  </li></ul></li><li><strong>输出</strong>  <ul><li><code>states</code>：每一步的 <code>(feat, stft)</code> 张量对列表  </li><li><code>actions</code>：动作序列张量  </li><li><code>logps</code>：对应的动作 log-probabilities  </li><li><code>values</code>：Critic 网络给出的状态价值  </li><li><code>rewards</code>：即时奖励序列  </li><li><code>dones</code>：终止标志序列（此处始终为 0）  </li><li><code>train_acc</code>：Rollout 期间的分类准确率  </li></ul></li></ul></li></ul><h2 id="3-PPO-更新（ppo-update-函数）"><a href="#3-PPO-更新（ppo-update-函数）" class="headerlink" title="3. PPO 更新（ppo_update 函数）"></a>3. PPO 更新（ppo_update 函数）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ppo_update</span>(<span class="params">ac_model, opt_groups, rollout_data,</span></span><br><span class="line"><span class="params">               device, ppo_epochs, mb_size</span>):</span><br><span class="line">    ac_model.train()</span><br><span class="line">    states, actions, old_logps, values, rewards, dones = rollout_data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 计算 Returns 和 GAE 优势</span></span><br><span class="line">    returns, advs = [], []</span><br><span class="line">    gae = <span class="number">0</span></span><br><span class="line">    next_value = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(rewards))):</span><br><span class="line">        delta = rewards[t] + gamma * next_value * (<span class="number">1</span>-dones[t]) - values[t]</span><br><span class="line">        gae = delta + gamma * gae_lambda * (<span class="number">1</span>-dones[t]) * gae</span><br><span class="line">        advs.insert(<span class="number">0</span>, gae)</span><br><span class="line">        next_value = values[t]</span><br><span class="line">        returns.insert(<span class="number">0</span>, gae + values[t])</span><br><span class="line">    returns = torch.stack(returns).to(device)</span><br><span class="line">    advs    = torch.stack(advs).to(device)</span><br><span class="line">    advs    = (advs - advs.mean()) / (advs.std() + <span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 多轮小批量更新</span></span><br><span class="line">    total_pi_loss = total_v_loss = total_ent = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(ppo_epochs):</span><br><span class="line">        idxs = torch.randperm(<span class="built_in">len</span>(rewards), device=device)</span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(idxs), mb_size):</span><br><span class="line">            mb = idxs[start:start+mb_size]</span><br><span class="line">            <span class="comment"># 准备小批量数据</span></span><br><span class="line">            feat_mb = torch.cat([states[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> mb], <span class="number">0</span>)</span><br><span class="line">            stft_mb = torch.cat([states[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> mb], <span class="number">0</span>)</span><br><span class="line">            a_mb     = actions[mb]</span><br><span class="line">            old_lp_mb= old_logps[mb]</span><br><span class="line">            R_mb     = returns[mb]</span><br><span class="line">            A_mb     = advs[mb]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向计算新策略</span></span><br><span class="line">            logits, V_mb = ac_model(feat_mb, stft_mb)</span><br><span class="line">            dist = Categorical(logits=logits)</span><br><span class="line">            lp_new = dist.log_prob(a_mb)</span><br><span class="line">            ratio = torch.exp(lp_new - old_lp_mb)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># PPO Clip-Objective</span></span><br><span class="line">            surr1 = ratio * A_mb</span><br><span class="line">            surr2 = torch.clamp(ratio, <span class="number">1</span>-clip_eps, <span class="number">1</span>+clip_eps) * A_mb</span><br><span class="line">            loss_pi = -torch.<span class="built_in">min</span>(surr1, surr2).mean() \</span><br><span class="line">                      - entropy_coef * dist.entropy().mean()</span><br><span class="line">            <span class="comment"># Value loss (MSE)</span></span><br><span class="line">            loss_v = nn.MSELoss()(V_mb, R_mb)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            <span class="keyword">for</span> opt <span class="keyword">in</span> opt_groups: opt.zero_grad()</span><br><span class="line">            (loss_pi + loss_v).backward()</span><br><span class="line">            <span class="keyword">for</span> opt <span class="keyword">in</span> opt_groups: opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累积统计</span></span><br><span class="line">            total_pi_loss += loss_pi.item()</span><br><span class="line">            total_v_loss  += loss_v.item()</span><br><span class="line">            total_ent     += dist.entropy().mean().item()</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平均损失与熵</span></span><br><span class="line">    <span class="keyword">return</span> total_pi_loss/count, total_v_loss/count, total_ent/count</span><br></pre></td></tr></table></figure><ol><li><p><strong>计算 Returns 与 GAE 优势</strong>  </p><ul><li>采用通用优势估计（GAE）公式：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>δ</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>A</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>δ</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><mi>λ</mi><mtext> </mtext><msub><mi>A</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\delta_t &amp;= r_t + \gamma\,V(s_{t+1}) - V(s_t),\\A_t      &amp;= \delta_t + \gamma\,\lambda\,A_{t+1}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span></span></span></span></span></span>  </li><li>并同时构造蒙特卡洛 Return：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>R</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>A</mi><mi>t</mi></msub><mo>+</mo><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}R_t &amp;= A_t + V(s_t)\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5em;vertical-align:-0.5em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em;"><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em;"><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span></span></span></span></span></span>  </li><li>最终对 advantages 进行归一化（零均值和单位方差）。</li></ul></li><li><p><strong>PPO Clip 目标</strong>  </p><ul><li>计算策略比率：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi mathvariant="normal">o</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">d</mi></mrow></msub></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo></mrow><annotation encoding="application/x-tex">r_t(\theta) = \exp\bigl(\log\pi_\theta(a_t\mid s_t) - \log\pi_{\theta_{\mathrm{old}}}(a_t\mid s_t)\bigr)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mop">exp</span><span class="mopen"><span class="delimsizing size1">(</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0059em;vertical-align:-0.2559em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">old</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="delimsizing size1">)</span></span></span></span></span>  </li><li>采用 clipped surrogate objective：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">P</mi></mrow></msup><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><mi>min</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><msub><mi>r</mi><mi>t</mi></msub><mtext> </mtext><msub><mi>A</mi><mi>t</mi></msub><mo separator="true">,</mo><mtext>  </mtext><mrow><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">p</mi></mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>ϵ</mi><mo separator="true">,</mo><mn>1</mn><mo>+</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mtext> </mtext><msub><mi>A</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo></mrow><annotation encoding="application/x-tex">L^{\mathrm{CLIP}} = -\mathbb{E}_t\Bigl[\min\bigl(r_t\,A_t,\;\mathrm{clip}(r_t,1-\epsilon,1+\epsilon)\,A_t\bigr)\Bigr]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">CLIP</span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen"><span class="delimsizing size2">[</span></span><span class="mop">min</span><span class="mopen"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathrm">clip</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϵ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing size1">)</span></span><span class="mclose"><span class="delimsizing size2">]</span></span></span></span></span>  </li><li>加上熵正则化以鼓励探索：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>β</mi><mtext> </mtext><mi>H</mi><mo stretchy="false">[</mo><mi>π</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">-\beta\,H[\pi]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mclose">]</span></span></span></span></li></ul></li><li><p><strong>价值函数更新</strong>  </p><ul><li>简单的均方误差损失：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mi>V</mi></msup><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi>R</mi><mi>t</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">]</mo></mrow><annotation encoding="application/x-tex">L^V = \mathbb{E}_t\bigl[(V_\theta(s_t) - R_t)^2\bigr]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing size1">]</span></span></span></span></span></li></ul></li><li><p><strong>多轮与小批量</strong>  </p><ul><li>在同一次 rollout 数据上重复多轮 (<code>ppo_epochs</code>) 更新。  </li><li>每轮将数据打乱并拆分为多个小批量 (<code>mb_size</code>)。</li></ul></li></ol><p>但存在的问题是，模型基本上是不收敛的，acc会急剧下降到一个特别低的水平。</p><h2 id="改进方向"><a href="#改进方向" class="headerlink" title="改进方向"></a>改进方向</h2><h3 id="1-对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移"><a href="#1-对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移" class="headerlink" title="1. 对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移"></a>1. 对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移</h3><h3 id="2-模型架构本身复杂度不够，无法学习到所有的特征"><a href="#2-模型架构本身复杂度不够，无法学习到所有的特征" class="headerlink" title="2. 模型架构本身复杂度不够，无法学习到所有的特征"></a>2. 模型架构本身复杂度不够，无法学习到所有的特征</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多模态智能体的睡眠分析工具链</title>
      <link href="/2025/04/09/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
      <url>/2025/04/09/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器登陆指南</title>
      <link href="/2025/03/21/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%99%BB%E9%99%86%E6%8C%87%E5%8D%97/"/>
      <url>/2025/03/21/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%99%BB%E9%99%86%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>在使用ssh登陆服务器的过程中，有一些特殊的场景，比如说使用vscode远程连接主机，每次都需要手动输入密码，非常繁琐，以及有的服务器上并没有“魔法”条件，这个时候就需要一些特殊的手段，本篇主要记录一些解决方案。</p>]]></content>
      
      
      <categories>
          
          <category> share </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基于4卡昇腾910B服务器部署DeepSeek的踩坑日记</title>
      <link href="/2025/02/25/DeepSeek%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
      <url>/2025/02/25/DeepSeek%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>最近终于在昇腾910B的服务器上跑通了DeepSeek的模型，期间踩了无数的坑，记录一下这些折磨人的经历。<br>首先，学校的服务器虽然看上去是4卡910B，但实际上是910A。坑爹，太坑爹了，既然是910A那为什么npu-smi info会显示910B，你这不欺负老实人吗？<br>其次我还要吐槽，为什么910B会分出来B1 B2 B3 B4，这些玩意还通通全叫910B，安能辨我是雄雌？ 硬件就先吐槽到这。<br>接下来就是cann的版本区别，在8.0.RC3这个版本下，910推理模型会缺失一些算子，但910B却不会，这一点坑了我好久。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">File &quot;/usr/local/Ascend/atb-models/atb_llm/utils/data/weight_wrapper.py&quot;, line 49, in __init__</span><br><span class="line">^^^^^^^    ^self.placeholder = torch.zeros(1, dtype=torch.float16, device=&quot;npu&quot;)^</span><br><span class="line">^^^^^^^^^ ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span><br><span class="line">^^RuntimeError^: ^call aclnnInplaceZero failed, detail:EZ9999: Inner Error!</span><br><span class="line">EZ9999: [PID: 3454] 2025-02-21-23:08:46.559.394 Parse dynamic kernel config fail.</span><br><span class="line">TraceBack (most recent call last):</span><br><span class="line">AclOpKernelInit failed opType</span><br><span class="line">ZerosLike ADD_TO_LAUNCHER_LIST_AICORE failed.</span><br><span class="line"></span><br><span class="line">[ERROR] 2025-02-21-23:08:46 (PID:3454, Device:2, RankID:2) ERR01100 OPS call acl api failed</span><br><span class="line"></span><br><span class="line">File &quot;/usr/local/Ascend/atb-models/atb_llm/utils/data/weight_wrapper.py&quot;, line 49, in __init__</span><br><span class="line">self.placeholder = torch.zeros(1, dtype=torch.float16, device=&quot;npu&quot;)</span><br><span class="line">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span><br><span class="line">RuntimeError: call aclnnInplaceZero failed, detail:EZ9999: Inner Error!</span><br></pre></td></tr></table></figure><br>后面尝试更新了最新的cann包8.0.0版本以及对应的910的kernels，这里打910B的kernels都不行。到这里不过至少没有算子的报错了，但变成了另外的报错：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Sync:torch_npu/csrc/framework/OpCommand.cpp:190 NPU error, error code is 507018</span><br><span class="line">[ERROR] 2025-02-25-21:55:56 (PID:72781, Device:0, RankID:-1) ERR00100 PTA call acl api failed</span><br><span class="line">[Error]: The aicpu execution is abnormal. </span><br><span class="line">        Rectify the fault based on the error information in the ascend log.</span><br><span class="line">E39999: Inner Error!</span><br><span class="line">E39999: [PID: 72781] 2025-02-25-21:55:56.347.048 An exception occurred during AICPU execution, stream_id:2, task_id:1918, errcode:21008, msg:inner error[FUNC:ProcessAicpuErrorInfo][FILE:device_error_proc.cc][LINE:832]</span><br><span class="line">        TraceBack (most recent call last):</span><br><span class="line">       rtStreamSynchronizeWithTimeout execute failed, reason=[aicpu exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]</span><br><span class="line">       synchronize stream failed, runtime result = 507018[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]</span><br></pre></td></tr></table></figure><br>这个问题弄的我很头疼，让我排查问题排查了很久，一度搁置了这个问题，直到我偶然在github的issue里面发现了相似的报错，最终导向了关闭do_sample这个选项，猜测应该也是某个算子缺了。<br>直到这里，才能正常的推理下去</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> Ascend </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>鹰眼项目重构</title>
      <link href="/2025/02/19/EagleEyes/"/>
      <url>/2025/02/19/EagleEyes/</url>
      
        <content type="html"><![CDATA[<h1 id="羽毛球轨迹预测系统-Badminton-Trajectory-Prediction"><a href="#羽毛球轨迹预测系统-Badminton-Trajectory-Prediction" class="headerlink" title="羽毛球轨迹预测系统 (Badminton Trajectory Prediction)"></a>羽毛球轨迹预测系统 (Badminton Trajectory Prediction)</h1><p>基于YOLOv5目标检测与LSTM时序建模的羽毛球运动轨迹预测系统(重构版)</p><h2 id="🚀-功能特性"><a href="#🚀-功能特性" class="headerlink" title="🚀 功能特性"></a>🚀 功能特性</h2><ul><li><strong>高精度检测</strong>: 采用YOLOv5实时检测羽毛球位置</li><li><strong>轨迹建模</strong>: 使用深度LSTM网络学习运动模式</li><li><strong>可视化分析</strong>: 生成轨迹对比图与训练曲线</li><li><strong>多步预测</strong>: 支持任意长度的轨迹预测</li></ul><h2 id="📦-环境要求"><a href="#📦-环境要求" class="headerlink" title="📦 环境要求"></a>📦 环境要求</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ultralytics/yolov5</span><br><span class="line"><span class="built_in">cd</span> yolov5</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="🗂-项目结构"><a href="#🗂-项目结构" class="headerlink" title="🗂 项目结构"></a>🗂 项目结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">EagleEyes/</span><br><span class="line">├── input_videos/          # 原始视频存储目录</span><br><span class="line">├── trajectories/          # 提取的轨迹CSV文件</span><br><span class="line">├── saved_models/          # 训练好的模型参数</span><br><span class="line">├── prediction_results/    # 预测结果可视化</span><br><span class="line">├── extract.py             # 轨迹提取脚本</span><br><span class="line">├── train.py               # LSTM训练脚本</span><br><span class="line">└── predict.py             # 预测与可视化脚本</span><br></pre></td></tr></table></figure><h2 id="🛠-使用指南"><a href="#🛠-使用指南" class="headerlink" title="🛠 使用指南"></a>🛠 使用指南</h2><ol><li><p>轨迹提取</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python extract.py \</span><br><span class="line">    --video_dir input_videos \</span><br><span class="line">    --output_dir trajectories \</span><br><span class="line">    --visualize </span><br></pre></td></tr></table></figure></li><li><p>模型训练</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py \</span><br><span class="line">    --data_dir ./trajectories \</span><br><span class="line">    --save_dir ./saved_models \</span><br><span class="line">    --epochs 500 \</span><br><span class="line">    --batch_size 64</span><br></pre></td></tr></table></figure></li><li><p>轨迹预测</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python predict.py \</span><br><span class="line">    --model_path ./saved_models/model_epoch500.pt \</span><br><span class="line">    --trajectory_file ./trajectories/test1.csv \</span><br><span class="line">    --output_dir ./prediction_results</span><br></pre></td></tr></table></figure><h2 id="⚙-参数说明"><a href="#⚙-参数说明" class="headerlink" title="⚙ 参数说明"></a>⚙ 参数说明</h2><h3 id="训练参数-train-py"><a href="#训练参数-train-py" class="headerlink" title="训练参数 (train.py)"></a>训练参数 (train.py)</h3><p>| 参数名         | 默认值 | 说明               |<br>|————————|————|——————————|<br>| —seq_len      | 30     | 输入序列长度（帧数） |<br>| —pred_steps   | 10     | 预测步长            |<br>| —hidden_size  | 128    | LSTM隐藏层维度      |<br>| —num_layers   | 3      | LSTM堆叠层数        |</p><h3 id="预测参数-predict-py"><a href="#预测参数-predict-py" class="headerlink" title="预测参数 (predict.py)"></a>预测参数 (predict.py)</h3><p>| 参数名           | 默认值 | 说明               |<br>|—————————|————|——————————|<br>| —observed_ratio | 0.3    | 输入观测比例         |<br>| —predict_steps  | 10     | 预测帧数            |<br>| —line_width     | 2      | 可视化线条粗细      |</p><h2 id="📊-结果示例"><a href="#📊-结果示例" class="headerlink" title="📊 结果示例"></a>📊 结果示例</h2></li></ol><h3 id="轨迹对比图"><a href="#轨迹对比图" class="headerlink" title="轨迹对比图"></a>轨迹对比图</h3><p><img src="path_to_image" alt="prediction"></p><ul><li><strong>蓝色实线</strong>: 实际观测轨迹</li><li><strong>红色虚线</strong>: 模型预测轨迹<h3 id="训练曲线"><a href="#训练曲线" class="headerlink" title="训练曲线"></a>训练曲线</h3></li></ul><p><img src="path_to_image" alt="training_curves"></p><ul><li>左: 训练损失下降曲线</li><li>右: 测试集相对误差</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AtlasChatR1项目</title>
      <link href="/2025/02/02/AtlasChatR1/"/>
      <url>/2025/02/02/AtlasChatR1/</url>
      
        <content type="html"><![CDATA[<h1 id="DeepSeek-R1-1-5B-模型在昇腾-Atlas-200I-DK-A2-上的推理项目"><a href="#DeepSeek-R1-1-5B-模型在昇腾-Atlas-200I-DK-A2-上的推理项目" class="headerlink" title="DeepSeek R1 1.5B 模型在昇腾 Atlas 200I DK A2 上的推理项目"></a>DeepSeek R1 1.5B 模型在昇腾 Atlas 200I DK A2 上的推理项目</h1><p>项目基于 DeepSeek 最新的 R1 1.5B 模型，在昇腾 Atlas 200I DK A2 设备上进行推理，并使用 int8 量化,并将模型转换为 OM 模型以便在板上运行。以下是项目简介。</p><hr><h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>本项目旨在将 DeepSeek R1 1.5B 模型部署到昇腾 Atlas 200I DK A2 设备上，通过 int8 量化优化模型推理性能。项目包含以下主要功能：</p><ol><li><strong>模型导出</strong>：将 DeepSeek R1 1.5B 模型导出为 ONNX 格式。</li><li><strong>模型量化</strong>：将 ONNX 模型量化为 int8 格式。</li><li><strong>模型推理与测评</strong>：在 Atlas 200I DK A2 设备上运行推理，并测评模型的推理速度和显存占用。</li></ol><hr><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><h2 id=""><a href="#" class="headerlink" title=""></a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DeepSeek-Atlas-Chat/</span><br><span class="line">├── export.py # 将 DeepSeek R1 模型导出为 ONNX 格式</span><br><span class="line">├── quant.py # 将 ONNX 模型量化为 int8 格式</span><br><span class="line">├── eval.py # 测评模型推理速度和显存占用</span><br><span class="line">├── onnx_model_output/ # 存放从原始 R1 模型导出的 ONNX 模型</span><br><span class="line">├── deepseek_quant8.onnx # 自动生成的 int8 量化后的 ONNX 模型</span><br><span class="line">└── README.md # 项目说明文档</span><br></pre></td></tr></table></figure></h2><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><ul><li><strong>硬件</strong>：昇腾 Atlas 200I DK A2，理论上也可以在其他310B设备运行</li><li><strong>软件</strong>：<ul><li>Python 3.9 或更高版本</li><li>ONNX 1.10.0 或更高版本</li><li>昇腾 CANN 工具包（推荐版本 8.0.0RC3）</li><li>PyTorch 2.0.0 及以上</li><li>ONNX Runtime（可选，用于本地测试）</li></ul></li></ul><hr><h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><h3 id="1-请先自行下载DeepSeek-R1-Distill-Qwen-1-5B模型"><a href="#1-请先自行下载DeepSeek-R1-Distill-Qwen-1-5B模型" class="headerlink" title="1. 请先自行下载DeepSeek-R1-Distill-Qwen-1.5B模型"></a>1. 请先自行下载DeepSeek-R1-Distill-Qwen-1.5B模型</h3><h3 id="2-导出-ONNX-模型"><a href="#2-导出-ONNX-模型" class="headerlink" title="2. 导出 ONNX 模型"></a>2. 导出 ONNX 模型</h3><p>运行 <code>export.py</code> 脚本，将 DeepSeek R1 1.5B 模型导出为 ONNX 格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python export.py -m /path/to/DeepSeek-R1-Distill-Qwen-1.5B</span><br></pre></td></tr></table></figure><p>若设备支持cuda或者mps，可在运行时加上<code>-d cuda</code>或者<code>-d mps</code></p><h3 id="3-量化-ONNX-模型为-int8-格式"><a href="#3-量化-ONNX-模型为-int8-格式" class="headerlink" title="3. 量化 ONNX 模型为 int8 格式"></a>3. 量化 ONNX 模型为 int8 格式</h3><p>运行 quant.py 脚本，将 ONNX 模型量化为 int8 格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python quant.py</span><br></pre></td></tr></table></figure><p>量化后的模型将保存为 <code>deepseek_quant8.onnx</code></p><h3 id="4-测评模型推理性能"><a href="#4-测评模型推理性能" class="headerlink" title="4. 测评模型推理性能"></a>4. 测评模型推理性能</h3><p>运行 eval.py 脚本，测评模型在 转换量化前后的推理速度：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python eval.py</span><br></pre></td></tr></table></figure><br>得到结果大致如下，设备性能不同可能得到不同的结果，结果符合从fp32到int8的性能提升<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">测试 PyTorch 模型...</span><br><span class="line">PyTorch 模型平均推理时间: 0.2651 秒</span><br><span class="line">PyTorch 模型每秒处理 token 数量: 37.72 tokens/s</span><br><span class="line"></span><br><span class="line">测试 ONNX 模型...</span><br><span class="line">ONNX 模型平均推理时间: 0.0611 秒</span><br><span class="line">ONNX 模型每秒处理 token 数量: 163.77 tokens/s</span><br><span class="line"></span><br><span class="line">ONNX 模型相较于 PyTorch 模型推理速度提升: 4.34 倍</span><br></pre></td></tr></table></figure></p><h3 id="5-部署算子"><a href="#5-部署算子" class="headerlink" title="5. 部署算子"></a>5. 部署算子</h3><p>因为<code>cann</code>的算子清单中没有<code>MatMulIntegar</code>,<code>DynamicQuantizeLinear</code>,<code>DequantizeLinear</code>算子，所以就需要自己将算子补上，否则atc工具无法转换成om模型，后续的推理也无法正常运行<br>首先安装<code>protoc</code>，这是算子部署build.sh需要的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装protoc==1.13.0, 找一空闲目录下载</span></span><br><span class="line">wget  https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/wanzutao/tiny-llama/protobuf-all-3.13.0.tar.gz</span><br><span class="line">tar -zxvf protobuf-all-3.13.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> protobuf-3.13.0</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install autoconf automake libtool</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure</span><br><span class="line">make -j4</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">sudo</span> ldconfig</span><br><span class="line">protoc --version <span class="comment"># 查看版本号</span></span><br></pre></td></tr></table></figure></p><p>随后部署算子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> matmul_integer_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cp</span> dynamic_quantize_linear_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cp</span> dequantize_linear_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx </span><br></pre></td></tr></table></figure><br>打开<code>build.sh</code>，添加如下四个环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ASCEND_TENSOR_COMPILER_INCLUDE=/usr/local/Ascend/ascend-toolkit/latest/include</span><br><span class="line"><span class="built_in">export</span> TOOLCHAIN_DIR=/usr</span><br><span class="line"><span class="built_in">export</span> AICPU_KERNEL_TARGET=cust_aicpu_kernels</span><br><span class="line"><span class="built_in">export</span> AICPU_SOC_VERSION=Ascend310B4</span><br></pre></td></tr></table></figure><br>编译部署算子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./build.sh </span><br><span class="line"><span class="built_in">cd</span> build_out/</span><br><span class="line">./custom_opp_ubuntu_aarch64.run</span><br></pre></td></tr></table></figure></p><h3 id="6-转换-ONNX-模型为-OM-模型"><a href="#6-转换-ONNX-模型为-OM-模型" class="headerlink" title="6. 转换 ONNX 模型为 OM 模型"></a>6. 转换 ONNX 模型为 OM 模型</h3><p>使用昇腾 ATC 工具将量化后的 ONNX 模型转换为 OM 模型：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">atc --model=/root/AtlasChatR1/modified_model.onnx \</span><br><span class="line">    --framework=5 \</span><br><span class="line">    --output=deepseek_om_model \</span><br><span class="line">    --input_format=ND \</span><br><span class="line">    --input_shape=<span class="string">&quot;input_ids:-1,-1;attention_mask:-1,-1&quot;</span> \</span><br><span class="line">    --dynamic_dims=<span class="string">&quot;1,64,1,64;8,128,8,128;16,256,16,256&quot;</span> \</span><br><span class="line">    --soc_version=Ascend310B4 \</span><br><span class="line">    --precision_mode=allow_fp32_to_fp16</span><br></pre></td></tr></table></figure><br>这一步的时间会很长，耐心等待</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> Ascend </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AI-Mario项目</title>
      <link href="/2024/12/23/AI-Mario/"/>
      <url>/2024/12/23/AI-Mario/</url>
      
        <content type="html"><![CDATA[<h1 id="超级马里奥-DQN-智能体"><a href="#超级马里奥-DQN-智能体" class="headerlink" title="超级马里奥 DQN 智能体"></a>超级马里奥 DQN 智能体</h1><p>该项目实现了一个使用 <strong>DQN</strong> 的智能体来玩 <strong>超级马里奥</strong>。智能体通过强化学习来最大化奖励，并学习在环境中采取最优动作。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><strong>Gym Super Mario Bros 环境</strong>：使用 gym-super-mario-bros 库创建马里奥环境。</li><li><strong>DQN</strong>：使用 PyTorch 实现 DQN 训练智能体。</li><li><strong>经验回放缓冲区</strong>：存储和采样游戏状态以稳定训练过程。</li><li><strong>目标网络（Target Network）</strong>：使用单独的目标网络来提高训练的稳定性。</li><li><strong>Epsilon-贪婪策略</strong>：在训练过程中平衡探索与利用。<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2></li></ul><ol><li>克隆本仓库：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/xxxkkw/AI-Mario.git</span><br></pre></td></tr></table></figure></li><li>安装所需的依赖：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>注：这里一定严格按照环境内的版本，要不然有bug<h3 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h3></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">├── models/                 <span class="comment"># 保存的模型将存储在这里</span></span><br><span class="line">├── train.py                <span class="comment"># 主要训练脚本</span></span><br><span class="line">├── agent.py                <span class="comment"># DQN 智能体实现</span></span><br><span class="line">├── run.py                  <span class="comment"># 测试游戏</span></span><br><span class="line">├── replay_buffer.py        <span class="comment"># 经验回放缓冲区</span></span><br><span class="line">├── config.py               <span class="comment"># 超参数配置文件</span></span><br><span class="line">├── init_env.py             <span class="comment"># 马里奥环境设置和包装</span></span><br><span class="line">├── requirements.txt        <span class="comment"># Python 依赖库</span></span><br><span class="line">├── final_model1-1.dat      <span class="comment"># 模型文件</span></span><br><span class="line">├── final_model1-2.dat      <span class="comment"># 模型文件</span></span><br><span class="line">└── README.md               <span class="comment"># 项目文档</span></span><br></pre></td></tr></table></figure><ol><li>使用前必读：<br>项目内置已经训练好的一个模型，可以使用<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run.py</span><br></pre></td></tr></table></figure>来尝试玩一下已经训练好的模型。如果你想自己从头开始训练模型，只需要<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>这样就能从头开始训练属于你的模型了.想玩别的关卡或者训练别的关卡，只需在命令行中输入时添加—level参数即可<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --level 1-1</span><br></pre></td></tr></table></figure>或者已经把某个模型训练到了一半，想继续训练，只需<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model path_to_your_model</span><br></pre></td></tr></table></figure>此外，项目内置两个关卡的模型，1-1以及1-2，可以体验一下<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run.py --level 1-2</span><br></pre></td></tr></table></figure>玩的开心！</li></ol>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，CRC代码</title>
      <link href="/2024/11/28/CRC/"/>
      <url>/2024/11/28/CRC/</url>
      
        <content type="html"><![CDATA[<p>代码实现了CRC（循环冗余校验）编码和解码的过程，应用于RFID实验中。在通信系统中，CRC是一种常用的错误检测技术，能够帮助检测传输数据中的误码。代码首先定义了消息比特和生成多项式，然后进行多项式除法来计算CRC校验码，并将其附加到原始消息比特中，生成编码后的帧。随后通过模拟接收到的码字进行CRC解码，检测接收数据是否存在误码。最后，代码通过图形化展示了编码前后的消息比特序列，以及是否存在错误的检测结果。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">L = <span class="number">16</span>;                       <span class="comment">%一帧中的消息比特个数</span></span><br><span class="line">poly = [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];         <span class="comment">%%此参数代表CRC编码使用的生成多项式，这里是x^4 + x^2 + x + 1</span></span><br><span class="line">N1 = <span class="built_in">length</span>(poly)<span class="number">-1</span>;          <span class="comment">%%此参数代表生成多项式的次数，用于确定消息比特左移的位数</span></span><br><span class="line"><span class="comment">%msg = randi([0 1], 1, L);      %消息比特（这里使用了自定义的消息比特序列代替随机生成）</span></span><br><span class="line">msg = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>];</span><br><span class="line">msg1 = [msg <span class="built_in">zeros</span>(<span class="number">1</span>,N1)];     <span class="comment">%消息比特左移，为后续的除法运算做准备，左移的位数等于生成多项式的次数</span></span><br><span class="line">[q,r]=deconv(msg1,poly);    <span class="comment">%%此过程是进行多项式除法，msg1为被除数（左移后的消息比特序列），poly为除数（生成多项式），q为商，r为余数</span></span><br><span class="line">r = <span class="built_in">mod</span>(<span class="built_in">abs</span>(r),<span class="number">2</span>);            <span class="comment">%%此过程是对余数进行模2运算，确保结果为0或1，符合CRC编码在GF(2)上的运算规则</span></span><br><span class="line">crc = r(L + <span class="number">1</span>:<span class="keyword">end</span>);             <span class="comment">%%此参数代表提取出的CRC校验码，即余数的后N1位</span></span><br><span class="line">frame = [msg crc];            <span class="comment">%%此参数代表构建的编码后的帧，由原始消息比特和CRC校验码组成</span></span><br><span class="line"><span class="comment">% 假设接收到的码字是frame，进行CRC解码</span></span><br><span class="line">rec_frame = frame; </span><br><span class="line">[q1,r1]=deconv([rec_frame <span class="built_in">zeros</span>(<span class="number">1</span>,N1)],poly); </span><br><span class="line">r1 = <span class="built_in">mod</span>(<span class="built_in">abs</span>(r1),<span class="number">2</span>);</span><br><span class="line">msg</span><br><span class="line">frame</span><br><span class="line">r1</span><br><span class="line"><span class="comment">%画图显示</span></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">stem(msg)</span><br><span class="line">title(<span class="string">&#x27;编码器输入信号&#x27;</span>)</span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">stem(frame)</span><br><span class="line">title(<span class="string">&#x27;编码器输出信号&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span>(all(r1(:) == <span class="number">0</span>))     <span class="comment">%</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">&quot;接收码字没有错误！&quot;</span>)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">&quot;接收码字中有误码！&quot;</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，LinearBlockCode代码</title>
      <link href="/2024/11/28/LinearBlockCode/"/>
      <url>/2024/11/28/LinearBlockCode/</url>
      
        <content type="html"><![CDATA[<p>代码实现了线性分组码（Linear Block Code, LBC）的编码和解码过程，用于RFID实验。线性分组码是一种常见的编码技术，能够帮助检测和纠正传输过程中的误码。</p><h2 id="代码主要流程"><a href="#代码主要流程" class="headerlink" title="代码主要流程"></a>代码主要流程</h2><ol><li><strong>生成矩阵 G</strong>：首先构建生成矩阵 <code>G</code>，用于将原始消息比特映射为编码后的码字。</li><li><strong>编码过程</strong>：定义消息比特矩阵 <code>A</code>，通过矩阵乘法将 <code>A</code> 和生成矩阵 <code>G</code> 相乘，得到编码后的码字 <code>C</code>。</li><li><strong>校验矩阵 H</strong>：通过辅助函数 <code>gen2par</code>，利用生成矩阵 <code>G</code> 生成校验矩阵 <code>H</code>，用于错误检测。</li><li><strong>译码过程</strong>：输入接收到的7位码字，通过与校验矩阵 <code>H</code> 计算综合矢量 <code>S</code>，定位出错误比特位置，并修正错误，输出正确的码字。</li></ol><p>代码不仅实现了编码和译码，还包括错误检测与纠错功能，是RFID通信实验的重要部分。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">gen2par_example</span><span class="params">()</span></span></span><br><span class="line">    clear all;</span><br><span class="line">    G1 = <span class="built_in">eye</span>(<span class="number">4</span>);</span><br><span class="line">    G2 = [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>;</span><br><span class="line">          <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>;</span><br><span class="line">          <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>;</span><br><span class="line">          <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">    G = [G1,G2];</span><br><span class="line">    fprintf(<span class="string">&#x27;生成矩阵为：G= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(G);</span><br><span class="line">    A = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>;];</span><br><span class="line">    fprintf(<span class="string">&#x27;原码为：A= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(A);</span><br><span class="line">    C1 = A*G;</span><br><span class="line">    C = <span class="built_in">mod</span>(C1,<span class="number">2</span>);</span><br><span class="line">    fprintf(<span class="string">&#x27;输出的编码为：C= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(C);</span><br><span class="line">    H = gen2par(G);</span><br><span class="line">    fprintf(<span class="string">&#x27;校验矩阵为：H= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(H);</span><br><span class="line">    <span class="comment">%%以下输入接收到的码字，译出原码</span></span><br><span class="line">    Rev = input(<span class="string">&#x27;请输入7位接收码字，用空格隔开：&#x27;</span>,<span class="string">&#x27;s&#x27;</span>);</span><br><span class="line">    Rev = str2num(Rev);</span><br><span class="line">    S1 = Rev*(H&#x27;);</span><br><span class="line">    S = <span class="built_in">mod</span>(S1,<span class="number">2</span>);</span><br><span class="line">    E = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">7</span>;</span><br><span class="line">        Hi = H(:,[<span class="built_in">i</span>]);</span><br><span class="line">        Sum = S+Hi&#x27;;</span><br><span class="line">        Sum = <span class="built_in">mod</span>(Sum,<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> (all(Sum(:)==<span class="number">0</span>));</span><br><span class="line">            fprintf(<span class="string">&#x27;接收码字中错误码位是第：&#x27;</span>);</span><br><span class="line">            <span class="built_in">disp</span>(<span class="built_in">i</span>);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            E(<span class="number">1</span>, <span class="built_in">i</span>)=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">end</span>;</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line">    Cr = <span class="built_in">mod</span>((Rev + E),<span class="number">2</span>);</span><br><span class="line">    fprintf(<span class="string">&#x27;正确接收码字：Cr=&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(Cr);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">H</span> = <span class="title">gen2par</span><span class="params">(G)</span></span></span><br><span class="line">    [k,n]=<span class="built_in">size</span>(G);</span><br><span class="line">    P = G(:,k + <span class="number">1</span>:n);</span><br><span class="line">    I = <span class="built_in">eye</span>(n - k);</span><br><span class="line">    H = [P&#x27;,I];</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，Parity代码</title>
      <link href="/2024/11/28/Parity/"/>
      <url>/2024/11/28/Parity/</url>
      
        <content type="html"><![CDATA[<p>代码实现了奇偶校验（Parity Check）在RFID实验中的应用，奇偶校验是一种简单但有效的错误检测方法，能够检测传输数据中的单个比特错误。</p><h2 id="代码主要功能"><a href="#代码主要功能" class="headerlink" title="代码主要功能"></a>代码主要功能</h2><ol><li><strong>输入矩阵大小</strong>：用户通过输入行数和列数，生成一个随机的二进制矩阵 <code>A</code>，代表待校验的数据。</li><li><strong>选择奇偶校验类型</strong>：用户可以选择奇校验或偶校验，程序根据选择为每一行数据生成相应的校验位，并将其附加到矩阵的最后一列。</li><li><strong>校验位计算</strong>：<ul><li><strong>偶校验</strong>：如果行中1的个数为奇数，添加校验位1，使得1的个数变为偶数；如果为偶数，则添加0。</li><li><strong>奇校验</strong>：如果行中1的个数为偶数，添加校验位1，使得1的个数变为奇数；如果为奇数，则添加0。</li></ul></li><li><strong>错误检测</strong>：代码通过手动引入错误，然后再次进行奇偶校验，逐行检查数据是否正确，输出检查结果。</li><li><strong>循环操作</strong>：用户可以多次选择不同的校验类型进行实验，直到选择结束校验（输入9）。</li></ol><p>该代码通过奇偶校验位的计算和检测，演示了如何在数据传输过程中发现错误，是RFID实验中基础的错误检测机制之一。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">clear all;<span class="comment">%清除工作空间的所有变量</span></span><br><span class="line">m = input(<span class="string">&#x27;请输入行:&#x27;</span>);<span class="comment">%input(&#x27; &#x27;);用于向计算机输入一个参数 </span></span><br><span class="line">n = input(<span class="string">&#x27;请输入列:&#x27;</span>);</span><br><span class="line">A = randi([<span class="number">0</span> <span class="number">1</span>],m,n)<span class="comment">%randint(m,n)产生的是一个m*n维的矩阵，矩阵的元素或者是0或者是1，是随机的并显示A</span></span><br><span class="line">B=A;<span class="comment">%A暂存在B，</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    A=B;<span class="comment">%避免循环中A中信码改变</span></span><br><span class="line">    sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">    l = input(<span class="string">&#x27;请选择奇偶校验(0:偶校验 1:奇校验 9:结束校验):&#x27;</span>);<span class="comment">%;不回显</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span> || l == <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:n            <span class="comment">%%计算矩阵A中每一行的元素之和，从第1列到第n列</span></span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);<span class="comment">%</span></span><br><span class="line">                x = sum(<span class="built_in">i</span>);<span class="comment">%</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> l == <span class="number">0</span>             <span class="comment">%%选择偶校验（l == 0）的情况下执行的操作</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span> <span class="comment">%</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">1</span>; <span class="comment">%</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">%</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> l == <span class="number">1</span>              <span class="comment">%%选择奇校验（l == 1）的情况下执行的操作</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span><span class="comment">%</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">0</span>;<span class="comment">%</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">1</span>;<span class="comment">%</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span>    </span><br><span class="line">     <span class="keyword">else</span> <span class="keyword">if</span> l == <span class="number">9</span></span><br><span class="line">            fprintf(<span class="string">&#x27;退出校验~\n&#x27;</span>);<span class="comment">%设置显示格式 </span></span><br><span class="line">            <span class="keyword">break</span>;<span class="comment">%跳出循环</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            fprintf(<span class="string">&#x27;非法输入！！\n&#x27;</span>);</span><br><span class="line">            <span class="keyword">continue</span>;<span class="comment">%结束本次循环</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    fprintf(<span class="string">&#x27;补校验位：&#x27;</span>)</span><br><span class="line">    A<span class="comment">%显示加入校验位后的矩阵</span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span>    </span><br><span class="line">       A(<span class="number">1</span>,<span class="number">2</span>) = ~A(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">        sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m          <span class="comment">%%检查添加校验位后的矩阵数据的正确性，逐行检查</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:(n+<span class="number">1</span>)  <span class="comment">%</span></span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);</span><br><span class="line">                x = sum(<span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">0</span>  <span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据正确！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">else</span>   <span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据有错！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">1</span> <span class="comment">%</span></span><br><span class="line">      A(<span class="number">3</span>,<span class="number">1</span>)=~A(<span class="number">3</span>,<span class="number">1</span>);</span><br><span class="line">      A</span><br><span class="line">      sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m    <span class="comment">%%检查添加校验位后的矩阵数据的正确性，逐行检查</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:(n+<span class="number">1</span>)  </span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);</span><br><span class="line">                x = sum(<span class="built_in">i</span>);</span><br><span class="line">           <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span><span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据正确！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">else</span><span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据有错！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span>                  </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>最小生成树模板</title>
      <link href="/2024/11/22/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E6%A8%A1%E6%9D%BF/"/>
      <url>/2024/11/22/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><h2 id="根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）"><a href="#根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）" class="headerlink" title="根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）"></a>根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）</h2><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><pre><code>顶点数nn个顶点边数mm条边信息,格式为：顶点1 顶点2 权值Prim算法的起点v</code></pre><h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><pre><code>输出最小生成树的权值之和</code></pre><p>对两种算法，按树的生长顺序，输出边信息(Kruskal中边顶点按数组序号升序输出)</p><p>题目是标准的Kruskal和Prim的板子，直接往里套就行，关键的是Kruskal和Prim的逻辑。<br>先介绍Kruskal算法。</p><h2 id="kruskal-算法的基本步骤："><a href="#kruskal-算法的基本步骤：" class="headerlink" title="kruskal 算法的基本步骤："></a>kruskal 算法的基本步骤：</h2><h3 id="边的排序："><a href="#边的排序：" class="headerlink" title="边的排序："></a>边的排序：</h3><pre><code>将图中所有的边按权重从小到大排序。</code></pre><h3 id="初始化并查集："><a href="#初始化并查集：" class="headerlink" title="初始化并查集："></a>初始化并查集：</h3><pre><code>使用并查集数据结构来判断两个顶点是否属于同一集合（即是否在同一个连通分量中）。</code></pre><h3 id="逐条检查边："><a href="#逐条检查边：" class="headerlink" title="逐条检查边："></a>逐条检查边：</h3><pre><code>遍历排序后的边，检查该边连接的两个点是否属于不同的连通分量，如果是，则将这条边加入到最小生成树中，合并这两个点成一个连通分量，若这两个点在同一个连通分量中，则加入这条边会形成环，因此跳过这条边。</code></pre><h3 id="停止条件："><a href="#停止条件：" class="headerlink" title="停止条件："></a>停止条件：</h3><pre><code>当加入了 n-1 条边时，最小生成树已经构建完成，其中 n 是图中顶点的数量。</code></pre><h2 id="在代码中的实现是这样的"><a href="#在代码中的实现是这样的" class="headerlink" title="在代码中的实现是这样的"></a>在代码中的实现是这样的</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">int</span> n, m, f[<span class="number">1010</span>], cnt = <span class="number">0</span>, sum = <span class="number">0</span>, won = <span class="number">0</span>;</span><br><span class="line">string s[<span class="number">1010</span>], st;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">edge</span> &#123; <span class="comment">// 这里使用结构体存边，便于排序以及存储以及遍历</span></span><br><span class="line">    <span class="type">int</span> u, v, w;</span><br><span class="line">&#125; tree[<span class="number">2010</span>];</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">cmp</span><span class="params">(edge x, edge y)</span> </span>&#123;  <span class="comment">// 重载运算符，在后续的排序里面会用到</span></span><br><span class="line">    <span class="keyword">return</span> x.w &lt; y.w;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 并查集最核心的操作，查询父节点，也就是用于判断是否在同一联通分量里面</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;   <span class="comment">// 如果x不是自己的父节点</span></span><br><span class="line">    <span class="keyword">if</span> (x != f[x])  <span class="comment">// 递归找到x的根节点，并压缩路径</span></span><br><span class="line">        f[x] = <span class="built_in">find</span>(f[x]);  <span class="comment">// 返回x的根节点</span></span><br><span class="line">    <span class="keyword">return</span> f[x];</span><br><span class="line">&#125;</span><br><span class="line">map&lt;string,<span class="type">int</span>&gt; mp; <span class="comment">//映射节点字符串与编号</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">vis</span><span class="params">(n + <span class="number">1</span>, <span class="literal">false</span>)</span></span>; <span class="comment">// 访问标记数组，记录哪些节点已经加入MST</span></span><br><span class="line"><span class="comment">// Lambda表达式，用于定义优先队列的比较规则：比较边的权重，较小的权重具有较高优先级</span></span><br><span class="line"><span class="keyword">auto</span> edgeCmp = [](edge a, edge b) &#123; <span class="keyword">return</span> a.w &gt; b.w; &#125;;</span><br><span class="line"><span class="comment">// 优先队列，存储边，按权重从小到大排列</span></span><br><span class="line">priority_queue&lt;edge, vector&lt;edge&gt;, <span class="keyword">decltype</span>(edgeCmp)&gt; <span class="built_in">pq</span>(edgeCmp);</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">()</span></span>&#123;  <span class="comment">//建图过程</span></span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i ++)&#123;</span><br><span class="line">        cin &gt;&gt; s[i];</span><br><span class="line">        mp[s[i]] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    cin &gt;&gt; m;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i ++)&#123;</span><br><span class="line">        string u,v;</span><br><span class="line">        <span class="type">int</span> w;</span><br><span class="line">        cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;</span><br><span class="line">        tree[i].u = mp[u];</span><br><span class="line">        tree[i].v = mp[v];</span><br><span class="line">        tree[i].w = w;</span><br><span class="line">     &#125;</span><br><span class="line">    cin &gt;&gt; st;</span><br><span class="line">    <span class="type">int</span> start = mp[st];</span><br><span class="line">    vis[start] = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;  <span class="comment">// 将所有与起点相连的边加入优先队列</span></span><br><span class="line">        <span class="keyword">if</span> (tree[i].u == start || tree[i].v == start) &#123;</span><br><span class="line">            pq.<span class="built_in">push</span>(tree[i]);  <span class="comment">// 将起点相连的所有边压入优先队列</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">kruskal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;kruskal:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;  <span class="comment">// 初始化并查集，f[i]表示第i个顶点的父节点</span></span><br><span class="line">        f[i] = i;  <span class="comment">// 每个节点的父节点初始化为自己</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">sort</span>(tree + <span class="number">1</span>, tree + m + <span class="number">1</span>, cmp);  <span class="comment">// 对所有的边按权重进行升序排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;  <span class="comment">// 遍历所有的边，选择不形成环的边加入MST</span></span><br><span class="line">        <span class="type">int</span> e1 = <span class="built_in">find</span>(tree[i].u), e2 = <span class="built_in">find</span>(tree[i].v);  <span class="comment">// 找到这条边的两个顶点的根</span></span><br><span class="line">        <span class="keyword">if</span> (e1 != e2) &#123;  <span class="comment">// 如果这两个顶点不在同一个连通分量中</span></span><br><span class="line">            f[e1] = e2;  <span class="comment">// 合并这两个集合</span></span><br><span class="line">            <span class="comment">// 输出这条边</span></span><br><span class="line">            string city1 = s[tree[i].u];</span><br><span class="line">            string city2 = s[tree[i].v];</span><br><span class="line">            <span class="keyword">if</span> (city1 &gt; city2) <span class="built_in">swap</span>(city1, city2);</span><br><span class="line">            cout &lt;&lt; city1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; city2 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; tree[i].w &lt;&lt; endl;</span><br><span class="line">            sum += tree[i].w;  <span class="comment">// 累加权重</span></span><br><span class="line">            cnt++;  <span class="comment">// 增加已加入的边数</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (cnt == n - <span class="number">1</span>) &#123;</span><br><span class="line">            won = <span class="number">1</span>;  <span class="comment">// 如果已加入 n-1 条边，则完成了MST</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Prim算法步骤"><a href="#Prim算法步骤" class="headerlink" title="Prim算法步骤"></a>Prim算法步骤</h2><h3 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h3><pre><code>vis：这是一个访问标记数组，用来标记哪些顶点已经被加入到MST。它的大小为 n+1，初始值全为 false。edgeCmp：这是一个比较函数，定义了优先队列的排序规则，优先选择权重较小的边。pq：这是一个优先队列，存储边的类型 edge。它按照 edge.w 从小到大排序。</code></pre><h3 id="选择起点："><a href="#选择起点：" class="headerlink" title="选择起点："></a>选择起点：</h3><pre><code>通过 find_idx(st) 找到用户输入的起点在 s[] 中的索引 start。标记起点为已访问：vis[start] = true。遍历所有边，将与起点相连的边压入优先队列 pq。</code></pre><h3 id="循环处理优先队列："><a href="#循环处理优先队列：" class="headerlink" title="循环处理优先队列："></a>循环处理优先队列：</h3><pre><code>从优先队列中不断取出当前权重最小的边 currentEdge。通过 currentEdge.u 和 currentEdge.v 获取这条边的两个顶点。如果 u 和 v 都已经被访问（即它们已经在MST中），则跳过这条边，因为加入这条边会形成环。如果其中一个顶点未被访问，则确定要加入MST的顶点（next），并将它标记为已访问。</code></pre><h3 id="输出："><a href="#输出：" class="headerlink" title="输出："></a>输出：</h3><pre><code>根据字典顺序输出加入MST的边的两个顶点和对应的权重。若 city1 的字典顺序比 city2 大，则交换两者，保证输出时小的顶点在前。</code></pre><h3 id="更新优先队列："><a href="#更新优先队列：" class="headerlink" title="更新优先队列："></a>更新优先队列：</h3><pre><code>遍历所有边，将与刚加入MST的顶点 next 相连且另一端未访问的边加入优先队列。</code></pre><h3 id="继续循环："><a href="#继续循环：" class="headerlink" title="继续循环："></a>继续循环：</h3><pre><code>不断重复从优先队列中取出最小边、加入MST、更新优先队列的过程，直到优先队列为空或者所有顶点都被访问。</code></pre><h2 id="代码实现如下"><a href="#代码实现如下" class="headerlink" title="代码实现如下"></a>代码实现如下</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">prim</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;prim:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">while</span> (!pq.<span class="built_in">empty</span>()) &#123; <span class="comment">// 开始处理优先队列中的边</span></span><br><span class="line">        <span class="comment">// 取出优先队列中权重最小的边</span></span><br><span class="line">        edge currentEdge = pq.<span class="built_in">top</span>();</span><br><span class="line">        pq.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="type">int</span> u = currentEdge.u;  <span class="comment">// 当前边的起点</span></span><br><span class="line">        <span class="type">int</span> v = currentEdge.v;  <span class="comment">// 当前边的终点</span></span><br><span class="line">        <span class="type">int</span> w = currentEdge.w;  <span class="comment">// 当前边的权重</span></span><br><span class="line">        <span class="comment">// 如果u和v都已经在MST中，跳过这条边，因为它会形成环</span></span><br><span class="line">        <span class="keyword">if</span> (vis[u] &amp;&amp; vis[v]) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="comment">// 确定下一个要加入MST的顶点（u或v中尚未访问的那个）</span></span><br><span class="line">        <span class="type">int</span> next = vis[u] ? v : u;</span><br><span class="line">        <span class="comment">// 标记这个顶点为已访问</span></span><br><span class="line">        vis[next] = <span class="literal">true</span>;</span><br><span class="line">        string city1 = s[u];</span><br><span class="line">        string city2 = s[v];</span><br><span class="line">        cout &lt;&lt; city1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; city2 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; w &lt;&lt; endl;</span><br><span class="line">        sum += w; <span class="comment">// 将这条边的权重加到总权重上</span></span><br><span class="line">        <span class="comment">// 遍历所有边，将与新加入顶点相连且未访问过的顶点加入优先队列</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;</span><br><span class="line">            <span class="comment">// 如果这条边连接的顶点之一是刚加入MST的顶点，且另一端尚未加入MST</span></span><br><span class="line">            <span class="keyword">if</span> ((tree[i].u == next &amp;&amp; !vis[tree[i].v]) ||</span><br><span class="line">                (tree[i].v == next &amp;&amp; !vis[tree[i].u])) &#123;</span><br><span class="line">                pq.<span class="built_in">push</span>(tree[i]);  <span class="comment">// 将这条边压入优先队列</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二叉树构建与遍历</title>
      <link href="/2024/10/21/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/"/>
      <url>/2024/10/21/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/</url>
      
        <content type="html"><![CDATA[<p>给出一颗二叉树的逻辑结构，并且建立该二叉树的二叉链式存储结构，分别输出二叉树的先序，中序，后序遍历<br>构建的整体思路就是依靠递归，分别构建左右子树，不为空就继续往下构建子树，直到结束<br>遍历也是差不多的思路，从根节点开始，不为空就继续向下递归，前中后只是输出的顺序不一样，本质上来说遍历的时候经过都是一样的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//节点的基本组成，包含本节点数据，左右子树的指针</span></span><br><span class="line">    <span class="type">char</span> data;</span><br><span class="line">    Node *lch;</span><br><span class="line">    Node *rch;</span><br><span class="line">    Node *parent;</span><br><span class="line">    <span class="built_in">Node</span>(<span class="type">char</span> c) : <span class="built_in">data</span>(c), <span class="built_in">lch</span>(<span class="literal">NULL</span>), <span class="built_in">rch</span>(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TREE</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Node* root;</span><br><span class="line">    ll pos;</span><br><span class="line">    string tree_str;</span><br><span class="line">    <span class="built_in">TREE</span>() : <span class="built_in">root</span>(<span class="literal">NULL</span>), <span class="built_in">pos</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">create_tree</span><span class="params">(<span class="type">const</span> string&amp; s)</span> </span>&#123;</span><br><span class="line">        pos = <span class="number">0</span>;</span><br><span class="line">        tree_str = s;</span><br><span class="line">        root = <span class="built_in">create</span>(); <span class="comment">//这里就是从根节点开始往下</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Node* <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//递归构建子树</span></span><br><span class="line">        <span class="keyword">if</span>(pos &gt;= tree_str.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        <span class="type">char</span> c = tree_str[pos++];</span><br><span class="line">        <span class="keyword">if</span> (c == <span class="string">&#x27;#&#x27;</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        Node* node = <span class="keyword">new</span> <span class="built_in">Node</span>(c);</span><br><span class="line">        node-&gt;lch = <span class="built_in">create</span>();</span><br><span class="line">        node-&gt;rch = <span class="built_in">create</span>();</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">pre</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//先序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">        <span class="built_in">pre</span>(node-&gt;lch);</span><br><span class="line">        <span class="built_in">pre</span>(node-&gt;rch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">in</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//中序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="built_in">in</span>(node-&gt;lch);</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">        <span class="built_in">in</span>(node-&gt;rch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">post</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//后序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="built_in">post</span>(node-&gt;lch);</span><br><span class="line">        <span class="built_in">post</span>(node-&gt;rch);</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">pre</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">        <span class="built_in">in</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">        <span class="built_in">post</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">leaves</span><span class="params">(Node* p)</span> </span>&#123;  <span class="comment">//这里顺便放上遍历叶子节点的函数</span></span><br><span class="line">        <span class="keyword">if</span> (p) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!p-&gt;lch &amp;&amp; !p-&gt;rch)</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">leaves</span>(p-&gt;lch);</span><br><span class="line">            <span class="built_in">leaves</span>(p-&gt;rch);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Parents</span><span class="params">(Node* p)</span> </span>&#123;  <span class="comment">//遍历父节点</span></span><br><span class="line">        <span class="keyword">if</span> (p) &#123;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;lch &amp;&amp; (!p-&gt;lch-&gt;lch &amp;&amp; !p-&gt;lch-&gt;rch))</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">Parents</span>(p-&gt;lch);</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;rch &amp;&amp; (!p-&gt;rch-&gt;lch &amp;&amp; !p-&gt;rch-&gt;rch))</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">Parents</span>(p-&gt;rch);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    ll t;</span><br><span class="line">    cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">while</span> (t--) &#123;</span><br><span class="line">        string s;</span><br><span class="line">        cin &gt;&gt; s;</span><br><span class="line">        TREE tree;</span><br><span class="line">        tree.<span class="built_in">create_tree</span>(s);</span><br><span class="line">        tree.<span class="built_in">display</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AscendC算子中级认证--指导向</title>
      <link href="/2024/10/21/AscendC%E7%AE%97%E5%AD%90%E4%B8%AD%E7%BA%A7%E8%AE%A4%E8%AF%81--%E6%8C%87%E5%AF%BC%E5%90%91/"/>
      <url>/2024/10/21/AscendC%E7%AE%97%E5%AD%90%E4%B8%AD%E7%BA%A7%E8%AE%A4%E8%AF%81--%E6%8C%87%E5%AF%BC%E5%90%91/</url>
      
        <content type="html"><![CDATA[<p>AscendC算子中级认证的题目是模拟numpy中的sinh算子，编写基于AscendC的算子sinh，命名为sinhCustom，并编写kernel侧代码，host侧代码，使用aclnn算子调用测试<br>sinh的算法实现为： sinh(x) = (exp(x) - exp(-x)) / 2.0<br>首先在kernel侧，完成sinh_custom.cpp文件<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;                        <span class="comment">//开启双缓冲，实现流水并行</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSinh</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSinh</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123; <span class="comment">// 获取host侧传入的tiling参数，尽量避免在kernel侧计算</span></span><br><span class="line">        TilingData tiling_data;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">        totalLength = tiling_data.totalLength;          <span class="comment">// 总数据长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;            <span class="comment">// 单tile长度，也就是根据ub确定下来的每次能处理的最大长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;              <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;                  <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR z, GM_ADDR tiling, TPipe* pipeIn)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化全局内存，获取host侧传入的x和z的地址以及数据长度，单核场景下无需考虑地址偏移</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X *)x, <span class="keyword">this</span>-&gt;totalLength);     </span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Z *)z, <span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">        pipe = pipeIn;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化队列，队列大小对应的每次能计算的数据量，大小为：数据类型 * 每次能计算的数据量 * 队列大小</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));     </span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Z));</span><br><span class="line">        <span class="comment">// 初始化计算所需的临时内存，大小为：数据类型 * 每次能计算的数据量</span></span><br><span class="line">        <span class="comment">// 这里因为是临时内存，所以无需考虑双缓冲，因为获取时就在核心内</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer4, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// loopCount为计算次数，在数据量较大时，核心装不下所有的数据，所以就需要分块计算</span></span><br><span class="line">        <span class="comment">// 每块的大小为tileLength，最后的尾块的长度为leftNum</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123; </span><br><span class="line">            <span class="built_in">CopyIn</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 拷贝输入数据到队列中</span></span><br><span class="line">    <span class="comment">// 这里的progress是计算次数，length是每次能计算的数据量</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="built_in">AllocTensor</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">        inQueueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心计算函数，取决于具体的算子实现</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="built_in">DeQue</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_Z&gt; zLocal = outQueueZ.<span class="built_in">AllocTensor</span>&lt;DTYPE_Z&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor1 = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor2 = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor3 = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor4 = tmpBuffer<span class="number">4.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        </span><br><span class="line">        DTYPE_X inputVal1 = <span class="number">-1</span>;</span><br><span class="line">        DTYPE_X inputVal2 = <span class="number">0.5</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">Muls</span>(tmpTensor1, xLocal, inputVal1, length);</span><br><span class="line">        <span class="built_in">Exp</span>(tmpTensor2, tmpTensor1, length);</span><br><span class="line">        <span class="built_in">Exp</span>(tmpTensor3, xLocal, length);</span><br><span class="line">        <span class="built_in">Sub</span>(tmpTensor4, tmpTensor3, tmpTensor2, length);</span><br><span class="line">        <span class="built_in">Muls</span>(zLocal, tmpTensor4, inputVal2, length);</span><br><span class="line">        </span><br><span class="line">        outQueueZ.<span class="built_in">EnQue</span>&lt;DTYPE_Z&gt;(zLocal);</span><br><span class="line">        inQueueX.<span class="built_in">FreeTensor</span>(xLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拷贝输出数据到全局内存中</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_Z&gt; zLocal = outQueueZ.<span class="built_in">DeQue</span>&lt;DTYPE_Z&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * <span class="keyword">this</span>-&gt;tileLength], zLocal, length);</span><br><span class="line">        outQueueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 一些初始化</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    GlobalTensor&lt;DTYPE_X&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_Z&gt; zGm;</span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1, tmpBuffer2, tmpBuffer3, tmpBuffer4;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> totalLength;</span><br><span class="line">    <span class="type">uint64_t</span> tileLength;</span><br><span class="line">    <span class="type">uint64_t</span> loopCount;</span><br><span class="line">    <span class="type">uint64_t</span> leftNum;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">sinh_custom</span><span class="params">(GM_ADDR x, GM_ADDR z, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    KernelSinh op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, z, tiling, &amp;pipe);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>接下来是host侧的文件<br>sinh_custom.cpp的修改：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sinh_custom_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算向上32对齐</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32U</span><span class="params">(<span class="type">uint32_t</span> n,<span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 数据向下32对齐</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">31</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  </span><br><span class="line">    SinhCustomTilingData tiling;</span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">//数据总长度</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    totalLength = <span class="built_in">align32U</span>(totalLength,sizeofdatatype);              <span class="comment">// 数据向上32B对齐，这里是因为在Gm中地址必须32B对齐</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*  </span></span><br><span class="line"><span class="comment">        向下32对齐的最大分块长度，这里需要基于ub的大小，再根据在kernel侧计算时所有所需的空间大小来确定</span></span><br><span class="line"><span class="comment">        这里的计算方式是：分块长度为tilelength，单个队列所需的空间大小为 tileLength * BufferNum * sizeofdatatype</span></span><br><span class="line"><span class="comment">        再考虑上所需要的临时空间的大小，这里的临时空间大小为：tileLength * sizeofdatatype</span></span><br><span class="line"><span class="comment">        所以在这个算子中，所需的空间大小为：tilelength * BufferNum * sizeofdatatype * 2 +</span></span><br><span class="line"><span class="comment">        tileLength * sizeofdatatype * 4 = tileLength * (2 * 2 * 2 + 4 * 2) = tileLength * 16</span></span><br><span class="line"><span class="comment">        实际计算过程中需要将这个数向下取整，防止超出Ub的大小</span></span><br><span class="line"><span class="comment">        这里的ub_size是根据不同的处理器来确定的，这里以Ascend310B为例，ub_size为253952B</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">16</span>,sizeofdatatype);     </span><br><span class="line">    tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">    <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">    <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">    tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">    tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">    tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">    tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// Gm总地址32B对齐</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">    <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">    <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">    <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">    <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(<span class="number">1</span>);</span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SinhCustom</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//这里是msopgen自动生成的，表明数据的输入输出的类型还有具体有哪些输入输出</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">SinhCustom</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;z&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>); <span class="comment">//具体放在什么处理器上运行</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(SinhCustom);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>sinh_custom_tilling.h文件：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这里主要就是定义一下</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(SinhCustomTilingData)</span><br><span class="line">  <span class="comment">//增加类对象</span></span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);</span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(SinhCustom, SinhCustomTilingData)</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>至于在AscendC中为什么要分为Gm以及Ub，这里简单解释一下：<br>Gm是全局内存，用于存放完整的输入输出数据，而Ub是核心内临时存储空间，它的大小很有限，所以需要将输入输出数据分成小块来处理，每次分块大小的根据就是基于Ub的实际大小以及每次计算过程中所需要的空间来分配，尽可能的提升计算效率。此外，还有一些关于广播等的操作，以后再补充。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AscendC算子</title>
      <link href="/2024/10/20/AscendC%E7%AE%97%E5%AD%90/"/>
      <url>/2024/10/20/AscendC%E7%AE%97%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>AscendC算子原生支持C和C++标准规范,主要运行在Ascend系列产品上。因为是直接运行在npu上的算子函数，所以涉及到比较多的内存处理，包括一些数据搬移，内存管理，队列管理，还是比较的繁琐，但好在官方提供了编程范式，只需要按照所给的框架就能完成算子的实现。<br>开发者主要做的就是确定任务，设计算子，实现计算功能。<br>明确矢量算子的输入以及输出。Ascend C提供的矢量计算接口的操作元素都为LocalTensor，输入数据需要先搬运进AI Core的内部存储Local Memory，然后使用自定义Compute函数计算接口完成，得到最终结果，再搬出到外部存储Global Memory上。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TOTAL_LENGTH = <span class="number">8</span> * <span class="number">2048</span>;                            <span class="comment">// total length of data</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> USE_CORE_NUM = <span class="number">8</span>;                                   <span class="comment">// num of core used</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BLOCK_LENGTH = TOTAL_LENGTH / USE_CORE_NUM;         <span class="comment">// length computed of each core</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TILE_NUM = <span class="number">8</span>;                                       <span class="comment">// split data into 8 tiles for each core</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;                                     <span class="comment">// tensor num for each queue</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TILE_LENGTH = BLOCK_LENGTH / TILE_NUM / BUFFER_NUM; <span class="comment">// seperate to 2 parts, due to double buffer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAdd</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span> <span class="comment">//初始化输入输出</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)x + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)y + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)z + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueY, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> <span class="comment">//实现流水操作</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int32_t</span> loopCount = TILE_NUM * BUFFER_NUM;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; loopCount; i++) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i);</span><br><span class="line">            <span class="built_in">Compute</span>(i);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//数据拷贝，入队</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; xLocal = inQueueX.<span class="built_in">AllocTensor</span>&lt;half&gt;();</span><br><span class="line">        LocalTensor&lt;half&gt; yLocal = inQueueY.<span class="built_in">AllocTensor</span>&lt;half&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * TILE_LENGTH], TILE_LENGTH);</span><br><span class="line">        <span class="built_in">DataCopy</span>(yLocal, yGm[progress * TILE_LENGTH], TILE_LENGTH);</span><br><span class="line">        inQueueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">        inQueueY.<span class="built_in">EnQue</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//核心计算过程，算法实现最核心的部分</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; xLocal = inQueueX.<span class="built_in">DeQue</span>&lt;half&gt;(); <span class="comment">//这两个LocalTensor就是实际函数的输入值，通过一系列数据搬移到了这，开始计算</span></span><br><span class="line">        LocalTensor&lt;half&gt; yLocal = inQueueY.<span class="built_in">DeQue</span>&lt;half&gt;();</span><br><span class="line">        LocalTensor&lt;half&gt; zLocal = outQueueZ.<span class="built_in">AllocTensor</span>&lt;half&gt;(); <span class="comment">//初始化输出对象，等下准备丢进输出队列</span></span><br><span class="line">        <span class="built_in">Add</span>(zLocal, xLocal, yLocal, TILE_LENGTH);</span><br><span class="line">        outQueueZ.<span class="built_in">EnQue</span>&lt;half&gt;(zLocal); <span class="comment">//在这里丢进输出队列</span></span><br><span class="line">        inQueueX.<span class="built_in">FreeTensor</span>(xLocal); <span class="comment">//释放空间</span></span><br><span class="line">        inQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//数据搬出</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; zLocal = outQueueZ.<span class="built_in">DeQue</span>&lt;half&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * TILE_LENGTH], zLocal, TILE_LENGTH);</span><br><span class="line">        outQueueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX, inQueueY;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    GlobalTensor&lt;half&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;half&gt; yGm;</span><br><span class="line">    GlobalTensor&lt;half&gt; zGm;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span> <span class="comment">//核函数，作为整个功能的接口</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    KernelAdd op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, z);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于yolov5的羽毛球轨迹识别</title>
      <link href="/2024/10/18/yolov5/"/>
      <url>/2024/10/18/yolov5/</url>
      
        <content type="html"><![CDATA[<p>yolov5是一种很流行的目标检测系统，基于这套系统，我们可以很轻松的开发各种识别物体的项目，不过需要自己准备数据集，以及一定的计算资源。<br>本质上来说，yolov5也是一个基于深度学习的视觉识别系统，效果很不错，就省去了自己开发的过程。同时还可以在源代码上修改，来实现自己的需求。<br>首先从部署yolov5开始：<br>部署的环境是基于python的，为了方便管理，我们使用anaconda创建一个新的虚拟环境，以便跟别的环境隔离开，这样就不会冲突。<br>在命令行中输入<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n yolov5 python=3.10</span><br></pre></td></tr></table></figure><br>然后再输入<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate yolov5</span><br></pre></td></tr></table></figure><br>这样就创建好并且进入了一个新的环境内。接下来克隆官方仓库并且安装依赖项<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ultralytics/yolov5</span><br><span class="line">cd yolov5</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><br>如果有N卡的话还得下载对应的cuda<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br></pre></td></tr></table></figure><br>到这里yolov5的环境就配置好了。随便跑点样例实验一下。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --device 0</span><br></pre></td></tr></table></figure><br>这就是一个最简单的训练的代码，使用的是官方的数据集，训练后的模型存储在 runs/train/exp/weights/best.pt<br>尝试用模型检测一下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python detect.py --device 0</span><br></pre></td></tr></table></figure><br>检测的结果会在 runs/detect/exp中<br>上面是一些比较简单的配置还有验证的过程，接下来的是最重要的，想要对一个物体进行识别，首先得有数据集，然后基于这个数据集进行训练，因为网上实在没有羽毛球的模型，我就自己框了大概1500张图，分割三分之一作为验证集，剩下的作为训练集。框图可以用这个<a href="http://makesense.bimant.com/">网站</a><br>框图之后会得到一份标签集，可以使用下面的代码分割训练集验证集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line">image_folder = <span class="string">&#x27;path/to/images&#x27;</span>  <span class="comment"># 图片文件夹路径</span></span><br><span class="line">label_folder = <span class="string">&#x27;path/to/labels&#x27;</span>  <span class="comment"># 标签文件夹路径</span></span><br><span class="line"></span><br><span class="line">val_image_folder = <span class="string">&#x27;path/to/val_images&#x27;</span>  <span class="comment"># 验证集图片存放路径</span></span><br><span class="line">val_label_folder = <span class="string">&#x27;path/to/val_labels&#x27;</span>  <span class="comment"># 验证集标签存放路径</span></span><br><span class="line"></span><br><span class="line">os.makedirs(val_image_folder, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(val_label_folder, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">image_files = <span class="built_in">sorted</span>(os.listdir(image_folder))</span><br><span class="line">label_files = <span class="built_in">sorted</span>(os.listdir(label_folder))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(image_files) != <span class="built_in">len</span>(label_files):</span><br><span class="line"><span class="keyword">raise</span> ValueError(<span class="string">&quot;图片和标签数量不匹配！请检查文件夹内容。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, image_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(image_files):</span><br><span class="line"><span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">3</span> == <span class="number">0</span>:  <span class="comment"># 每三张图片选一张</span></span><br><span class="line"><span class="comment"># 获取对应的标签文件名</span></span><br><span class="line">label_file = label_files[i]</span><br><span class="line"></span><br><span class="line">        image_path = os.path.join(image_folder, image_file)</span><br><span class="line">        label_path = os.path.join(label_folder, label_file)</span><br><span class="line">        </span><br><span class="line">        shutil.move(image_path, os.path.join(val_image_folder, image_file))</span><br><span class="line">        shutil.move(label_path, os.path.join(val_label_folder, label_file))</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;验证集划分完成！&quot;</span>)</span><br></pre></td></tr></table></figure><br>然后再对分割好的数据集去训练<br>下面是基于项目需求，对代码的修改<br>首先添加一个元组，并且生成一个背景，用于绘制我们的轨迹<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_centers = []</span><br><span class="line">canvas = np.ones((im0s.shape[<span class="number">0</span>], im0s.shape[<span class="number">1</span>], <span class="number">3</span>), dtype=np.uint8) * <span class="number">255</span></span><br></pre></td></tr></table></figure><br>用来存储我们识别到的羽毛球在空间中的坐标<br>然后在识别到目标之后，把原代码的框选修改为点<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_center = (xyxy[<span class="number">0</span>] + xyxy[<span class="number">2</span>]) / <span class="number">2</span></span><br><span class="line">y_center = (xyxy[<span class="number">1</span>] + xyxy[<span class="number">3</span>]) / <span class="number">2</span></span><br><span class="line"><span class="comment">#LOGGER.info(&quot;x_center: %f, y_center: %f&quot;, x_center, y_center)</span></span><br><span class="line">all_centers.append((x_center, y_center))</span><br><span class="line">radius = <span class="number">10</span></span><br><span class="line">color = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">cv2.circle(imc, (<span class="built_in">int</span>(x_center), <span class="built_in">int</span>(y_center)), radius, color, thickness=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>然后再遍历我们的坐标，将点绘制在背景上<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x_center , y_center <span class="keyword">in</span> all_centers:</span><br><span class="line">    cv2.circle(canvas, (<span class="built_in">int</span>(x_center), <span class="built_in">int</span>(y_center)), <span class="number">10</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">save_path = increment_path(Path(project) / name, exist_ok=exist_ok)</span><br><span class="line">save_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">final_save_path = save_path / <span class="string">&quot;all_centers.jpg&quot;</span></span><br><span class="line">cv2.imwrite(<span class="built_in">str</span>(final_save_path), canvas)</span><br></pre></td></tr></table></figure><br>然后就可以得到羽毛球的轨迹啦<br>其实最开始是打算做类似鹰眼的轨迹识别加预测，但是预测的过程太过于复杂，折腾了一堆东西没有什么进展就over了</p>]]></content>
      
      
      <categories>
          
          <category> 项目 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，FM0编解码代码</title>
      <link href="/2024/10/17/FM0/"/>
      <url>/2024/10/17/FM0/</url>
      
        <content type="html"><![CDATA[<p>使用matlab编写的一份用于编解码信号的.m文件<br>密勒码解码过程可以表述为：以 2 倍的数据时钟码读入，进行每两位转换一次，01 和 10 都转换为 1，00 和 11 都转换为 0，这样即完成解码得到原始 NRZ 码，本实验无起始同步和停止过程<br>本代码参照密勒码的文件修改<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]; <span class="comment">% 输入的二进制数据</span></span><br><span class="line">FM0 = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="number">2</span> * <span class="built_in">length</span>(x)); <span class="comment">% 生成FM0编码,对应两个编码位</span></span><br><span class="line">state = <span class="number">0</span>; <span class="comment">% 初始化状态，初始为0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 对输入数据进行FM0编码</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">length</span>(x)</span><br><span class="line">    <span class="keyword">if</span> x(<span class="built_in">i</span>) == <span class="number">1</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>) = ~state; <span class="comment">% 当当前数据位为1时，第一个码元是当前状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 状态翻转</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span>) = state; <span class="comment">% 第二个码元是翻转后的状态</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>) = ~state; <span class="comment">% 当当前数据位为0时，第一个码元是当前状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 状态翻转</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span>) = ~state; <span class="comment">% 第二个码元是翻转后的状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 再次翻转状态以保持为下一位做准备</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>); <span class="comment">% 绘制原始输入数据</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(x)<span class="number">-1</span>, x, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示输入数据</span></span><br><span class="line">title(<span class="string">&#x27;原始数据&#x27;</span>); <span class="comment">% 设置标题为&quot;原始数据&quot;</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>); <span class="comment">% 绘制编码后的FM0结果</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(FM0)<span class="number">-1</span>, FM0, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示FM0编码结果</span></span><br><span class="line">title(<span class="string">&#x27;FM0 编码结果&#x27;</span>); <span class="comment">% 设置标题为&quot;FM0 编码结果&quot;</span></span><br><span class="line"><span class="comment">% 创建存储解码结果的向量，其长度为FM0编码长度的一半</span></span><br><span class="line">decoded_data = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">length</span>(FM0) / <span class="number">2</span>); </span><br><span class="line"><span class="comment">% 解码循环，从FM0编码结果中恢复原始数据</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">2</span>:<span class="built_in">length</span>(FM0)<span class="number">-2</span></span><br><span class="line">    <span class="comment">% 如果两个相邻的FM0码元不同且下一对码元相同</span></span><br><span class="line">    <span class="keyword">if</span> (FM0(<span class="built_in">i</span>) ~= FM0(<span class="built_in">i</span>+<span class="number">1</span>)) &amp;&amp; (FM0(<span class="built_in">i</span>+<span class="number">1</span>) == FM0(<span class="built_in">i</span>+<span class="number">2</span>)) </span><br><span class="line">        decoded_data((<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">1</span>; <span class="comment">% 则解码为1</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        decoded_data((<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">0</span>; <span class="comment">% 否则解码为0</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>); <span class="comment">% 绘制解码后的数据</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(decoded_data)<span class="number">-1</span>, decoded_data, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示解码后的数据</span></span><br><span class="line">title(<span class="string">&#x27;FM0 解码结果&#x27;</span>); <span class="comment">% 设置标题为&quot;FM0 解码结果&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>随便写点</title>
      <link href="/2024/10/15/start/"/>
      <url>/2024/10/15/start/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到我的博客! 如果感兴趣的话就多逛逛。不定期更新项目的经历，记录自己走过的路。这是我的<a href="https://github.com/xxxkkw">代码仓库</a>。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
