<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>喉镜数据分析</title>
      <link href="/2025/10/12/%E5%96%89%E9%95%9C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2025/10/12/%E5%96%89%E9%95%9C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="喉镜数据分析"><a href="#喉镜数据分析" class="headerlink" title="喉镜数据分析"></a>喉镜数据分析</h1><p><img src="/img/class_distribution_combined.png" alt="image.png"></p><p>喉镜各类别数据分布说明：</p><ul><li>当前各类别样本量总体接近，不存在某一类别极端稀少的情况。</li><li>这意味着数据足以支撑训练与评估；模型在测试集的总体分类准确率约为 87%。</li></ul><p><img src="/img/test_confusion_matrix_new.png" alt="image.png"></p><p>如何阅读这张混淆矩阵图：</p><ul><li>行是“真实类别”，列是“模型预测类别”，对角线表示判对的数量；对角线越深/越大越好。</li><li>非对角线的数字表示“把某类别判成了另一个类别”，这些就是模型最容易犯的错。</li><li>当前错分主要集中在以下相似组：1–2、3–6、6–7、8–9–10、11–12、15–16。说明这些组之间的外观更相似，模型更难区分。</li></ul><p>采集/选图的实用建议：</p><ul><li>每个部位优先选清晰、角度有差异、可辨特征明显的图片；避免同一序列的近重复帧。</li><li>尤其对上述“易混淆组”，尽量挑差异更大的样本；如果确实选不出差异明显的图，建议直接舍弃该样本。</li></ul><h2 id="示例图片（规范与相似对比，仅供参考）"><a href="#示例图片（规范与相似对比，仅供参考）" class="headerlink" title="示例图片（规范与相似对比，仅供参考）"></a>示例图片（规范与相似对比，仅供参考）</h2><p>下方示例用于对齐“规范选图”和“应避免的相似样本”两类情况，请各位老师在实际采集时对照执行：</p><h3 id="规范选图"><a href="#规范选图" class="headerlink" title="规范选图"></a>规范选图</h3><p><img src="/img/stander.png" alt="image.png"></p><h3 id="应避免的相似样本"><a href="#应避免的相似样本" class="headerlink" title="应避免的相似样本"></a>应避免的相似样本</h3><p>类别1-2</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_1.jpg" style="width:50%; height:auto; object-fit:contain;">  <img src="/img/sim_2.jpg" style="width:50%; height:auto; object-fit:contain;"></div><p>类别3-6</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_3_1.jpg" style="width:50%; height:auto; object-fit:contain;">  <img src="/img/sim_6_1.jpg" style="width:50%; height:auto; object-fit:contain;"></div><p>类别6-7</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_6_2.jpg" style="width:50%; height:auto; object-fit:contain;">  <img src="/img/sim_7_2.jpg" style="width:50%; height:auto; object-fit:contain;"></div><p>类别8-9-10</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_8.jpg" style="width:33%; height:auto; object-fit:contain;">  <img src="/img/sim_9.jpg" style="width:33%; height:auto; object-fit:contain;">  <img src="/img/sim_10.jpg" style="width:33%; height:auto; object-fit:contain;"></div><p>类别11-12</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_11.jpg" style="width:50%; height:auto; object-fit:contain;">  <img src="/img/sim_12.jpg" style="width:50%; height:auto; object-fit:contain;"></div><p>类别15-16</p><div style="display:flex; gap:12px; align-items:flex-start; margin:8px 0;">  <img src="/img/sim_15.jpg" style="width:50%; height:auto; object-fit:contain;">  <img src="/img/sim_16.jpg" style="width:50%; height:auto; object-fit:contain;"></div>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器SMB文件共享指南</title>
      <link href="/2025/10/05/%E6%9C%8D%E5%8A%A1%E5%99%A8SMB%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E6%8C%87%E5%8D%97/"/>
      <url>/2025/10/05/%E6%9C%8D%E5%8A%A1%E5%99%A8SMB%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>有时我们需要在局域网内访问服务器上的视频、音乐或数据文件，服务器比较好塞下较多的机械硬盘。<br>此时可以通过 SMB（Windows 文件共享）协议 实现跨平台访问（Windows / macOS / Linux）。此时服务器的作用就相当于一台Nas,只不过只能在局域网访问。</p><h2 id="1-安装-Samba"><a href="#1-安装-Samba" class="headerlink" title="1. 安装 Samba"></a>1. 安装 Samba</h2><h3 id="1-1-安装-Samba-服务器"><a href="#1-1-安装-Samba-服务器" class="headerlink" title="1.1 安装 Samba 服务器"></a>1.1 安装 Samba 服务器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt install samba</span><br></pre></td></tr></table></figure><h3 id="1-2-检查安装是否成功"><a href="#1-2-检查安装是否成功" class="headerlink" title="1.2 检查安装是否成功"></a>1.2 检查安装是否成功</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbd --version</span><br></pre></td></tr></table></figure><h3 id="1-3-配置-Samba-服务器"><a href="#1-3-配置-Samba-服务器" class="headerlink" title="1.3 配置 Samba 服务器"></a>1.3 配置 Samba 服务器</h3><p>编辑 Samba 配置文件 <code>/etc/samba/smb.conf</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p>在文件末尾添加以下内容：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[share]</span></span><br><span class="line">    <span class="attr">path</span> = /path/to/shared/directory</span><br><span class="line">    <span class="attr">browseable</span> = <span class="literal">yes</span></span><br><span class="line">    read <span class="attr">only</span> = <span class="literal">no</span></span><br><span class="line">    guest <span class="attr">ok</span> = <span class="literal">no</span></span><br><span class="line">    valid <span class="attr">users</span> = 你的用户名</span><br><span class="line">    create <span class="attr">mask</span> = <span class="number">0755</span></span><br></pre></td></tr></table></figure><h3 id="1-4-创建用户，设置密码"><a href="#1-4-创建用户，设置密码" class="headerlink" title="1.4 创建用户，设置密码"></a>1.4 创建用户，设置密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> smbpasswd -a 你的用户名</span><br></pre></td></tr></table></figure><h3 id="1-5-重启-Samba-服务"><a href="#1-5-重启-Samba-服务" class="headerlink" title="1.5 重启 Samba 服务"></a>1.5 重启 Samba 服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart smbd</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> smbd</span><br></pre></td></tr></table></figure><h3 id="1-6-配置防火墙"><a href="#1-6-配置防火墙" class="headerlink" title="1.6 配置防火墙"></a>1.6 配置防火墙</h3><p>确保防火墙允许 SMB 流量通过：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> ufw allow samba</span><br></pre></td></tr></table></figure><p>随后就能在局域网内访问 <code>\\服务器IP\share</code> 了。或者在各个平台上的文件系统中或者是影音系统等支持 SMB 协议的 App 中访问。</p>]]></content>
      
      
      <categories>
          
          <category> share </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报7.0</title>
      <link href="/2025/09/20/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A57.0/"/>
      <url>/2025/09/20/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A57.0/</url>
      
        <content type="html"><![CDATA[<h1 id="补充实验"><a href="#补充实验" class="headerlink" title="补充实验"></a>补充实验</h1><p><img src="/img/S3.png" alt="image.png"></p><p>为清晰起见，首先对本文后续将使用的关键术语进行定义。<code>X_3^T</code>代表从模型骨干网络中提取的时域特征。<code>X_3^E</code>表示源自STFT分支的时频域特征，此特征未经时域对齐网络（t-ALN）处理。<code>X_3^Q</code>则为<code>X_3^E</code>经过t-ALN对齐后得到的特征。后续展示的均为基于T-SNE降维的特征可视化结果。本文设计了三组对比实验，以评估模型在不同配置下所提取特征的性能差异。这些配置包括：(1) 完整模型；(2) 简化对齐模型；(3) 无中间层交互模型（即骨干网络中间层<code>X_1^E</code>与<code>X_2^E</code>不参与注意力计算）。实验旨在深入分析并比较输入专家层特征的类别可分离性，并评估骨干网络提取特征的有效性。</p><h2 id="时域特征X-3-T"><a href="#时域特征X-3-T" class="headerlink" title="时域特征X_3^T"></a>时域特征<code>X_3^T</code></h2><h3 id="完整模型"><a href="#完整模型" class="headerlink" title="完整模型"></a>完整模型</h3><p><img src="/img/features_tsne_x3t_normal_fold_7.png" alt="image.png"></p><p>实验结果表明，五个类别的特征在T-SNE可视化中表现出良好的可分离性，聚类边界清晰，表明模型能够有效区分不同类别。</p><h3 id="简化版对齐"><a href="#简化版对齐" class="headerlink" title="简化版对齐"></a>简化版对齐</h3><p><img src="/img/features_tsne_x3t_noalign_fold_7.png" alt="image.png"></p><p>在简化对齐配置下，与完整模型相比，REM、N1和N2三个类别的特征出现显著混叠，类别间的边界变得模糊。此外，特征簇之间的距离相较于完整模型明显减小，表明特征的可分性有所下降。</p><h3 id="无中间层交互"><a href="#无中间层交互" class="headerlink" title="无中间层交互"></a>无中间层交互</h3><p><img src="/img/features_tsne_x3t_noc_fold_7.png" alt="image.png"></p><p>在移除中间层交互后，N1、N2与REM类别的特征混杂现象进一步加剧。同时，各个类别的类内距离增大，特征分布更为松散，这预示着模型区分这些相似类别的能力被进一步削弱。这也从侧面印证了时频域特征在为时域引入了另外一个视角的特征，进而提升了模型的分类性能。</p><h2 id="时频域特征X-3-E"><a href="#时频域特征X-3-E" class="headerlink" title="时频域特征X_3^E"></a>时频域特征<code>X_3^E</code></h2><h3 id="完整模型-1"><a href="#完整模型-1" class="headerlink" title="完整模型"></a>完整模型</h3><p><img src="/img/features_tsne_x3e_normal_fold_7.png" alt="image.png"></p><p>完整模型提取的时频域特征表现出与时域特征相似的性能，五个类别的可分离度依然非常清晰。通过对两种特征的可视化结果进行直接比较，可以观察到两者在特征分布上具有显著的相似性。</p><h3 id="简化版对齐-1"><a href="#简化版对齐-1" class="headerlink" title="简化版对齐"></a>简化版对齐</h3><p><img src="/img/features_tsne_x3e_noalign_fold_7.png" alt="image.png"></p><p>实验结果清晰地表明，在简化对齐配置下，即便没有直接的时域交互，时频域特征的质量同样受到负面影响。特征分布整体上呈现出更强的混杂性，可分性降低。</p><h3 id="无中间层交互-1"><a href="#无中间层交互-1" class="headerlink" title="无中间层交互"></a>无中间层交互</h3><p><img src="/img/features_tsne_x3e_noc_fold_7.png" alt="image.png"></p><p>在无中间层交互的条件下，时频域特征的质量同样受到影响。尽管其特征分离度优于简化对齐模型，但仍未达到完整模型所展现出的高水平可分离性。</p><h2 id="时频域特征X-3-Q"><a href="#时频域特征X-3-Q" class="headerlink" title="时频域特征X_3^Q"></a>时频域特征<code>X_3^Q</code></h2><p>进一步探究时域对齐网络（t-ALN）的有效性，本研究额外增加了一组针对对齐后特征<code>X_3^Q</code>的实验。该实验旨在从侧面验证对齐操作是否能够有效提升特征的类别可分性，同时保持其固有的表征能力。</p><h3 id="完整模型-2"><a href="#完整模型-2" class="headerlink" title="完整模型"></a>完整模型</h3><p><img src="/img/features_tsne_x3q_normal_fold_7.png" alt="image.png"></p><p>经过t-ALN对齐后，特征的类别可分性得到显著增强。可视化结果清晰地显示，尽管N1和N2两个类别由于内在相似性较高而未能完全分离（表现为紧密相邻而非混杂），但其余所有类别均呈现出比未对齐特征更高的分离度，类别间的边界也更为明确。</p><h3 id="简化版对齐-2"><a href="#简化版对齐-2" class="headerlink" title="简化版对齐"></a>简化版对齐</h3><p><img src="/img/features_tsne_x3q_noalign_fold_7.png" alt="image.png"></p><p>简化对齐模型的性能远不及完整模型，其特征分离度较低，且类间分布松散。通过对比对齐前后的特征分布图，可以发现两者几乎没有显著差异，类别特征的分布模式基本保持一致。这一结果从反面印证了我们所提出的t-ALN对齐模块的有效性。</p><h3 id="无中间层交互-2"><a href="#无中间层交互-2" class="headerlink" title="无中间层交互"></a>无中间层交互</h3><p><img src="/img/features_tsne_x3q_noc_fold_7.png" alt="image.png"></p><p>在无中间层交互的情况下，对齐后的特征质量虽优于简化对齐模型，但其分离度和完整性仍显著低于完整模型。特别是在N1和N2两个类别上，特征聚集效果不佳，相较于完整模型呈现出更为混乱的分布状态，这凸显了中间层交互对于提升模型性能的重要性。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报6.0</title>
      <link href="/2025/08/18/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A56.0/"/>
      <url>/2025/08/18/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A56.0/</url>
      
        <content type="html"><![CDATA[<h1 id="当前进展"><a href="#当前进展" class="headerlink" title="当前进展"></a>当前进展</h1><h2 id="ISRUC-S3"><a href="#ISRUC-S3" class="headerlink" title="ISRUC-S3"></a>ISRUC-S3</h2><div class="table-container"><table><thead><tr><th></th><th>Fold 0</th><th>Fold 1</th><th>Fold 2</th><th>Fold 3</th><th>Fold 4</th><th>Fold 5</th><th>Fold 6</th><th>Fold 7</th><th>Fold 8</th><th>Fold 9</th></tr></thead><tbody><tr><td>Fold  Length</td><td>924</td><td>911</td><td>794</td><td>764</td><td>914</td><td>823</td><td>784</td><td>970</td><td>939</td><td>766</td></tr><tr><td>SwinMOE Mode</td><td>0.87667</td><td>0.84852</td><td>0.86524</td><td>0.83508</td><td>0.87965</td><td>0.83354</td><td>0.85459</td><td>0.91546</td><td>0.82215</td><td>0.83812</td></tr><tr><td>New Gate</td><td>0.87667</td><td>0.85730</td><td>0.87280</td><td>0.83508</td><td>0.88293</td><td>0.83961</td><td>0.87628</td><td>0.92680</td><td>0.82428</td><td>0.84073</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>cVAN-S</th><th>cVAN-M</th><th>cVAN-L</th><th>DGraphormer-SleepNet</th><th>StAGN</th><th>MSTGCN</th><th>STDP-GCN</th><th>1bimamba</th><th>MSF-SleepNet</th><th>MVF-SleepNet</th><th>CNN-GCN</th><th>SLEEPSMC</th></tr></thead><tbody><tr><td>S3 ACC</td><td>86.31</td><td>85.6</td><td>86.9</td><td>85.8</td><td>85.4</td><td>84.4</td><td>82.1</td><td>82.6</td><td>85.2</td><td>84.9</td><td>84.1</td><td>84.26</td><td>79.30</td></tr></tbody></table></div><h2 id="新门控-双分支交叉注意力门控"><a href="#新门控-双分支交叉注意力门控" class="headerlink" title="新门控-双分支交叉注意力门控"></a>新门控-双分支交叉注意力门控</h2><p><img src="/img/Dual_Brunch_Gating.png" alt="image.png"></p><p>在原来门控的基础上，重新加深，同时采用时频信号以及STFT分支信号，然后如图做交叉注意力，得到专家权重，实测新门控有明确的性能提升。</p><h2 id="新对齐模块"><a href="#新对齐模块" class="headerlink" title="新对齐模块"></a>新对齐模块</h2><p><img src="/img/CDP_Align.png" alt="image.png"></p><h3 id="问题动机"><a href="#问题动机" class="headerlink" title="问题动机"></a>问题动机</h3><p>在睡眠分期任务中，多通道频谱图<code>STFT</code>如何在时间维度上对齐效果对模型结果有显著影响，而不同频率与通道对目标任务的贡献是不一致的，这种不一致导致直接池化或者展平会带来信息的丢失以及不稳定，且可解释性弱。</p><h3 id="痛点"><a href="#痛点" class="headerlink" title="痛点"></a>痛点</h3><ul><li>维度间相互依赖：频率重要性会影响通道选择，通道选择又决定时间段的显著性。</li><li>在睡眠分期中，不同期的特征对应在频谱图中的能量分布是是不一致的，且不同频率间的贡献度也不一致。</li><li>以往的对齐方式往往只考虑了形状对齐，而忽略了信息分布的差异化所带来的对齐问题。</li><li>这种频谱图本质上是不同频率幅度对应的能量分布，而不是传统的图像信息。</li></ul><p>当前方法是通过跨维度<code>先-后</code>估计链，(频率-&gt;通道-&gt;时间)，用概率分布式归一实现尺度对齐，同时稳定了频率与通道在时间上的特征，且提供了强可解释性。</p><h3 id="设计路径"><a href="#设计路径" class="headerlink" title="设计路径"></a>设计路径</h3><ul><li><p><strong>频谱图能量化</strong>:</p><ul><li>对每个样本的<code>STFT</code>频谱图，复谱的模平方 |X(f, t)|^2 就是功率/能量密度，因此在时频图上用平方是把<code>幅度</code>转成<code>能量</code>，得到非负且物理可解释的量。</li></ul></li><li><p><strong>频率重要性估计s_h</strong>:</p><ul><li>对每个样本自适应的评估各频带的重要性（跨时间，通道的频率重要性）。</li><li>这里相当于一个频率门控，基于数据分布，得到频带热力图。</li></ul></li><li><p><strong>全局通道加权聚合得到M</strong>:</p><ul><li>将能量在s_h在频率维度上加权再聚合，得到得到通道×时间的<code>频率重加权能量轨迹</code>，符合频率的数据分布。</li></ul></li><li><p><strong>通道重要性估计g_c</strong>:</p><ul><li>对每个样本评估各通道的重要性（跨时间的平均能量再归一化）。</li><li>这里相当于一个通道门控，基于数据分布，得到通道热力图。直接指向哪些通道更重要。</li></ul></li><li><p><strong>时间曲线s_t</strong>:</p><ul><li>用g_c对M在时间维度上加权，得到通道×时间的<code>时间重加权能量轨迹</code>，符合通道的的数据分布。</li></ul></li><li><p><strong>概率式归一 + 尺度对齐w</strong>:</p><ul><li>用Softmax保证数据的分布性，防止被能量尺度所影响，解决幅度问题导致的偏置问题。</li></ul></li><li><p><strong>时间优先的展平</strong>:</p><ul><li>对每个通道固定时间步，聚合到一维时间时间序列，这样保证了时间序列任务中的基本时间上下文不丢失，且融合了前面通道的信息。</li><li>最后再映射到统一的特征维度，为后续的注意力计算提供统一且在时间尺度上的对齐查询信号<code>Q</code></li></ul></li></ul><h3 id="模块性质"><a href="#模块性质" class="headerlink" title="模块性质"></a>模块性质</h3><ul><li><p>s_h（频带）、g_c（通道）、w（时间）。这三者构成了“频-通-时”的可解释链条。</p></li><li><p>跨维因果顺序：先频率后通道再时间，体现“频率选择影响通道选择，通道选择塑造时间注意力”的结构性假设，优于并行、无序的注意力。</p></li><li><p>复杂度友好：计算量主导为 O(B·C·H·T)，只引入一个线性层，几乎无额外显存开销。</p></li></ul><h3 id="Alpha-超参数结果"><a href="#Alpha-超参数结果" class="headerlink" title="Alpha 超参数结果"></a>Alpha 超参数结果</h3><div class="table-container"><table><thead><tr><th>alpha</th><th>Accuracy</th><th>F1-Score</th><th>Kappa</th></tr></thead><tbody><tr><td>0</td><td>0.848485</td><td>0.804517</td><td>0.794412</td></tr><tr><td>0.5</td><td>0.839827</td><td>0.805115</td><td>0.780510</td></tr><tr><td>0.75</td><td>0.844156</td><td>0.805968</td><td>0.790240</td></tr><tr><td>1</td><td>0.865</td><td>0.853</td><td>0.826</td></tr><tr><td>1.5</td><td>0.850649</td><td>0.819768</td><td>0.794110</td></tr><tr><td>2</td><td>0.844156</td><td>0.811491</td><td>0.789289</td></tr></tbody></table></div><h3 id="Embedding-维度（embed-dim）"><a href="#Embedding-维度（embed-dim）" class="headerlink" title="Embedding 维度（embed dim）"></a>Embedding 维度（embed dim）</h3><div class="table-container"><table><thead><tr><th>embed dim</th><th>Accuracy</th><th>F1-Score</th><th>Kappa</th></tr></thead><tbody><tr><td>16</td><td>0.851732</td><td>0.818182</td><td>0.796676</td></tr><tr><td>32</td><td>0.854978</td><td>0.825180</td><td>0.803595</td></tr><tr><td>64</td><td>0.866</td><td>0.855</td><td>0.827</td></tr><tr><td>128</td><td>0.843074</td><td>0.809956</td><td>0.788037</td></tr><tr><td>256</td><td>0.848485</td><td>0.808143</td><td>0.792297</td></tr></tbody></table></div><h3 id="层数（layer-num）"><a href="#层数（layer-num）" class="headerlink" title="层数（layer num）"></a>层数（layer num）</h3><div class="table-container"><table><thead><tr><th>layer num</th><th>embed dim</th><th>Accuracy</th><th>F1-Score</th><th>Kappa</th></tr></thead><tbody><tr><td>1</td><td>0.844156</td><td>0.816897</td><td>0.788315</td></tr><tr><td>2</td><td>0.866</td><td>0.855</td><td>0.827</td></tr><tr><td>3</td><td>0.853896</td><td>0.817099</td><td>0.801245</td></tr><tr><td>4</td><td>0.856061</td><td>0.825460</td><td>0.804506</td></tr><tr><td>5</td><td>0.854639</td><td>0.825662</td><td>0.802797</td></tr></tbody></table></div><h3 id="专家数（expert-num）"><a href="#专家数（expert-num）" class="headerlink" title="专家数（expert num）"></a>专家数（expert num）</h3><div class="table-container"><table><thead><tr><th>expert num</th></tr></thead><tbody><tr><td>1</td><td>0.866</td><td>0.855</td><td>0.827</td></tr><tr><td>2</td><td>0.856061</td><td>0.820601</td><td>0.803714</td></tr><tr><td>3</td><td>0.853896</td><td>0.824725</td><td>0.800476</td></tr><tr><td>4</td><td>0.853896</td><td>0.827581</td><td>0.801192</td></tr><tr><td>5</td><td>0.852577</td><td>0.818810</td><td>0.804912</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报5.0</title>
      <link href="/2025/08/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A55.0/"/>
      <url>/2025/08/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A55.0/</url>
      
        <content type="html"><![CDATA[<h1 id="当前进展"><a href="#当前进展" class="headerlink" title="当前进展"></a>当前进展</h1><h2 id="ISRUC-S3"><a href="#ISRUC-S3" class="headerlink" title="ISRUC-S3"></a>ISRUC-S3</h2><div class="table-container"><table><thead><tr><th></th><th>Fold 0</th><th>Fold 1</th><th>Fold 2</th><th>Fold 3</th><th>Fold 4</th><th>Fold 5</th><th>Fold 6</th><th>Fold 7</th><th>Fold 8</th><th>Fold 9</th></tr></thead><tbody><tr><td>Fold  Length</td><td>924</td><td>911</td><td>794</td><td>764</td><td>914</td><td>823</td><td>784</td><td>970</td><td>939</td><td>766</td></tr><tr><td>SwinMOE Mode</td><td>0.87667</td><td>0.84852</td><td>0.86524</td><td>0.83508</td><td>0.87965</td><td>0.83354</td><td>0.85459</td><td>0.91546</td><td>0.82215</td><td>0.83812</td></tr><tr><td>New Gate</td><td>0.87667</td><td>0.84962</td><td>0.86524</td><td>0.83508</td><td>0.87965</td><td>0.83475</td><td>0.86097</td><td>0.92165</td><td>0.82322</td><td>0.83812</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>cVAN-S</th><th>cVAN-M</th><th>cVAN-L</th><th>DGraphormer-SleepNet</th><th>StAGN</th><th>MSTGCN</th><th>STDP-GCN</th><th>1bimamba</th><th>MSF-SleepNet</th><th>MVF-SleepNet</th><th>CNN-GCN</th><th>SLEEPSMC</th></tr></thead><tbody><tr><td>S3 ACC</td><td>85.97</td><td>85.6</td><td>86.9</td><td>85.8</td><td>85.4</td><td>84.4</td><td>82.1</td><td>82.6</td><td>85.2</td><td>84.9</td><td>84.1</td><td>84.26</td><td>79.30</td></tr></tbody></table></div><h2 id="Sleep-EDF-153"><a href="#Sleep-EDF-153" class="headerlink" title="Sleep-EDF-153"></a>Sleep-EDF-153</h2><div class="table-container"><table><thead><tr><th></th><th>Fold 0</th><th>Fold 1</th><th>Fold 2</th><th>Fold 3</th><th>Fold 4</th><th>Fold 5</th><th>Fold 6</th><th>Fold 7</th><th>Fold 8</th><th>Fold 9</th></tr></thead><tbody><tr><td>Fold  Length</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td><td>19104</td></tr><tr><td>SwinMOE Mode</td><td>0.86553</td><td>0.86652</td><td>0.86490</td><td>0.86725</td><td>0.86547</td><td>0.86228</td><td>0.86751</td><td>0.86087</td><td>0.86108</td><td>0.86725</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>cVAN-S</th><th>cVAN-M</th><th>cVAN-L</th><th>STDP-GCN</th><th>MSTGCN</th></tr></thead><tbody><tr><td>EDF-153 ACC</td><td>86.50</td><td>86.4</td><td>87.5</td><td>88.0</td><td>87.4</td><td>86.4</td></tr></tbody></table></div><h2 id="下面是一些其他数据集的数据"><a href="#下面是一些其他数据集的数据" class="headerlink" title="下面是一些其他数据集的数据"></a>下面是一些其他数据集的数据</h2><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>cVAN-S</th><th>cVAN-M</th><th>cVAN-L</th><th>DGraphormer-SleepNet</th><th>StAGN</th><th>BSTT</th><th>CNN+ECA+1bimamba</th><th>MSF-SleepNet</th><th>MVF-SleepNet</th><th>SLEEPSMC</th></tr></thead><tbody><tr><td>S1  ACC</td><td></td><td>83.5</td><td>85.7</td><td>85.2</td><td>81.4</td><td>81.1</td><td>81.96</td><td>83.0</td><td>82.6</td><td>82.1</td><td>77.10</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>EEGMamba</th><th>SleepContextNet</th><th>GradCAM</th></tr></thead><tbody><tr><td>SHHS ACC</td><td></td><td>84.78</td><td>86.4</td><td>87.8</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>BSTT</th><th>Siamese AEs</th><th>SeqSleepNet</th><th>CNN-GCN</th><th>SLEEPSMC</th><th>SleepPrintNet</th><th>GraphSleepNet</th><th>ST-Transformer</th></tr></thead><tbody><tr><td>MASS-SS3 ACC</td><td></td><td>89.50</td><td>87.2</td><td>86.5</td><td>85.71</td><td>86.86</td><td>88.8</td><td>88.36</td><td>88.64</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>model name</th><th>STAGES(OURS)</th><th>BiT-MamSleep</th><th>SleepContextNet</th><th>GradCAM</th><th>SLEEPSMC</th><th>MC2SleepNet</th><th>SleePyco</th></tr></thead><tbody><tr><td>EDF-78 ACC</td><td></td><td>80.21</td><td>82.7</td><td>83.8</td><td>81.58</td><td>84.6</td><td>84.6</td></tr></tbody></table></div><p>目前调参时均未动种子，仅对超参数调优得到，S3数据集的调参比较细致，EDF一共才跑了三十次左右，S1暂未开始跑，后面看情况要不要直接把EDF换成SHHS，或者MASS-SS3,我更偏向于换MASS。这两个数据集做的人更多，数据量小一些，但cVAN没做，刚好岔开，我的结果按说是较高的，超过别的模型简单一点。</p><h2 id="模型结构图"><a href="#模型结构图" class="headerlink" title="模型结构图"></a>模型结构图</h2><p><img src="/img/STAGES.png" alt="image.png"></p><p>模型的结构如图所示，有两个分支，一个是时频分支，也就是基于<code>Swin Transformer</code>，也就是原始的Swin Transformer爆改成1D版本，参考下表。swin这里的分支另外的点就是重新改了他的注意力结构，扩展了一份从后面STFT分支来的Q，原始的就是把x直接升维分三份，完全相同的QKV,然后就是改动了Patch Embed，改成1D的，Patch Merging也是，另一个分支是频谱分支，将原始的raw信号经过<code>STFT</code>变换得到，随后进入由分层的类<code>ResNet</code>结构，每层抽出来一份特征，经过对齐后送入<code>Swin Transformer 1D</code>中做交叉注意力，也就是这里的<code>STFT</code>分支作为<code>Q</code>，原本的就作为<code>KV</code>然后用两层这种互补结构作为骨干网络，也就同时为后面的MOE结构提供基础骨干网络，共享特征。下面连接两个<code>Expert</code>，这两个专家的结构复用了前面的Swin Transformer 1D的结构，一个是浅睡眠专家<code>浅睡眠专家</code>(W N1 N2)，另一个是<code>深睡眠专家</code>(N3，REM)，稠密激活，最终由门控网络得到的权重，合并两个logits得到最终的结果。</p><div class="table-container"><table><thead><tr><th>Aspect</th><th>Swin Transformer</th><th>Swin Transformer 1D</th></tr></thead><tbody><tr><td>Data Shape</td><td>[B, C, H, W]</td><td>[B, C, L]</td></tr><tr><td>Patch Embedding</td><td>Conv2d(<em>, </em>, kernel=p, stride=p)</td><td>Conv1d(<em>, </em>, kernel=p, stride=p)</td></tr><tr><td>Window Partitioning</td><td>Split into p×p 2D windows</td><td>Split into length-p 1D windows</td></tr><tr><td>Relative Position</td><td>2D grid distances (u, v)</td><td>1D distances (i - j)</td></tr><tr><td>Shifted Roll</td><td>Roll along height&amp;width dims</td><td>Roll along sequence dim</td></tr><tr><td>Masking</td><td>Complex 2D boundary masks</td><td>Simplified 1D segment masks</td></tr><tr><td>Patch Merging</td><td>Merge 2×2 spatial patches</td><td>Merge every two tokens: L → L/2</td></tr><tr><td>Cross-Modal QKV</td><td>Not supported</td><td>External query from STFT via external_q</td></tr><tr><td>Complexity</td><td>O(HW × C) per layer</td><td>O(L × C) per layer</td></tr></tbody></table></div><h2 id="做这种MOE以及Swin-Transformer-1D动机以及原因"><a href="#做这种MOE以及Swin-Transformer-1D动机以及原因" class="headerlink" title="做这种MOE以及Swin Transformer 1D动机以及原因"></a>做这种MOE以及Swin Transformer 1D动机以及原因</h2><p>下图从左到右分别是Sleep-EDF-153,ISRUC-S1,ISRUC-S3数据集上全局数据的转移矩阵，顾名思义，就是每个分期往下个分期转移的概率，如图所示，三份数据集都表现出(W N1 N2)三期是相对混乱的转移的，而(N3 REM)两期是相对自转移概率较大，或者说是稳定分期。所以选择将这两份分期作为两个专家，一个是浅睡眠专家，一个是深睡眠专家，分别对应(W N1 N2)和(N3 REM)两期，然后用软门控网络给两个专家权重，来决定哪个专家的占比大，这样做的好处是避免了硬门控带来的一系列错分问题，门控只是给出一个占比，不是绝对。</p><p><img src="/img/global_trans.png" alt="image.png"></p><p>下面是t-SNE可视化，图中不同颜色代表不同的分期，不同的点代表不同的样本，从图中可以看出，(W N1 N2)三期的样本分布更偏向揉在一起的，而(N3 REM)两期的样本分布更像外挂在外面，换句话说，稳定的还是(N3 REM)两期，混乱的还是(W N1 N2)三期，这与全局转移矩阵的结果是一致的。</p><p><img src="/img/t_sne_cvan.png" alt="image.png"></p><p>再就是双分支 + Swin Transformer 1D,其他人的模型基本采用的都是Transformer结构，计算强度有点大，这里用swin来替换，降低时间复杂度，并且swin的好处还能同时兼顾长距离跟细节尺度，这与它按patch提取的方式有关，带了一点CNN的思想。然后再选择与cVAN类似的STFT分支，做一个交叉注意力，来更深层次的构成特征的互补。因为这些生理信号是具有不同特征的，时频层面与频谱层面的特征需要互补才能有更好的效果，所以这里用交叉注意力来做特征的互补。</p><p>目前没有调种子，S3的调参结果与EDF初步的结果能证明，上面做的那些分析还是有效果的，与实际情况能对应上。当前的模型的size与cVAN-S是差不多一致的，但按骨干计算量来说，我的结构的计算复杂度会小很多，按说就这样往后去调种子结果也够了。</p><p>下面是模型核心的forward代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, stft, return_features=<span class="literal">True</span></span>):</span><br><span class="line">    B, C, L = x.shape</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 1. 对应图中的Patch Embedding 1D,这里可以考虑将图中部分改成Time Embedding,符合时间序列特征</span></span><br><span class="line">    x = <span class="variable language_">self</span>.time_embed(x)</span><br><span class="line">    <span class="comment"># 2. STFT特征提取，这里的三份STFT就是从resnet那边送回来做交叉注意力的特征</span></span><br><span class="line">    stft = stft.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    stft1, stft2, stft3 = <span class="variable language_">self</span>.res_block(stft)</span><br><span class="line">    <span class="comment"># 3. STFT特征投影</span></span><br><span class="line">    stft1 = stft1.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    stft2 = stft2.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    stft3 = stft3.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    stft1 = <span class="variable language_">self</span>.stft_proj1(stft1)  <span class="comment"># (B, 1000, embed_dim)</span></span><br><span class="line">    stft2 = <span class="variable language_">self</span>.stft_proj2(stft2)  <span class="comment"># (B, 500, embed_dim*2)</span></span><br><span class="line">    stft3 = <span class="variable language_">self</span>.stft_proj3(stft3)  <span class="comment"># (B, 250, embed_dim*4)</span></span><br><span class="line">    x = <span class="variable language_">self</span>.pos_drop(x)</span><br><span class="line">    <span class="comment"># 4. 共享主干 - 第一层 (使用stft1)</span></span><br><span class="line">    x = <span class="variable language_">self</span>.shared_layer0(x.contiguous(), stft1)</span><br><span class="line">    <span class="comment"># 5. 共享主干 - 第二层 (使用stft2)</span></span><br><span class="line">    x = <span class="variable language_">self</span>.shared_layer1(x.contiguous(), stft2)</span><br><span class="line">     <span class="comment"># 6. 门控网络 (基于共享主干输出)</span></span><br><span class="line">    x_for_gating = rearrange(x, <span class="string">&#x27;b c l -&gt; b l c&#x27;</span>)</span><br><span class="line">    gate_weights = <span class="variable language_">self</span>.gating_network(x_for_gating)  <span class="comment"># (B, num_experts)</span></span><br><span class="line">    <span class="comment"># 7. 专家网络分别计算</span></span><br><span class="line">    logits_transition = <span class="variable language_">self</span>.expert_transition(x.contiguous(), stft3) <span class="comment"># (B, 3)</span></span><br><span class="line">    logits_stable = <span class="variable language_">self</span>.expert_stable(x.contiguous(), stft3) <span class="comment"># (B, 2)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 8. 使用门控权重加权并合并logits</span></span><br><span class="line">    weighted_logits_transition = logits_transition * gate_weights[:, <span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">    weighted_logits_stable = logits_stable * gate_weights[:, <span class="number">1</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 拼接成最终的5分类输出</span></span><br><span class="line">    final_logits = torch.cat([weighted_logits_transition, weighted_logits_stable], dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> return_features:</span><br><span class="line">        <span class="keyword">return</span> final_logits, gate_weights</span><br><span class="line">    <span class="keyword">return</span> final_logits</span><br></pre></td></tr></table></figure></p><h2 id="模型的损失函数"><a href="#模型的损失函数" class="headerlink" title="模型的损失函数"></a>模型的损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_load_balancing_loss</span>(<span class="params">self, gate_weights, alpha=<span class="number">0.01</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算负载均衡损失&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># gate_weights: (B, num_experts)</span></span><br><span class="line">    expert_usage = torch.mean(gate_weights, dim=<span class="number">0</span>)  <span class="comment"># (num_experts,)</span></span><br><span class="line">    target_usage = <span class="number">1.0</span> / <span class="variable language_">self</span>.num_experts</span><br><span class="line">    load_loss = alpha * torch.<span class="built_in">sum</span>((expert_usage - target_usage) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> load_loss</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">logits, gate_weights = model(inputs, stft)    </span><br><span class="line"><span class="comment"># 计算分类损失</span></span><br><span class="line">classification_loss = criterion(logits, targets.argmax(<span class="number">1</span>))  </span><br><span class="line"><span class="comment"># 计算负载均衡损失</span></span><br><span class="line">expert_targets = (targets.argmax(<span class="number">1</span>) &gt;= <span class="number">3</span>).long()          <span class="comment"># (B,)</span></span><br><span class="line">gate_loss = nn.CrossEntropyLoss()(gate_weights, expert_targets) * beta</span><br><span class="line">load_balancing_loss = model.compute_load_balancing_loss(gate_weights, alpha=alpha)       </span><br><span class="line"><span class="comment"># 总损失</span></span><br><span class="line">total_loss = classification_loss + load_balancing_loss + gate_loss</span><br></pre></td></tr></table></figure><p>这里选择三段式的损失，分别是分类损失，负载均衡损失，门控损失。分类损失是为了保证最终准确率仍保持一个比较高的水平，负载均衡损失是防止出现死专家问题，而最后的门控损失带来的收益是相当明显的，这个门控损失相当于直接指导信号往不同的专家内走，也有点类似于偏好导向的优化，但这种门控损失是直接面向模型结构的，我觉得很大的提升了模型的可解释性，并且也的确带来了性能的提升，在调参的过程中是是能感知到添加上这个门控损失后准确率有显著提升的。</p><h1 id="后期准备做的任务"><a href="#后期准备做的任务" class="headerlink" title="后期准备做的任务"></a>后期准备做的任务</h1><p>后面剩下的工作就是继续调参，把剩下的数据集跑完，然后做消融实验，做一点可视化结果，把门控权重的可视化做了，把最后结果的可视化结果做了，然后再考虑在附录里面做一个关于这三个数据集的可视化，类似于那种数据具体怎么分布的，就是用来佐证我为什么要用 Swin + MOE 这种操作，弄出来它细粒度的特征以及长期特征，以及W N1 N2与N3 REM特征具体哪里不一样，然后再引用睡眠分期的信号定义，主要还是为了可解释性以及故事性，然后说明为什么这样做是有效的。</p><p>不过关于之前说的用一个更高质量的数据集去做一个骨干然后回到数据集上微调或者蒸馏之类的，感觉如果做得用那个准确率能上9的数据集，要么用MASS-SS3去做，要么用SHHS，这两个应该要干净一点，特征泛化应该也更好，EDF太大了且不说，准确率要先往上调到一个比较高的水准才能去拿现在我们所需要的数据集去微调。要不然搞不出一个好的结果来。不过我认为按照现在的准确率来说，在S3上已经足够高了，后面我调种子也能带来一个点多的收益，做过cVAN应该也够了。所以这个做不做看情况吧。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报4.0</title>
      <link href="/2025/07/17/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A54.0/"/>
      <url>/2025/07/17/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A54.0/</url>
      
        <content type="html"><![CDATA[<h1 id="当前进展"><a href="#当前进展" class="headerlink" title="当前进展"></a>当前进展</h1><div class="table-container"><table><thead><tr><th></th><th>Fold 0</th><th>Fold 1</th><th>Fold 2</th><th>Fold 3</th><th>Fold 4</th><th>Fold 5</th><th>Fold 6</th><th>Fold 7</th><th>Fold 8</th><th>Fold 9</th></tr></thead><tbody><tr><td>Fold  Length</td><td>924</td><td>911</td><td>794</td><td>764</td><td>914</td><td>823</td><td>784</td><td>970</td><td>939</td><td>766</td></tr><tr><td>History Best</td><td>0.87667</td><td>0.83095</td><td>0.84383</td><td>0.82330</td><td>0.87965</td><td>0.82231</td><td>0.85821</td><td>0.91031</td><td>0.81363</td><td>0.82768</td></tr><tr><td>SwinMOE Mode</td><td>0.87667</td><td>0.83095</td><td>0.84257</td><td>0.82330</td><td>0.87965</td><td>0.82017</td><td>0.84311</td><td>0.91031</td><td>0.81363</td><td>0.82768</td></tr></tbody></table></div><h2 id="MVF总ACC-84-1"><a href="#MVF总ACC-84-1" class="headerlink" title="MVF总ACC 84.1"></a>MVF总ACC <code>84.1</code></h2><h2 id="NOW总ACC-84-84"><a href="#NOW总ACC-84-84" class="headerlink" title="NOW总ACC 84.84"></a>NOW总ACC <code>84.84</code></h2><h2 id="cVAN总ACC-85-6"><a href="#cVAN总ACC-85-6" class="headerlink" title="cVAN总ACC 85.6"></a>cVAN总ACC <code>85.6</code></h2><p>重新读了几篇论文后，发现原先MOE的思路应该是做错了，原来想的是一个硬门控，直接来区分具体该是<code>浅睡眠专家</code>(W N1 N2),还是<code>深睡眠专家</code>(N3，REM)这种思路，通过硬门控直接输出具体是哪个专家，但有个硬伤，如果某次分类的时候，例如N2刚刚转N3的时候，这种特别像的特征，即使门控网络的硬划分准确率达到了95%，后面的小专家的准确率也需要做到比较的高，才能有效果。并且按照这种思路做，需要分两次训练，整个模型的梯度更新非常麻烦，有严重断层，需要调参两次，要先把门控的分类准确率做到非常的高后面才有用，再者说那还是剩下5的错误，这后一点分错还会干扰，所以经过一些修改，重新改成软门控机制，如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gate_weights = <span class="variable language_">self</span>.gating_network(x_for_gating)                   <span class="comment"># (B, num_experts)</span></span><br><span class="line"></span><br><span class="line">logits_transition = <span class="variable language_">self</span>.expert_transition(x.contiguous(), stft3)  <span class="comment"># (B, 3)</span></span><br><span class="line">logits_stable = <span class="variable language_">self</span>.expert_stable(x.contiguous(), stft3)          <span class="comment"># (B, 2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用门控权重加权并合并logits</span></span><br><span class="line">weighted_logits_transition = logits_transition * gate_weights[:, <span class="number">0</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line">weighted_logits_stable = logits_stable * gate_weights[:, <span class="number">1</span>].unsqueeze(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 拼接成最终的5分类输出</span></span><br><span class="line">final_logits = torch.cat([weighted_logits_transition, weighted_logits_stable], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>这次做的时候换了一种思路，不做之前的那种硬门控，转回来做软门控，只需要训练门控输出一个权重系数网络，然后在最后的专家结果上乘以权重系数，拼接一下就能得到最终的结果。并且这样也不会太孤立，如果某个信号特别模棱两可的话，也可以有去处，整个网络可以进行统一的端到端训练，梯度能够完整地反向传播到所有组件，避免了训练断层问题，且每个专家只需要关注专家网络内部的结果是否正常就行了，也就是只需要专门做浅睡眠专家和深睡眠专家，然后由门控网络训练出一个权重系数，这个门控网络就是标准的<code>MOE</code>的门控网络。</p><p>之前做的时候做的是两层<code>Layer</code>结构的网络，在重新读了几篇论文后，发现大部份做都是做三层结构，然后尤其是<code>cVAN</code>按照大中小三个尺度去做<code>CNN_Block</code>，把这些特征拿回来做注意力，所以想了想还是对齐这种结构，同时选择用两层<code>Layer</code>做两个专家的共享骨干，剩下每个专家独占一个<code>Layer</code>，这样还能共享上面两层<code>Layer</code>的特征，网络也不至于做的很臃肿，推理速度也保证了，也算是解决了之前遗留的一系列问题。然后同时边上是一条类似<code>cVAN</code>那种卷积块的结构，每层拉回来一个,分别是大中小三个维度不同层级的<code>STFT</code>特征，捕获不同时间尺度的睡眠模式，然后把这些<code>STFT</code>信号作为<code>Query</code>丢到<code>Window Attention</code>里面做注意力计算，刚好三层特征<code>STFT</code>对应三层<code>Layer</code>。</p><p>下面是单层<code>Layer</code>跟<code>CNN Block</code>的大致结构图，骨干网络与两个专家网络做的都是这种结构。</p><p><img src="/img/SwinBlock.png" alt="image.png"></p><p>目前来看,做了粗摸底，效果其实跟单独按照上次的<code>STFT</code>作为<code>Query</code>然后做注意力计算效果差不多,可以认为是一致的，不过我才开始训这种新结构，按直觉来说<code>MOE</code>这种架构效果是会好一些，上限应该也是更高的。之前做的数据分析的结果是能支撑我做这种操作的。不过按这种结构来说的话方法创新会高一截，我做的算是标准结构的<code>MOE</code>了，不是之前那种怪异的。</p><p>不过我还在想能不能多塞一个专家，也就是在第三层跟浅睡眠专家与深睡眠专家并行的做一个完整的五分类专家，第三个专家的输出结果去跟前两个专家的结果结合得到结果，这个暂时搁置，效果存疑。</p><p>现在刚改完架构，还在重新摸这个新结构的底，需要重新调超参数，结果没这么快出来。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报3.0</title>
      <link href="/2025/07/14/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A53.0/"/>
      <url>/2025/07/14/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A53.0/</url>
      
        <content type="html"><![CDATA[<h1 id="当前进展"><a href="#当前进展" class="headerlink" title="当前进展"></a>当前进展</h1><div class="table-container"><table><thead><tr><th></th><th>Fold 0</th><th>Fold 1</th><th>Fold 2</th><th>Fold 3</th><th>Fold 4</th><th>Fold 5</th><th>Fold 6</th><th>Fold 7</th><th>Fold 8</th><th>Fold 9</th></tr></thead><tbody><tr><td>now swin Acc</td><td>0.87337</td><td>0.82766</td><td>0.84383</td><td>0.81774</td><td>0.86543</td><td>0.81774</td><td>0.83036</td><td>0.90825</td><td>0.81047</td><td>0.81853</td></tr><tr><td>history best</td><td>0.87337</td><td>0.82766</td><td>0.84383</td><td>0.81774</td><td>0.86543</td><td>0.82231</td><td>0.85821</td><td>0.90825</td><td>0.81237</td><td>0.82231</td></tr><tr><td>is stft as q</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td><td>no</td></tr></tbody></table></div><h2 id="总ACC-84-31"><a href="#总ACC-84-31" class="headerlink" title="总ACC 84.31"></a>总ACC <code>84.31</code></h2><h2 id="MVF总-84-1"><a href="#MVF总-84-1" class="headerlink" title="MVF总 84.1"></a>MVF总 <code>84.1</code></h2><p>当前调参结果还有点粗，还能继续往细里面跑，可以换随机种子，多试参数，应该还能涨点。<br>当前路线基本对标<code>CVAN</code>，多尺度时空双分支，时频分支经过处理作为<code>windows attention</code> 的 <code>k v</code>，空间图由原始信号<code>stft</code>得到，后经过部份<code>resnet</code>的结构，每层中间拉出一个分支作为<code>attention</code>的<code>q</code>，增强信号表达，原始的<code>swintransformer</code>的<code>qkv</code>完全来自于基础信号，也就是单独的<code>时频</code>，后续可以考虑添加一部份残差连接。但现在并不是所有的折都采用了这种多分支，部份折还未来得及跑，至少从目前来看，只要添加了就能涨点，fold2涨了三个点，fold6涨了两个点，其他正在跑的目测至少是不会掉，所以是可以认为这种修改是有效的。</p><h1 id="下图为cvan架构图"><a href="#下图为cvan架构图" class="headerlink" title="下图为cvan架构图"></a>下图为cvan架构图</h1><p><img src="/img/cvan.png" alt="image.png"></p><p>结构比较类似cvan的结构，但swintransformer层砍成了两层，顶上的CNN块也比cvan少，其余结构比较类似</p><h2 id="关于MoE的进展"><a href="#关于MoE的进展" class="headerlink" title="关于MoE的进展"></a>关于MoE的进展</h2><p>几乎为零，首先，原先我谈到的MoE架构是一个大门控网络，也就是由一层swintransformer作为门控，门控的输出作为索引，作为专家的输入，专家模型也是swintransforemer，但问题在于，粗分类的效果不及预期，准确度算下来可能跟不做MOE的效果是一致的，或者用之前的多分类头的思路，先用二分类头做，再接五分类头，但这样的收益也是不及直接做五分类。我原本想的是，先做二分类，然后根据二分类后的结果，对应去原始的特征里面筛选，哪些是浅睡眠(W N1 N2)，哪些是深睡眠(N3 REM)，但发现这样无法实现，特征是筛不出来的。所以就回到了原点。如果按照上述那种门控的输出作为索引，计算量也上来了，但效果却并没有变好，所以还是选择搁置这个的添加。</p><h2 id="关于强化学习的进展"><a href="#关于强化学习的进展" class="headerlink" title="关于强化学习的进展"></a>关于强化学习的进展</h2><p>关于提到的DPO，可能可以作为后训练阶段的尝试，在完成了现阶段的训练，可以尝试用一个很小的学习率去监督微调，但我认为问题是DPO是直面人类偏好的奖励，一般是在LLM中，去优化偏好导向，但放在这边有个问题，没有所谓的<code>偏好数据对</code>,LLM中的数据大多是通过打分得到的，在这里不可能手动对数据打分，那么就只剩下两条路</p><h1 id="一-、基于某个基础模型作为监督模型去指导它的梯度方向"><a href="#一-、基于某个基础模型作为监督模型去指导它的梯度方向" class="headerlink" title="一 、基于某个基础模型作为监督模型去指导它的梯度方向"></a>一 、基于某个基础模型作为监督模型去指导它的梯度方向</h1><p>在这个基础上用基础模型的输出构成偏好对，但这有个问题，现在拿不到比我这里性能更好的基础模型，如果用效果更差的模型来监督，效果可能来的有限，即使有提升也可能像之前说的只是在随机参数上的一些进步，不是真正的有性能提升。</p><h1 id="二、直接合成"><a href="#二、直接合成" class="headerlink" title="二、直接合成"></a>二、直接合成</h1><p>这里我找到了一个专门用于时间序列领域DPO的强化学习库，链接如下</p><p><a href="https://nanodpo.readthedocs.io/en/stable/README.html">NanoDPO</a><br>这个框架可以直接合成偏好对，只不过是通过一些随机手段合成的，但也可以用监督模型来提供偏好<br>这个框架的效果目前还没有测试，等我调参结束后尝试一下</p><p>总之现在有一些问题，关于AAAI的创新点是否够？性能要做到什么水准够发？然后后续该怎么做？</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目周记录</title>
      <link href="/2025/06/28/%E9%A1%B9%E7%9B%AE%E5%91%A8%E8%AE%B0/"/>
      <url>/2025/06/28/%E9%A1%B9%E7%9B%AE%E5%91%A8%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="项目周记录"><a href="#项目周记录" class="headerlink" title="项目周记录"></a>项目周记录</h1><h2 id="第五周：项目启动与文献调研"><a href="#第五周：项目启动与文献调研" class="headerlink" title="第五周：项目启动与文献调研"></a>第五周：项目启动与文献调研</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>搭建项目所需的基础开发环境。</li><li>进行睡眠分期领域的文献调研，筛选核心复现目标。</li><li>确定首先复现 MVF-SleepNet 论文。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>配置了基于 Python 和 PyTorch 的深度学习环境，安装了必要的科学计算库,cuda，cudnn。</li><li>阅读了多篇关于自动睡眠分期的顶会论文，重点比较了不同模型在处理多模态生理信号上的优劣。深入研究了MVF-SleepNet论文，该论文提出了一种基于多视角融合的睡眠分期网络，通过融合光谱-时间表示和空间-时间表示来提升睡眠分期分类性能。<a href="https://pubmed.ncbi.nlm.nih.gov/36129857/">1</a></li><li>最终选定 MVF-SleepNet，因其创新的多视角融合网络结构（时频图+图网络）具有很强的代表性，在ISRUC-S3数据集上达到了0.821的准确率、0.802的F1分数和0.768的Kappa值。<a href="https://pubmed.ncbi.nlm.nih.gov/36129857/">1</a></li></ol></li><li><p><strong>工作体会</strong>：<br>通过本周的调研，深刻体会到多模态生理信号分析的复杂性。传统的信号处理方法与深度学习的结合是当前的主流趋势。选择一个合适的切入点（复现一篇高质量论文）是启动一个科研项目的关键第一步。MVF-SleepNet的多模态融合思想为后续的技术探索奠定了基础。</p></li></ul><h2 id="第六周：MVF-SleepNet-论文复现"><a href="#第六周：MVF-SleepNet-论文复现" class="headerlink" title="第六周：MVF-SleepNet 论文复现"></a>第六周：MVF-SleepNet 论文复现</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>依据原论文，实现 MVF-SleepNet 的核心网络架构。</li><li>编写针对 ISRUC-S3 数据集的预处理脚本。</li><li>深入理解MVF-SleepNet的技术细节和创新点。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>编码实现了模型的双分支结构：一个分支使用预训练的 VGG-16 处理时频图，另一个分支使用图卷积网络（GCN）处理通道间关系图。MVF-SleepNet通过融合EEG、ECG、EOG和EMG等多模态生理信号，实现了对睡眠阶段的精确分类。<a href="https://pubmed.ncbi.nlm.nih.gov/36129857/">1</a></li><li>编写了数据预处理流程，包括使用短时傅里叶变换（STFT）将时序信号转换为时频图，以及构建代表通道关系的邻接矩阵。理解了该模型如何通过多视角融合来捕获异构信息，包括空间-时间和光谱-时间特征的融合。<a href="https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-025-02995-9">2</a></li></ol></li><li><p><strong>工作体会</strong>：<br>将论文中的模型图转化为实际代码是一项极具挑战的工作，需要对网络每一层的输入输出维度有精确的把握。数据预处理是模型成功复现的基石，其重要性不亚于模型结构本身。MVF-SleepNet的成功在于其有效地利用了多模态信号间的互补信息。</p></li></ul><h2 id="第七周：并行复现与技术拓展"><a href="#第七周：并行复现与技术拓展" class="headerlink" title="第七周：并行复现与技术拓展"></a>第七周：并行复现与技术拓展</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>在调试 MVF-SleepNet 的同时，启动 TSA-Net 模型的复现。</li><li>研究 MSF-SleepNet 和时空图卷积网络等相关技术。</li><li>深入学习TSA论文的轻量级多尺度融合网络设计。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>为提高效率，并行开启了 TSA-Net 的复现工作，该模型专注于睡眠呼吸暂停检测。TSA论文提出了SE-MSCNN（Squeeze-and-Excitation Multi-Scaled CNN），这是一个基于单导联ECG信号的轻量级睡眠呼吸暂停检测方法。<a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122003689">3</a></li><li>深入阅读了其他几篇相关论文，特别是基于图网络的方法。学习了SE-MSCNN的核心设计：多尺度卷积神经网络模块和通道注意力模块，通过三个子神经网络提取不同长度相邻片段的多尺度ECG信息。<a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122003689">3</a></li></ol></li><li><p><strong>工作体会</strong>：<br>并行处理多个任务能有效利用等待模型训练的碎片时间。广泛的技术调研有助于形成更全面的知识体系，避免陷入单一技术路线的局限性中。TSA的轻量级设计思想为后续的模型优化提供了重要启发。</p></li></ul><h2 id="第八周：模型集成与工具链初步构建"><a href="#第八周：模型集成与工具链初步构建" class="headerlink" title="第八周：模型集成与工具链初步构建"></a>第八周：模型集成与工具链初步构建</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>基本完成 MVF-SleepNet 和 TSA-Net 的复现，并与原文指标进行对比。</li><li>将两个模型集成到 Openmanus 智能体框架中。</li><li>开始研究StAGN论文的空间-时间自适应图网络架构。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>对复现模型进行了多轮训练和测试，复现精度与原文存在~2%的差距，初步判断为超参数敏感性导致。TSA模型在Apnea-ECG数据集上表现出色，验证了其轻量级设计的有效性。<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10235715/">4</a></li><li>将训练好的模型权重保存，并编写封装代码，将其注册为 Openmanus 框架中可以被智能体调用的”工具”。同时开始了解StAGN（Spatial-Temporal Adaptive Graph Network）的对比学习机制。<a href="https://github.com/Chen-Junyang-cn/StAGN">5</a></li></ol></li><li><p><strong>工作体会</strong>：<br>从独立的模型代码到可被调用的”工具”，是科研成果走向应用的关键一步。这个过程需要考虑接口的标准化和模块化，为后续构建复杂的应用流程打下基础。不同模型的技术特点为构建多样化的工具链提供了丰富的选择。</p></li></ul><h2 id="第九周：睡眠分析工具链开发"><a href="#第九周：睡眠分析工具链开发" class="headerlink" title="第九周：睡眠分析工具链开发"></a>第九周：睡眠分析工具链开发</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>开发自动化脚本，串联起数据处理、模型推理和报告生成的全过程。</li><li>实现睡眠分析报告的可视化输出。</li><li>深入研究StAGN的对比学习机制在睡眠分期中的应用。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>编写了一个主控制脚本，该脚本能够引导智能体按顺序调用数据加载、睡眠分期、呼吸暂停检测等工具。</li><li>使用 Matplotlib 等库，将模型的输出结果（如各睡眠阶段占比、呼吸暂停事件次数）绘制成图表，并自动生成一份图文并茂的PDF报告。</li><li>学习了StAGN如何通过对比学习来改进MSTGCN（Multi-View Spatial-Temporal Graph Convolutional Networks），理解其在处理EEG信号空间-时间关系方面的优势。<a href="https://www.researchgate.net/publication/369980943_StAGN_Spatial-Temporal_Adaptive_Graph_Network_via_Contrastive_Learning_for_Sleep_Stage_Classification">6</a></li></ol></li><li><p><strong>工作体会</strong>：<br>一个完整的端到端工具链能极大地提升工作效率，并使得研究成果更具展示性。看到原始数据能自动”流淌”成一份分析报告，非常有成就感。StAGN的对比学习思想为后续的模型改进提供了新的思路。</p></li></ul><h2 id="第十周：性能瓶颈分析与强化学习引入"><a href="#第十周：性能瓶颈分析与强化学习引入" class="headerlink" title="第十周：性能瓶颈分析与强化学习引入"></a>第十周：性能瓶颈分析与强化学习引入</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>详细分析 MVF-SleepNet 的性能瓶颈。</li><li>决定引入强化学习进行模型优化，并设计初步的奖励函数。</li><li>开始深入学习PPO（Proximal Policy Optimization）算法。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>通过分析混淆矩阵，发现绝大多数分类错误发生在 W、N1、N2 等阶段的转换边界，这表明模型缺乏时序连续性考量。</li><li>为此，构想了利用强化学习对模型输出序列进行”后处理”优化的思路，并设计了包含分类精度（r_cls）和平滑度（r_sm）的初始奖励函数。</li><li>深入研究了PPO算法的核心思想：通过裁剪机制来限制策略更新的幅度，避免过大的策略变化导致训练不稳定。PPO是一种策略梯度方法，相比TRPO更简单易实现，同时保持了良好的样本效率。<a href="https://arxiv.org/abs/1707.06347">7</a></li></ol></li><li><p><strong>工作体会</strong>：<br>单纯追求分类准确率是不够的，特别是在序列任务中。模型的输出必须符合领域的先验知识（如睡眠阶段不会频繁跳变）。强化学习为引入这类复杂的序列级约束提供了一个强大的框架。PPO的保守性设计理念与我们的需求高度契合。</p></li></ul><h2 id="第十一周：强化学习奖励函数设计"><a href="#第十一周：强化学习奖励函数设计" class="headerlink" title="第十一周：强化学习奖励函数设计"></a>第十一周：强化学习奖励函数设计</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>对强化学习的奖励函数进行扩展，引入更多领域知识。</li><li>完成了包含四个分量的复杂奖励函数的设计。</li><li>深入理解PPO的技术细节和实现要点。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>为了让模型学习到更真实的睡眠转换模式，我们从训练集中统计了真实的阶段转移概率矩阵，并将其作为奖励（r_trans）。</li><li>同时，我们为每个睡眠阶段定义了其在整晚中通常出现的时间区间，并以此设计了时间分布奖励（r_time）。</li><li>学习了PPO的核心机制：通过概率比率裁剪来实现保守的策略更新。PPO使用替代目标函数，通过限制新旧策略间的KL散度来确保训练稳定性，相比其他强化学习算法需要更少的超参数调优。<a href="https://en.wikipedia.org/wiki/Proximal_policy_optimization">8</a></li></ol></li><li><p><strong>工作体会</strong>：<br>奖励函数的设计是强化学习应用的核心与难点。它本质上是将复杂的、有时甚至是模糊的领域知识，翻译成一个精确的数学优化目标。这个过程极具创造性。PPO的设计哲学体现了在性能和稳定性之间寻求平衡的重要性。</p></li></ul><h2 id="第十二周：强化学习实验与结果分析"><a href="#第十二周：强化学习实验与结果分析" class="headerlink" title="第十二周：强化学习实验与结果分析"></a>第十二周：强化学习实验与结果分析</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>全面开展基于新奖励函数的强化学习微调实验。</li><li>分析实验结果，评估强化学习方法的有效性。</li><li>对比REINFORCE和PPO算法的性能差异。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>使用简单的 REINFORCE 算法，在预训练的 MVF-SleepNet 模型上进行策略梯度更新。</li><li>在10折交叉验证的框架下进行实验，发现模型在 fold-8 上性能提升明显，但在其他 folds 上效果不佳，甚至出现了训练后期准确率断崖式下跌的现象。</li><li>分析了PPO相比REINFORCE的优势：PPO通过裁剪机制避免了过大的策略更新，理论上应该更稳定。PPO的保守优势估计可以防止智能体因高优势估计而做出过大的策略变化。<a href="https://en.wikipedia.org/wiki/Proximal_policy_optimization">8</a></li></ol></li><li><p><strong>工作体会</strong>：<br>强化学习的训练过程非常不稳定，对超参数和初始化极其敏感。在某个子集上的成功，并不能保证其泛化能力。这次实验让我对RL的”美好愿景”和”残酷现实”都有了更清醒的认识。PPO的设计理念虽然先进，但在具体应用中仍需要大量的调试和优化。</p></li></ul><h2 id="第十三周：强化学习问题排查"><a href="#第十三周：强化学习问题排查" class="headerlink" title="第十三周：强化学习问题排查"></a>第十三周：强化学习问题排查</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>深入排查强化学习模型不稳定的原因。</li><li>尝试使用更先进的 PPO 算法进行优化。</li><li>分析PPO算法在睡眠分期任务中的适用性。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>系统分析了失败案例，推测问题可能源于奖励函数设计不当、模型过拟合或探索不足。</li><li>为此，我们实现了更稳定的 PPO 算法，它通过 Clip 机制限制策略更新幅度。然而，尽管尝试了多组超参数，模型不收敛的问题依旧存在。</li><li>深入分析了PPO的裁剪目标函数，理解了其如何通过限制概率比率来实现保守更新。<a href="https://paperswithcode.com/method/ppo">9</a></li></ol></li><li><p><strong>工作体会</strong>：<br>当一个方法行不通时，有时问题不在于算法本身，而在于问题定义或数据层面。这次失败促使我从对算法的”迷信”中走出来，开始重新审视问题本身。PPO虽然在很多任务上表现出色，但并非万能的解决方案。</p></li></ul><h2 id="第十四周：研究方向调整与深度数据分析"><a href="#第十四周：研究方向调整与深度数据分析" class="headerlink" title="第十四周：研究方向调整与深度数据分析"></a>第十四周：研究方向调整与深度数据分析</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>暂停强化学习方向，将研究重心转向对原始数据的深度分析。</li><li>对整个数据集的宏观统计特征进行分析。</li><li>开始研究MOE（Mixture of Experts）架构的理论基础。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>编写了一系列数据分析脚本，使用 Pandas 和 Seaborn 等工具。</li><li>系统性地计算并可视化了全局的睡眠阶段分布、阶段转移概率矩阵、各阶段平均持续时间等，形成了一份详细的数据分析报告。</li><li>开始学习MOE的核心思想：通过多个专家网络来处理不同的输入子空间，每个专家专门处理特定类型的数据。MOE使用门控网络来决定哪些专家应该被激活来处理给定的输入。<a href="https://en.wikipedia.org/wiki/Mixture_of_experts">10</a></li></ol></li><li><p><strong>工作体会</strong>：<br>“回到数据”是解决研究瓶颈的法宝。数据中蕴含着模型性能天花板的答案。通过细致的数据分析，我们能发现许多之前被忽略的关键信息，为后续的模型改进指明方向。MOE的思想为处理异构数据提供了新的视角。</p></li></ul><h2 id="第十五周：个体差异性分析"><a href="#第十五周：个体差异性分析" class="headerlink" title="第十五周：个体差异性分析"></a>第十五周：个体差异性分析</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>对不同受试者之间的个体睡眠差异进行量化分析。</li><li>基于分析结果，对受试者进行模式分类。</li><li>深入研究MOE在处理异构数据方面的优势。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>在10折交叉验证的每一折上，重复了上一周的宏观数据分析流程，从而得到了每个受试者的睡眠模式画像。</li><li>对比发现，不同个体在清醒占比、N1-N2转换频率等指标上差异巨大。据此，我们将受试者粗略分为”稳定型”、”过渡型”等几类。</li><li>学习了MOE如何通过条件计算来实现稀疏性：不是对每个输入使用整个网络，而是学习一个计算成本低的映射函数来确定网络的哪些部分最有效地处理给定输入。<a href="https://www.ibm.com/think/topics/mixture-of-experts">11</a></li></ol></li><li><p><strong>工作体会</strong>：<br>这是项目的一个关键转折点。我们终于意识到，将所有受试者的数据视为同质的是一个错误的假设。个体差异性是导致单一模型（无论是普通监督学习还是强化学习）泛化能力差的根本原因。MOE架构正是为了解决这种数据异构性问题而设计的。</p></li></ul><h2 id="第十六周：多专家模型架构设计"><a href="#第十六周：多专家模型架构设计" class="headerlink" title="第十六周：多专家模型架构设计"></a>第十六周：多专家模型架构设计</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>基于个体差异性的发现，设计一种新的、更具适应性的模型架构。</li><li>提出了层次化多专家（Mixture of Experts, MOE）模型方案。</li><li>深入理解MOE的路由机制和专家选择策略。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>借鉴大语言模型中的 MOE 思想，我们设计了一个两层分类系统。</li><li>第一层是一个”门控网络”，负责判断当前睡眠片段属于”稳定阶段”还是”过渡阶段”。第二层是两个”专家网络”，分别针对这两种不同难度的情况进行精细化分类。</li><li>学习了现代MOE的关键设计选择：如何将查询路由到最佳专家。稀疏门控MOE层使用前馈网络作为专家，并采用线性-softmax门控机制。在Transformer模型中，MOE层通常用于选择前馈层。<a href="https://en.wikipedia.org/wiki/Mixture_of_experts">10</a></li></ol></li><li><p><strong>工作体会</strong>：<br>好的模型设计源于对数据和问题的深刻理解。MOE 架构的提出，正是为了应对数据异构性的挑战。将其他领域的先进思想（如NLP）引入到自己的研究中，是重要的创新途径。MOE的条件计算机制为处理复杂的多模态数据提供了有效的解决方案。</p></li></ul><h2 id="第十七周：Swin-Transformer-新架构探索"><a href="#第十七周：Swin-Transformer-新架构探索" class="headerlink" title="第十七周：Swin Transformer 新架构探索"></a>第十七周：Swin Transformer 新架构探索</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>探索将前沿的 Vision Transformer 模型应用于1D生理信号分析。</li><li>设计并实现了一个基于 Swin Transformer 的睡眠分期模型。</li><li>深入学习Swin Transformer的移位窗口机制和层次化设计。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>将 Swin Transformer 的核心思想（窗口化自注意力、层级化特征提取）适配到1D时序数据上。</li><li>实现了包括 PatchEmbed1D、Window Attention 1D、Patch Merging 等核心模块，并设计了一个多尺度融合模块来聚合不同阶段的特征。</li><li>深入理解了Swin Transformer的创新点：通过移位窗口方案实现更高效的自注意力计算，同时允许跨窗口连接。Swin Transformer解决了Vision Transformer在处理不同尺度视觉实体和高分辨率图像时的挑战。<a href="https://arxiv.org/abs/2103.14030">12</a></li></ol></li><li><p><strong>工作体会</strong>：<br>技术迁移是推动领域发展的重要动力。将一个为2D图像设计的SOTA模型成功改造并应用于1D时序信号，这个过程虽然充满挑战，但也极大地锻炼了我的模型设计与实现能力。Swin Transformer的层次化设计和移位窗口机制为处理长序列数据提供了新的思路。</p></li></ul><h2 id="第十八周：新架构评估与项目总结"><a href="#第十八周：新架构评估与项目总结" class="headerlink" title="第十八周：新架构评估与项目总结"></a>第十八周：新架构评估与项目总结</h2><ul><li><p><strong>工作内容</strong>：</p><ol><li>对新设计的 Swin Transformer 模型进行全面的性能评估。</li><li>完成项目总结报告和最终版工具链的文档。</li><li>总结整个项目中涉及的关键技术和创新点。</li></ol></li><li><p><strong>工作过程</strong>：</p><ol><li>在与 MVF-SleepNet 完全相同的实验设置下，训练并测试了 Swin Transformer 模型。</li><li>实验结果显示，新模型在准确率、F1-Score 等多项关键指标上均取得了超越基线的性能，验证了其有效性。Swin Transformer在COCO数据集上相比之前的SOTA模型有+2.7 box AP和+2.6 mask AP的显著提升。<a href="https://arxiv.org/abs/2103.14030">12</a></li><li>最后，系统性地梳理了整个项目从启动到最终成果的全过程，完成了周记和项目报告的撰写。总结了从MVF-SleepNet的多模态融合、TSA的轻量级设计、StAGN的对比学习、PPO的强化学习优化、MOE的专家混合机制，到Swin Transformer的层次化注意力等关键技术的学习和应用。</li></ol></li><li><p><strong>工作体会</strong>：<br>这个项目是一次完整的科研历程体验。从最初的文献调研，到模型复现，再到创新性的架构设计，每一个阶段都有其独特的挑战和收获。特别是在遇到强化学习方法失败后，能够及时调整研究方向，回归数据本身，最终找到问题的根源（个体差异性），这个过程让我深刻体会到科研中”试错”和”迭代”的重要性。技术的融合与创新往往来源于跨领域的思维碰撞，无论是将NLP中的MOE思想引入睡眠分析，还是将Vision Transformer适配到1D信号处理，都体现了这一点。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多模态智能体的睡眠分析平台</title>
      <link href="/2025/06/19/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
      <url>/2025/06/19/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>睡眠是人类一项基本但复杂的生命活动，对于身体修复、记忆巩固和整体健康至关重要。通过科学的睡眠状态识别与分类，我们不仅可以更好地了解自身的健康状况，还能及早发现潜在的健康问题。本项目将介绍一个基于多模态智能体的睡眠分析工具链，它集成了先进的深度学习模型，用于自动化的睡眠分期以及睡眠呼吸暂停检测，并最终生成一份详尽的睡眠分析报告。</p><h2 id="睡眠分期：探索睡眠的奥秘"><a href="#睡眠分期：探索睡眠的奥秘" class="headerlink" title="睡眠分期：探索睡眠的奥秘"></a>睡眠分期：探索睡眠的奥秘</h2><p>根据美国睡眠医学会（AASM）的标准，人类睡眠过程主要分为两个阶段：快速眼动（REM）睡眠和非快速眼动（NREM）睡眠。其中，NREM睡眠又可细分为三个阶段：N1、N2和N3。每个阶段都对应着不同的大脑、眼睛和肌肉活动模式。</p><p>传统的睡眠分期依赖于睡眠专家对多导睡眠图（Polysomnography, PSG）进行人工判读。PSG记录了包括脑电图（EEG）、眼电图（EOG）、心电图（ECG）和肌电图（EMG）在内的多种生理信号。然而，这种人工判读方法不仅耗时耗力，而且其结果高度依赖于专家的经验，存在一定的主观性。因此，开发自动化的睡眠分期算法，对于提高诊断效率和客观性具有重要意义。</p><h2 id="睡眠呼吸暂停：沉默的健康杀手"><a href="#睡眠呼吸暂停：沉默的健康杀手" class="headerlink" title="睡眠呼吸暂停：沉默的健康杀手"></a>睡眠呼吸暂停：沉默的健康杀手</h2><p>睡眠呼吸暂停（Sleep Apnea, SA）是一种常见的睡眠障碍，其主要特征是在睡眠过程中反复出现呼吸气流减少或完全停止的现象，每次持续时间超过10秒。这通常是由于上呼吸道（如舌头或软组织）的塌陷所致。呼吸暂停会导致血氧饱和度下降和二氧化碳水平升高，长期以往会引发一系列严重的并发症，如日间嗜睡、疲劳、记忆力减退、中风、心血管疾病等。</p><p>尽管PSG是诊断SA的“金标准”，但其过程繁琐、侵入性强，且需要在医院进行整夜监测，这对于大规模的常规健康筛查构成了挑战。因此，发展便携式、无创的居家睡眠监测技术（如基于物联网的智能设备）成为了当前研究的热点。</p><h2 id="我们的工具链：一个集成的解决方"><a href="#我们的工具链：一个集成的解决方" class="headerlink" title="我们的工具链：一个集成的解决方"></a>我们的工具链：一个集成的解决方</h2><p>为了实现高效、准确的自动化睡眠分析，共复现了七篇睡眠方向论文，选用其中两篇作为基础，构建了一个集成的工具链。该工具链基于 <strong>Openmanus</strong> 框架，整合了两项前沿研究成果，分别用于睡眠分期和呼吸暂停检测。</p><ol><li><p><strong>睡眠分期模块</strong>: 工具采用了 <strong>MVF-SleepNet (Multi-View Fusion Network for Sleep Stage Classification)</strong> 模型。该模型能够有效融合来自不同生理信号（如EEG, EOG）的多视角特征，从而实现对N1, N2, N3, REM等睡眠阶段的精准分类。</p></li><li><p><strong>呼吸暂停检测模块</strong>: 工具集成了 <strong>TSA (Toward sleep apnea detection with lightweight multi-scaled fusion network)</strong> 模型。该网络专为睡眠呼吸暂停检测而设计，它能够高效地处理生理信号，并以较低的计算成本准确识别呼吸暂停事件。</p></li></ol><p>通过这个工具链，我们可以自动化地处理采集到的睡眠数据，并最终生成一份包含睡眠结构、各分期时长、呼吸暂停事件统计等信息的综合性<strong>睡眠状况分析报告</strong>。</p><h2 id="睡眠分期识别模块：MVF-SleepNet介绍"><a href="#睡眠分期识别模块：MVF-SleepNet介绍" class="headerlink" title="睡眠分期识别模块：MVF-SleepNet介绍"></a>睡眠分期识别模块：MVF-SleepNet介绍</h2><p><img src="/img/MVF.png" alt="image.png"></p><p>MVF-SleepNet的核心思想是<strong>多视角特征提取与融合</strong>。从结构图可以看出，它的处理流程如下：</p><ol><li><p><strong>多模态输入与关系表示</strong>：</p><ul><li>模型接收多种生理信号作为输入，包括脑电图（EEG）、眼电图（EOG）、心电图（ECG）和肌电图（EMG）。</li><li>这些原始时序信号被转换为两种不同的关系表示：<ul><li><strong>时频图（TF Image）</strong>：将信号通过时频分析（短时傅里叶变换）转换成图像格式，保留了时间和频率维度的信息。</li><li><strong>图结构（GL Graph）</strong>：将不同信号通道间的关系构建成图，其中节点代表信号通道，边代表它们之间的关联性。</li></ul></li></ul></li><li><p><strong>双分支特征提取</strong>：</p><ul><li><strong>基于图像的特征提取分支</strong>：<ul><li>时频图被送入一个预训练的VGG-16网络来提取空间特征。</li><li>随后，通过一个门控循环单元（GRU）网络及其注意力机制（GRU Att）来捕捉时间序列上的动态变化。</li></ul></li><li><strong>基于图的特征提取分支</strong>：<ul><li>图结构数据首先通过空间注意力（Spatial Att）和时间注意力（Temporal Att）机制来增强重要节点和时间步的特征。</li><li>接着，使用切比雪夫图卷积（Chebyshev Graph Conv）网络来学习图结构中的高阶邻域信息。</li><li>最后，通过一个时间卷积网络（Temporal Conv）来提取时序特征。</li></ul></li></ul></li><li><p><strong>特征融合与分类</strong>：</p><ul><li>两个分支提取出的高级特征被融合（图中由 <code>+</code> 号表示）。</li><li>融合后的特征经过进一步处理，最终送入分类器，输出W、N1、N2、N3、REM这五个睡眠阶段的预测结果。</li></ul></li></ol><p>通过这种方式，MVF-SleepNet能够同时从信号的“形态”（时频图）和“关系”（图结构）两个视角进行学习，从而更全面地捕捉睡眠过程中的复杂模式。</p><h2 id="MVF论文复现情况"><a href="#MVF论文复现情况" class="headerlink" title="MVF论文复现情况"></a>MVF论文复现情况</h2><p>原文使用了ISRUC-S3以及ISRUC-S1两种数据集，S1数据集过大，遂只跑了S3数据集。<br>下面是原文的混淆矩阵以及各项性能指标<br><img src="/img/cm_origin.png" alt="image.png"></p><p><img src="/img/result_origin.png" alt="image.png"></p><h3 id="论文复现结果如下"><a href="#论文复现结果如下" class="headerlink" title="论文复现结果如下"></a>论文复现结果如下</h3><p><img src="/img/cm_now.png" alt="image.png"></p><div class="table-container"><table><thead><tr><th>stage</th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>Wake</td><td>0.8790</td><td>0.8892</td><td>0.8841</td><td>1651</td></tr><tr><td>N1</td><td>0.6368</td><td>0.5556</td><td>0.5934</td><td>1215</td></tr><tr><td>N2</td><td>0.7836</td><td>0.8593</td><td>0.8197</td><td>2609</td></tr><tr><td>N3</td><td>0.9429</td><td>0.8525</td><td>0.8954</td><td>2014</td></tr><tr><td>REM</td><td>0.8382</td><td>0.8991</td><td>0.8675</td><td>1060</td></tr><tr><td>accuracy</td><td></td><td></td><td>0.8252</td><td>8549</td></tr><tr><td>macro avg</td><td>0.8161</td><td>0.8111</td><td>0.8120</td><td>8549</td></tr><tr><td>weighted avg</td><td>0.8255</td><td>0.8252</td><td>0.8238</td><td>8549</td></tr></tbody></table></div><h3 id="Accuracy-0-8252427184466019"><a href="#Accuracy-0-8252427184466019" class="headerlink" title="Accuracy     0.8252427184466019"></a>Accuracy     0.8252427184466019</h3><h3 id="Cohen-Kappa-0-7747536173752807"><a href="#Cohen-Kappa-0-7747536173752807" class="headerlink" title="Cohen Kappa     0.7747536173752807"></a>Cohen Kappa     0.7747536173752807</h3><h3 id="F1-Score-0-8120410271984937"><a href="#F1-Score-0-8120410271984937" class="headerlink" title="F1-Score     0.8120410271984937"></a>F1-Score     0.8120410271984937</h3><h3 id="Precision-0-8161071198851069"><a href="#Precision-0-8161071198851069" class="headerlink" title="Precision     0.8161071198851069"></a>Precision     0.8161071198851069</h3><h3 id="Recall-0-8111271194453279"><a href="#Recall-0-8111271194453279" class="headerlink" title="Recall         0.8111271194453279"></a>Recall         0.8111271194453279</h3><h3 id="结果对比如下"><a href="#结果对比如下" class="headerlink" title="结果对比如下"></a>结果对比如下</h3><div class="table-container"><table><thead><tr><th>对比</th><th>Accuracy</th><th>F1-Score</th><th>Kappa</th></tr></thead><tbody><tr><td>原文</td><td>0.841</td><td>0.828</td><td>0.795</td></tr><tr><td>复现</td><td>0.8252</td><td>0.812</td><td>0.775</td></tr></tbody></table></div><p>可以看到，与原文的性能差距存在，可能是超参数设置不够到位，训练后期收敛的效果稍差</p><h2 id="睡眠呼吸暂停检测模块：轻量级多尺度融合网络-TSA-Net-介绍"><a href="#睡眠呼吸暂停检测模块：轻量级多尺度融合网络-TSA-Net-介绍" class="headerlink" title="睡眠呼吸暂停检测模块：轻量级多尺度融合网络 (TSA-Net)介绍"></a>睡眠呼吸暂停检测模块：轻量级多尺度融合网络 (TSA-Net)介绍</h2><p><img src="/img/TSA.png" alt="image.png"></p><p>TSA-Net的设计精妙且高效，其核心在于<strong>多尺度输入</strong>和<strong>通道注意力机制</strong>，主要处理心电信号衍生的R峰振幅（R peak amplitudes）和R-R间期（R-R intervals）序列。其结构可以分解为以下几个部分：</p><ol><li><p><strong>多尺度输入模块</strong>：</p><ul><li>为了捕捉不同时间尺度下的信号特征，模型将输入的R峰振幅和R-R间期序列分割成三种不同长度的片段：180、540和900个数据点。这对应于不同时长的观测窗口，使得模型能够同时关注短期和长期的信号变化。</li></ul></li><li><p><strong>多尺度CNN模块</strong>：</p><ul><li>三种不同尺度的输入分别被送入三个独立的、结构相似但参数不共享的CNN分支（SA-CNN-1, SA-CNN-2, SA-CNN-3）。</li><li>每个SA-CNN分支由一系列的1D卷积层（Convolutional1D layer）和1D最大池化层（MaxPooling1D layer）组成，用于从相应尺度的数据中提取特征。</li><li>这三个分支的输出特征在通道维度上被堆叠（Feature stacking）起来，形成一个包含了多尺度信息的融合特征图。</li></ul></li><li><p><strong>通道注意力模块 (Channel-wise attention module)</strong>：</p><ul><li>这是模型的核心创新之一。为了让模型能够自适应地关注信息量最丰富的特征通道，这里引入了Squeeze-and-Excitation (SE) block的思想。</li><li><strong>Squeeze操作 (f_sq)</strong>：通过全局平均池化（GlobalAverage Pooling1D）将每个通道的特征压缩成一个单一的数值，得到一个通道描述符。</li><li><strong>Excitation操作 (f_ex)</strong>：这个通道描述符经过两个全连接层（Fully connected layer），学习各个通道之间的非线性关系，并输出每个通道的权重（即重要性得分）。</li><li><strong>Scale操作 (f_scale)</strong>：将学习到的通道权重乘回到原始的多尺度融合特征图上，从而对不同通道的特征进行重新加权，增强重要特征，抑制次要特征。</li></ul></li><li><p><strong>输出模块</strong>：</p><ul><li>经过注意力模块加权后的特征图，最终通过一个全连接层和Softmax层，输出对睡眠呼吸暂停事件的检测结果。</li></ul></li></ol><p>通过这种多尺度分析和通道注意力的结合，TSA-Net能够在保持轻量级的同时，高效地从心电信号中提取出与呼吸暂停相关的关键生物标志物，实现精准检测。</p><h2 id="TSA论文复现情况"><a href="#TSA论文复现情况" class="headerlink" title="TSA论文复现情况"></a>TSA论文复现情况</h2><p>原文使用了PhysioNet Apnea‑ECG数据集，复现同样选用该数据集，使用相同的参数训练，原文数据如下</p><p><img src="/img/TSA_res.png" alt="image.png"></p><p><img src="/img/cm_TSA.png" alt="image.png"></p><h3 id="论文复现结果如下-1"><a href="#论文复现结果如下-1" class="headerlink" title="论文复现结果如下"></a>论文复现结果如下</h3><p><img src="/img/cm_TSA_now.png" alt="image.png"></p><h3 id="结果对比如下-1"><a href="#结果对比如下-1" class="headerlink" title="结果对比如下"></a>结果对比如下</h3><div class="table-container"><table><thead><tr><th>对比</th><th>Acc</th><th>Sens</th><th>Spec</th></tr></thead><tbody><tr><td>原文</td><td>90.6</td><td>86.0</td><td>93.5</td></tr><tr><td>复现</td><td>89.23</td><td>85.07</td><td>92.74</td></tr></tbody></table></div><p>可以看到，与原文的性能差距较小，效果较好</p><h2 id="睡眠分析工具链使用状况："><a href="#睡眠分析工具链使用状况：" class="headerlink" title="睡眠分析工具链使用状况："></a>睡眠分析工具链使用状况：</h2><h3 id="睡眠阶段分析报告："><a href="#睡眠阶段分析报告：" class="headerlink" title="睡眠阶段分析报告："></a>睡眠阶段分析报告：</h3><p><img src="/img/MVF_result.png" alt="image.png"></p><h3 id="睡眠呼吸暂停检测报告"><a href="#睡眠呼吸暂停检测报告" class="headerlink" title="睡眠呼吸暂停检测报告"></a>睡眠呼吸暂停检测报告</h3><p><img src="/img/TSA_result.png" alt="image.png"></p><p>至此，我们得到了在数据集上所有受试者的睡眠分析报告</p><h2 id="未来展望：引入Swin-Transformer进行睡眠分期"><a href="#未来展望：引入Swin-Transformer进行睡眠分期" class="headerlink" title="未来展望：引入Swin Transformer进行睡眠分期"></a>未来展望：引入Swin Transformer进行睡眠分期</h2><p>尽管现有的模型已经取得了不错的成果，但我们仍在探索更先进的架构以提升性能。我们提出一种新的设想，即采用 <strong>Swin Transformer</strong> 模型来进行睡眠分期。Swin Transformer是一种基于自注意力机制的层级式视觉Transformer，我们将其思想应用于1D时序信号处理，以期获得更好的性能。</p><p>设计的基于Swin Transformer的睡眠分期模型结构如下图所示，主要包含三个核心部分：<strong>编码器（Encoder）</strong>、<strong>多尺度融合（Multi Fusion）</strong> 和 <strong>分类头（Classification Head）</strong>。</p><p><img src="/img/swintransformer.png" alt="image.png"></p><h3 id="1-编码器-Encoder"><a href="#1-编码器-Encoder" class="headerlink" title="1. 编码器 (Encoder)"></a>1. 编码器 (Encoder)</h3><p>编码器是模型的主干，负责从输入的生理信号序列中提取层级化的特征。其工作流程如下：</p><ul><li><p><strong>输入与嵌入 (Input &amp; PatchEmbed)</strong>: 模型接收多通道生理信号（如ECG, EOG, EMG, EEG）组成的时间序列作为输入。首先，通过一个<code>PatchEmbed1D</code>模块，将输入序列分割成不重叠的“补丁”（Patches），并通过一个1D卷积将其线性嵌入到高维特征空间，这类似于NLP中的词嵌入过程。</p></li><li><p><strong>Swin Transformer 模块</strong>: 嵌入后的序列被送入一系列串联的Swin Transformer模块。每个模块包含：</p><ul><li><strong>窗口化多头自注意力 (Window Attention 1D)</strong>: 为了降低计算复杂度，自注意力计算被限制在不重叠的局部窗口内。为了实现跨窗口的信息交互，后续的模块会采用<strong>移位窗口（Shifted Window）</strong>的策略。</li><li><strong>多层感知机 (MLP)</strong>: 一个标准的MLP块，用于进一步的特征变换。</li><li><strong>残差连接与层归一化</strong>: 每个注意力模块和MLP模块之后都使用了残差连接（Add）和层归一化（Layer Norm），以保证训练的稳定性。</li></ul></li><li><p><strong>补丁合并 (Patch Merging)</strong>: 在每个阶段（Stage）之间，通过<code>PatchMerging</code>模块对特征进行降采样。它将相邻的补丁合并，从而在减少序列长度的同时增加特征维度，构建出层级式的特征金字塔。</p></li></ul><h3 id="2-多尺度融合-Multi-Fusion"><a href="#2-多尺度融合-Multi-Fusion" class="headerlink" title="2. 多尺度融合 (Multi Fusion)"></a>2. 多尺度融合 (Multi Fusion)</h3><p>为了充分利用编码器在不同阶段（Stage1, Stage2, Stage3, Stage4）提取出的多尺度特征，我们设计了一个多尺度融合模块：</p><ul><li>编码器每个阶段输出的特征图代表了不同层次的抽象信息。我们将这些特征图通过<strong>插值（Interpolate）</strong>操作上采样到相同的尺寸。</li><li>然后，将所有上采样后的特征图在通道维度上<strong>拼接（Concat）</strong>起来，形成一个富含多尺度信息的融合特征。</li><li>这个融合后的特征通过一个残差连接加到编码器最后一层的输出上，进一步增强了最终特征的表达能力。</li></ul><h3 id="3-分类头-Classification-Head"><a href="#3-分类头-Classification-Head" class="headerlink" title="3. 分类头 (Classification Head)"></a>3. 分类头 (Classification Head)</h3><p>最终的特征被送入分类头，以得出睡眠分期的结果：</p><ul><li>首先经过一层<strong>层归一化 (Layer Norm)</strong>。</li><li>然后通过<strong>全局平均池化 (Global AvgPool)</strong>将序列特征聚合为单个特征向量。</li><li>最后，一个<strong>全连接层 (FC)</strong> 将该向量映射到最终的类别数（如W, N1, N2, N3, REM五个阶段），输出Logits。</li></ul><p>通过这种结合了Swin Transformer的层级化特征提取能力和多尺度融合策略的架构，能够更有效地捕捉睡眠生理信号中的复杂动态，从而在自动睡眠分期任务上取得更优越的性能。</p><h2 id="新架构效果"><a href="#新架构效果" class="headerlink" title="新架构效果"></a>新架构效果</h2><h3 id="原架构MVF在pytorch中的效果如下"><a href="#原架构MVF在pytorch中的效果如下" class="headerlink" title="原架构MVF在pytorch中的效果如下"></a>原架构MVF在pytorch中的效果如下</h3><p><img src="/img/cm_MVF_torch.png" alt="image.png"></p><div class="table-container"><table><thead><tr><th>stage</th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>Wake</td><td>0.8625</td><td>0.8740</td><td>0.8682</td><td>1651</td></tr><tr><td>N1</td><td>0.6021</td><td>0.5144</td><td>0.5548</td><td>1215</td></tr><tr><td>N2</td><td>0.7838</td><td>0.8406</td><td>0.8112</td><td>2609</td></tr><tr><td>N3</td><td>0.9119</td><td>0.8734</td><td>0.8922</td><td>2014</td></tr><tr><td>REM</td><td>0.8344</td><td>0.8745</td><td>0.8540</td><td>1060</td></tr><tr><td>accuracy</td><td></td><td></td><td>0.8126</td><td>8549</td></tr><tr><td>macro avg</td><td>0.7989</td><td>0.7954</td><td>0.7961</td><td>8549</td></tr><tr><td>weighted avg</td><td>0.8096</td><td>0.8126</td><td>0.8102</td><td>8549</td></tr></tbody></table></div><h3 id="新架构的结果如下"><a href="#新架构的结果如下" class="headerlink" title="新架构的结果如下"></a>新架构的结果如下</h3><p><img src="/img/cm_swin.png" alt="image.png"></p><div class="table-container"><table><thead><tr><th>对比</th><th>Accuracy</th><th>F1-Score</th><th>Kappa</th></tr></thead><tbody><tr><td>MVF-torch</td><td>0.8126</td><td>0.7960</td><td>0.758</td></tr><tr><td>swin</td><td>0.8319</td><td>0.815</td><td>0.781</td></tr></tbody></table></div><p>可以看到，对比在pytorch中的MVF架构，现有架构展现了更好的性能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>该项目成功构建了一个集成的多模态睡眠分析工具链，旨在自动化和精确化睡眠健康评估。该工具链核心包含两个先进的深度学习模型：</p><ol><li>MVF-SleepNet ：用于睡眠分期，通过融合多视角生理信号（如EEG、EOG）的特征，实现对睡眠阶段（W, N1, N2, N3, REM）的准确分类。</li><li>TSA-Net ：一个轻量级网络，专门用于检测睡眠呼吸暂停事件，它高效处理心电信号衍生的数据，在保持较低计算成本的同时实现了高精度检测。</li></ol><h2 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h2><p>为了进一步提升睡眠分期的准确性，项目探索了更前沿的模型架构，并提出了一种基于 Swin Transformer 的新方法。该模型的核心优势在于：</p><ul><li>层级化特征提取 ：借鉴其在视觉领域的成功，将Swin Transformer应用于一维时序信号，通过窗口化自注意力和补丁合并机制，有效捕捉生理信号从局部到全局的层级化特征。</li><li>多尺度特征融合 ：融合编码器在不同阶段输出的特征，以获得更丰富的表征，从而增强模型的判别能力。<br>初步实验结果令人鼓舞，显示新的Swin Transformer架构在关键性能指标（如Accuracy, F1-Score, Kappa）上均优于基线MVF模型。未来的工作将聚焦于：</li></ul><ol><li>模型优化 ：对Swin Transformer模型的超参数进行精细调优，并探索更有效的特征融合策略，以充分挖掘其性能潜力。</li><li>模型集成 ：将优化后的新模型集成到现有的睡眠分析工具链中，以替代或补充原有的睡眠分期模块。</li><li>功能扩展 ：考虑将工具链扩展到更多睡眠相关事件的检测，并探索在更大、更多样化的数据集上验证模型的泛化能力，最终推动其在临床辅助诊断和个人健康管理领域的应用。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>昇腾AI创新算子挑战赛S4赛季</title>
      <link href="/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/"/>
      <url>/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="昇腾AI创新算子挑战赛S4赛季"><a href="#昇腾AI创新算子挑战赛S4赛季" class="headerlink" title="昇腾AI创新算子挑战赛S4赛季"></a>昇腾AI创新算子挑战赛S4赛季</h1><p>本项目是昇腾AI创新算子挑战赛S4赛季的开源代码。</p><h2 id="行业背景"><a href="#行业背景" class="headerlink" title="行业背景"></a>行业背景</h2><p>人工智能、云计算、边缘计算等领域的计算需求的爆发式增长带动了GPU计算能力的发展。这些领域都依赖高性能算法来实现特定的需求，而作为算法核心执行单元的算子，负责实现基础的数学运算和逻辑运算。算子的性能直接影响整个算法的性能。算子也是软件和硬件之间的桥梁，是算法得以落地的关键环节，已经成为推动计算机技术进步和算法产业应用发展的核心动力。<br><img src="/img/cuda.png" alt="image.png"><br>主流的PyTorch、TensorFlow、Caffe等人工智能框架中使用的算子已相当成熟，这些算子基于GPU算力的CUDA、cuDNN等平台实现。</p><h3 id="昇腾计算产业"><a href="#昇腾计算产业" class="headerlink" title="昇腾计算产业"></a>昇腾计算产业</h3><p>昇腾计算产业是华为公司推出的一系列人工智能解决方案，基于昇腾硬件处理器和配套软件设施所构建的全栈人工智能技术应用和服务，包括昇腾系列训练和推理芯片、CANN软件栈、深度学习计算框架、应用开发工具、应用管理运维工具、工业级服务等多种产业链，为国内人工智能的研究提供了强大的计算能力和全面的软硬件支持。<br><img src="/img/cann.png" alt="image.png"></p><h3 id="AscendC算子编程介绍"><a href="#AscendC算子编程介绍" class="headerlink" title="AscendC算子编程介绍"></a>AscendC算子编程介绍</h3><p>基于Ascend C方式实现基础矢量算子核函数的流程如下图所示。<br><img src="/img/con.png" alt="image.png"></p><ul><li>算子分析：分析算子的数学表达式、输入、输出以及计算逻辑的实现，明确需要调用的Ascend C接口。</li><li>核函数定义：定义Ascend C算子入口函数。</li><li>根据矢量编程范式实现算子类：完成核函数的内部实现，包括3个基本任务：CopyIn，Compute，CopyOut。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAdd</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 不同核根据各自的block_idx设置数据地址</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)x + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)y + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)z + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        <span class="comment">// Queue初始化，单位为字节</span></span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueY, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">CopyIn</span>();</span><br><span class="line">        <span class="built_in">Compute</span>();</span><br><span class="line">        <span class="built_in">CopyOut</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现核函数</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化算子类，算子类提供算子初始化和核心处理等方法</span></span><br><span class="line">    KernelAdd op;</span><br><span class="line">    <span class="comment">// 初始化函数，获取该核函数需要处理的输入输出地址，同时完成必要的内存初始化工作</span></span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, z);</span><br><span class="line">    <span class="comment">// 核心处理函数，完成算子的数据搬运与计算等核心逻辑</span></span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下图为AscendC编程过程中抽象表示的硬件架构图<br><img src="/img/vector.png" alt="image.png"></p><h2 id="赛题列表"><a href="#赛题列表" class="headerlink" title="赛题列表"></a>赛题列表</h2><p>以下是本次S4赛季的赛题列表：</p><ul><li>[x] Reshape  (demo)</li><li>[x] RmsNorm  (demo)</li><li>[x] SelectV2 (AC)</li><li>[x] Pows     (AC)</li><li>[ ] Gather</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>针对已完成的算子，后续的优化方向包括：</p><ul><li><strong>SelectV2 &amp; Pows</strong>:<ul><li>细分广播与非广播场景的实现，进行针对性优化。</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li></ul><p>针对未完成的算子，后续的完善过程包括：</p><ul><li><strong>Reshape</strong>:<ul><li>重写输出shape函数，符合正常reshape函数逻辑</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li><li><strong>RmsNorm</strong>:<ul><li>解决数据未完全对齐的问题</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li></ul><hr><h1 id="Pows算子实现详解"><a href="#Pows算子实现详解" class="headerlink" title="Pows算子实现详解"></a>Pows算子实现详解</h1><h2 id="算子概述"><a href="#算子概述" class="headerlink" title="算子概述"></a>算子概述</h2><p>Pows算子实现了幂运算功能，即计算<code>y = x1^x2</code>，其中x1为底数，x2为指数。该算子需支持广播机制，能够处理不同形状的输入张量。</p><p>算法实现原理：<code>pow(x1, x2) = exp(x2 * ln(x1))</code></p><h2 id="kernel侧实现"><a href="#kernel侧实现" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><h3 id="1-完成pow-cpp文件-这里是算子的入口"><a href="#1-完成pow-cpp文件-这里是算子的入口" class="headerlink" title="1. 完成pow.cpp文件,这里是算子的入口"></a>1. 完成pow.cpp文件,这里是算子的入口</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 引入必要的头文件</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span>  <span class="comment">// AscendC核心算子开发框架</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pow.h&quot;</span>              <span class="comment">// 非广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;powb.h&quot;</span>             <span class="comment">// 广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 算子入口函数，使用extern &quot;C&quot;确保C++函数能被C代码调用</span></span><br><span class="line"><span class="comment">// __global__表示这是一个设备端函数，__aicore__表示运行在AI Core上</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">pows</span><span class="params">(GM_ADDR x1,GM_ADDR x2, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR y, GM_ADDR workspace, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;  <span class="comment">// 这里有个细节，建议在最开始就定义好pipe对象，然后通过传参数</span></span><br><span class="line">                 <span class="comment">//  再进到Init中，有一定性能优化</span></span><br><span class="line">    <span class="comment">// 根据tiling key选择不同的实现策略</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">1</span>))&#123; <span class="comment">// tiling key为1：非广播场景</span></span><br><span class="line">        KernelPows op;  <span class="comment">// 创建非广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">2</span>))&#123; <span class="comment">// tiling key为2：广播场景</span></span><br><span class="line">        KernelPowsBroadCast op;  <span class="comment">// 创建广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 以下是针对不同数据类型的扩展实现（当前注释掉）</span></span><br><span class="line">    <span class="comment">// 可以根据需要细分fp16和fp32的非广播和广播实现</span></span><br><span class="line">    <span class="comment">// if(TILING_KEY_IS(1))&#123; // fp16非广播</span></span><br><span class="line">    <span class="comment">//     KernelPows op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(2))&#123; // fp32非广播</span></span><br><span class="line">    <span class="comment">//      op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(3))&#123; // fp16广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastB op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(4))&#123; // fp32广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastBB op;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-非广播场景实现-pow-h"><a href="#2-非广播场景实现-pow-h" class="headerlink" title="2. 非广播场景实现 (pow.h)"></a>2. 非广播场景实现 (pow.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;  <span class="comment">// 双缓冲机制，提高数据传输效率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非广播场景的Pows算子实现类（tiling key 1）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPows</span>&#123; </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPows</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化tiling参数，从host侧传递的tiling数据中获取分块信息</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);  <span class="comment">// 获取tiling数据结构</span></span><br><span class="line">            totalLength = tiling_data.totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;    <span class="comment">// 每个tile的长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;      <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;          <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化算子，设置全局内存地址和缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);  <span class="comment">// 初始化tiling参数</span></span><br><span class="line">    </span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);  <span class="comment">// 确保block数量不为0</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，将GM地址转换为GlobalTensor</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;  <span class="comment">// 保存pipe指针</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化输入输出队列，使用双缓冲提高效率</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX1, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX2, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 对于half类型，把half转成float，要不然精度不够</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 主处理函数，按tile进行循环处理</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 处理完整的tile</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(i,  <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将数据从GM拷贝到UB</span></span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 在UB中进行计算</span></span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将结果从UB拷回GM</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余的不足一个tile的数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 数据输入函数：从全局内存拷贝数据到本地缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 分配本地tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 从全局内存拷贝数据到本地tensor</span></span><br><span class="line">            <span class="built_in">DataCopy</span>(x1Local, x1Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            <span class="built_in">DataCopy</span>(x2Local, x2Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将tensor加入队列</span></span><br><span class="line">            inQueueX<span class="number">1.</span><span class="built_in">EnQue</span>(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.</span><span class="built_in">EnQue</span>(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算函数：执行幂运算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 从队列中取出输入tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">DeQue</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">DeQue</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型选择不同的计算方法</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length);  <span class="comment">// float类型直接计算</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);     <span class="comment">// 半精度类型需要类型转换</span></span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 释放输入tensor</span></span><br><span class="line">            inQueueX<span class="number">1.F</span>reeTensor(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.F</span>reeTensor(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现：pow(x1, x2) = exp(x2 * ln(x1))</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// 计算ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// 计算x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// 计算exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现：需要先转换为float进行计算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时float缓冲区</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将半精度数据转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 在float精度下进行幂运算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将结果转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 数据输出函数：将计算结果从本地缓冲区拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 队列和缓冲区定义</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX1;   <span class="comment">// 输入x1队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX2;   <span class="comment">// 输入x2队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;  <span class="comment">// 输出y队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时缓冲区（用于半精度计算）</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 管道和参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;   <span class="comment">// 每个tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;    <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;      <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-广播场景实现-powb-h"><a href="#3-广播场景实现-powb-h" class="headerlink" title="3. 广播场景实现 (powb.h)"></a>3. 广播场景实现 (powb.h)</h3><p>广播场景的实现更加复杂，需要处理不同形状的输入张量。主要特点：</p><ul><li>支持多维张量的广播机制</li><li>动态计算每个输出元素对应的输入元素索引</li><li>逐元素计算，适用于形状不匹配的情况</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 广播场景的Pows算子实现类（tiling key 2）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPowsBroadCast</span>&#123;  </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPowsBroadCast</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播相关的tiling参数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling); </span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输出张量的维度信息</span></span><br><span class="line">            y_dimensional = tiling_data.y_dimensional;  <span class="comment">// 输出张量维度数</span></span><br><span class="line">            y_ndarray = tiling_data.y_ndarray;          <span class="comment">// 输出张量各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输入张量的维度信息</span></span><br><span class="line">            x1_ndarray = tiling_data.x1_ndarray;        <span class="comment">// 输入x1各维度大小</span></span><br><span class="line">            x2_ndarray = tiling_data.x2_ndarray;        <span class="comment">// 输入x2各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 累积维度信息，用于索引计算</span></span><br><span class="line">            y_sumndarray = tiling_data.y_sumndarray;    <span class="comment">// 输出张量累积维度</span></span><br><span class="line">            x1_sumndarray = tiling_data.x1_sumndarray;  <span class="comment">// 输入x1累积维度</span></span><br><span class="line">            x2_sumndarray = tiling_data.x2_sumndarray;  <span class="comment">// 输入x2累积维度</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 张量长度信息</span></span><br><span class="line">            x1TotalLength = tiling_data.x1TotalLength;  <span class="comment">// x1总长度</span></span><br><span class="line">            x2TotalLength = tiling_data.x2TotalLength;  <span class="comment">// x2总长度</span></span><br><span class="line">            x1Size = tiling_data.x1Size;                <span class="comment">// x1大小</span></span><br><span class="line">            x2Size = tiling_data.x2Size;                <span class="comment">// x2大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 分块信息</span></span><br><span class="line">            totalLength = tiling_data.totalLength;      <span class="comment">// 输出总长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;        <span class="comment">// 每个tile长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;          <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;              <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播算子</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，注意x1和x2的长度可能不同</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1, x1TotalLength);  </span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X2*)x2, x2TotalLength); </span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y, totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化临时缓冲区（广播场景不使用队列，而是直接使用缓冲区）</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 半精度类型需要额外的float缓冲区</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 广播场景的主处理函数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时缓冲区用于存储广播后的数据</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = tmpBufferX<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = tmpBufferX<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 按tile处理数据</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;                   </span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength,x1Local,x2Local);           </span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum,x1Local,x2Local);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 广播场景的计算函数：逐元素计算广播索引</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length,LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local)</span> </span>&#123; </span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 逐元素处理，计算每个输出元素对应的输入元素索引</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">uint32_t</span> j = <span class="number">0</span>;j &lt; length;j ++)&#123;</span><br><span class="line">                <span class="type">uint32_t</span> x1_start = <span class="number">0</span>;  <span class="comment">// x1的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> x2_start = <span class="number">0</span>;  <span class="comment">// x2的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> index = j + progress * <span class="keyword">this</span>-&gt;tileLength;  <span class="comment">// 当前输出元素的全局索引</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 根据广播规则计算输入索引</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">uint32_t</span> k = <span class="number">0</span>; k &lt; <span class="keyword">this</span>-&gt;y_dimensional; k++)&#123;</span><br><span class="line">                    <span class="comment">// 如果x1在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;x1_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x1_start += <span class="keyword">this</span>-&gt;x1_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 如果x2在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span>(<span class="keyword">this</span>-&gt;x2_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x2_start += <span class="keyword">this</span>-&gt;x2_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);  </span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 从全局内存获取对应位置的值</span></span><br><span class="line">                <span class="keyword">auto</span> x1 = x1Gm.<span class="built_in">GetValue</span>(x1_start); </span><br><span class="line">                <span class="keyword">auto</span> x2 = x2Gm.<span class="built_in">GetValue</span>(x2_start);</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 将值设置到本地tensor中</span></span><br><span class="line">                x1Local.<span class="built_in">SetValue</span>(j,x1);</span><br><span class="line">                x2Local.<span class="built_in">SetValue</span>(j,x2);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型执行计算</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length); </span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// float精度计算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出函数：将结果拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 输出队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时计算缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX1;  <span class="comment">// x1临时缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX2;  <span class="comment">// x2临时缓冲区</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 管道和基本参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;   <span class="comment">// 输出总长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;    <span class="comment">// tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;     <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;       <span class="comment">// 剩余长度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 广播相关参数</span></span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional;     <span class="comment">// 输出维度数</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_sumndarray;    <span class="comment">// x1累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_sumndarray;    <span class="comment">// x2累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_ndarray;        <span class="comment">// 输出各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_ndarray;       <span class="comment">// x1各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_ndarray;       <span class="comment">// x2各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_sumndarray;     <span class="comment">// 输出累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> x1TotalLength;     <span class="comment">// x1总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x2TotalLength;     <span class="comment">// x2总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x1Size;            <span class="comment">// x1大小</span></span><br><span class="line">        <span class="type">uint32_t</span> x2Size;            <span class="comment">// x2大小</span></span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><h2 id="host侧实现"><a href="#host侧实现" class="headerlink" title="host侧实现"></a>host侧实现</h2><p>host侧主要负责算子的注册、形状推理、tiling策略计算等功能。包含以下几个关键部分：</p><h3 id="1-Tiling数据结构定义-pows-tiling-h"><a href="#1-Tiling数据结构定义-pows-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (pows_tiling.h)"></a>1. Tiling数据结构定义 (pows_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">// 定义Pows算子的tiling数据结构</span></span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(PowsTilingData)</span><br><span class="line">  <span class="comment">// 基础分块参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);    <span class="comment">// 总数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);      <span class="comment">// 循环次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);        <span class="comment">// 剩余数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);     <span class="comment">// 每个tile的长度</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 广播相关参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, y_dimensional);  <span class="comment">// 输出张量维度数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1TotalLength);  <span class="comment">// x1总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2TotalLength);  <span class="comment">// x2总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1Size);         <span class="comment">// x1大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2Size);         <span class="comment">// x2大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 维度数组（最大支持20维）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_ndarray);   <span class="comment">// 输出各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_ndarray);  <span class="comment">// x1各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_ndarray);  <span class="comment">// x2各维度大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 累积维度数组（用于索引计算）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_sumndarray);  <span class="comment">// 输出累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_sumndarray); <span class="comment">// x1累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_sumndarray); <span class="comment">// x2累积维度</span></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册tiling数据类</span></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(Pows, PowsTilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-pows-cpp"><a href="#2-Tiling策略计算-pows-cpp" class="headerlink" title="2. Tiling策略计算 (pows.cpp)"></a>2. Tiling策略计算 (pows.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pows_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向上32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32U</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>) / DataType;  <span class="comment">// 向上对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向下32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">31</span>) / DataType;      <span class="comment">// 向下对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="type">const</span> <span class="type">uint32_t</span> BLOCK_SIZE = <span class="number">32</span>;      <span class="comment">// 块大小常量</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;    <span class="comment">// 双缓冲数量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PowsTilingData tiling;  <span class="comment">// 创建tiling数据结构</span></span><br><span class="line">    <span class="type">uint64_t</span> sizeofdatatype;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取平台信息</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> socVersion = ascendcPlatform.<span class="built_in">GetSocVersion</span>();  <span class="comment">// 获取SoC版本</span></span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);  <span class="comment">// 获取UB大小</span></span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNum</span>();  <span class="comment">// 获取核心数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入数据信息</span></span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// 数据总长度</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();  <span class="comment">// 获取数据类型</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 根据数据类型确定字节大小</span></span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;  <span class="comment">// 半精度类型占2字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;  <span class="comment">// 单精度类型占4字节</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="type">uint32_t</span> x2Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="keyword">if</span> (x1Size != x2Size)&#123;  <span class="comment">// 长度不一就广播，广播部分采用论坛中的广播样例</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(3);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(4);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 定义维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> y_ndarray[<span class="number">20</span>], x1_ndarray[<span class="number">20</span>], x2_ndarray[<span class="number">20</span>];</span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional, x1_dimensional, x2_dimensional;</span><br><span class="line">        <span class="comment">// 获取张量形状信息</span></span><br><span class="line">        <span class="keyword">auto</span> shape_y  = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x1 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x2 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="comment">// 获取各张量的维度数</span></span><br><span class="line">        y_dimensional  = shape_y.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        x1_dimensional = shape_x<span class="number">1.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        x2_dimensional = shape_x<span class="number">2.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> max_dimensional = y_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x1_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x1_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x2_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x2_dimensional;</span><br><span class="line">        <span class="comment">// 初始化维度数组，处理维度对齐</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; max_dimensional; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; y_dimensional) &#123;</span><br><span class="line">                y_ndarray[y_dimensional - i - <span class="number">1</span>] = shape_y.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                y_ndarray[i] = <span class="number">1</span>; <span class="comment">// 不足的维度补1</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x1_dimensional) &#123;</span><br><span class="line">                x1_ndarray[x1_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">1.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x1_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x2_dimensional) &#123;</span><br><span class="line">                x2_ndarray[x2_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">2.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x2_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_dimensional</span>(max_dimensional);</span><br><span class="line">        tiling.<span class="built_in">set_y_ndarray</span>(y_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_ndarray</span>(x1_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_ndarray</span>(x2_ndarray);</span><br><span class="line">        <span class="comment">// 计算累积维度数组（用于索引计算）</span></span><br><span class="line">        <span class="type">uint32_t</span> y_sumndarray[<span class="number">20</span>], x1_sumndarray[<span class="number">20</span>], x2_sumndarray[<span class="number">20</span>];</span><br><span class="line">        y_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x1_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x2_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">1</span>; i &lt;= max_dimensional; i++)&#123;</span><br><span class="line">            y_sumndarray[i]   = y_sumndarray[i - <span class="number">1</span>]   * y_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x1_sumndarray[i]  = x1_sumndarray[i - <span class="number">1</span>]  * x1_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x2_sumndarray[i]  = x2_sumndarray[i - <span class="number">1</span>]  * x2_ndarray[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_sumndarray</span>(y_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_sumndarray</span>(x1_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_sumndarray</span>(x2_sumndarray);</span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(y_sumndarray[max_dimensional],sizeofdatatype); </span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_x1TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x2TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x1Size</span>(x1Size);</span><br><span class="line">        tiling.<span class="built_in">set_x2Size</span>(x2Size);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength);</span><br><span class="line">        <span class="comment">// 这里比较关键，这个24是通过实际需要使用多少块空间来计算的</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     </span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;y_dimensional: %d\n&quot;, max_dimensional);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1Size: %d\n&quot;, x1Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2Size: %d\n&quot;, x2Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123; <span class="comment">// 非广播场景</span></span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(totalLength,sizeofdatatype);</span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(1);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(2);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 这里恰好half的分块数与float一致，感兴趣的可以自己算一下试试看</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     <span class="comment">//向下32对齐的最大长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// Gm总地址32B对齐</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);  </span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);     </span><br><span class="line">    *y_shape = *x1_shape;  </span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pows</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Pows</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="comment">// 定义第一个输入x1（底数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)  <span class="comment">// 支持的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)  <span class="comment">// 支持的数据格式</span></span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);  </span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义第二个输入x2（指数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义输出y</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置形状推理函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置AI Core实现</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);  <span class="comment">// 设置tiling函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>);  <span class="comment">// 添加支持的硬件配置</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(Pows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关键技术要点"><a href="#关键技术要点" class="headerlink" title="关键技术要点"></a>关键技术要点</h2><ol><li>内存对齐优化 ：使用32字节对齐确保内存访问效率</li><li>UB空间管理 ：根据数据类型和缓冲区数量动态计算tile大小</li><li>广播支持 ：通过维度数组和累积维度数组实现复杂的广播索引计算</li><li>Tiling Key分离 ：根据数据类型和是否广播设置不同的tiling key</li><li>平台适配 ：获取硬件平台信息进行针对性优化</li></ol><h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><ol><li>双缓冲机制 ：在非广播场景使用双缓冲提高数据传输效率</li><li>内存对齐 ：确保所有内存访问都是32字节对齐的</li><li>UB空间最大化利用 ：根据实际硬件UB大小动态计算最优tile长度</li><li>数据类型优化 ：针对不同精度类型采用不同的计算策略</li><li>广播优化 ：在广播场景下使用专门的索引计算逻辑</li></ol><h1 id="SelectV2算子实现详解"><a href="#SelectV2算子实现详解" class="headerlink" title="SelectV2算子实现详解"></a>SelectV2算子实现详解</h1><h2 id="算子概述-1"><a href="#算子概述-1" class="headerlink" title="算子概述"></a>算子概述</h2><p>SelectV2算子是一个条件选择算子，根据布尔条件张量从两个输入张量中选择对应元素。该算子支持广播机制，能够处理不同形状的输入张量。算子的核心功能是：当条件为True时选择x1中的元素，当条件为False时选择x2中的元素。</p><h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p>SelectV2算子的数学表达式为：<code>y[i] = condition[i] ? x1[i] : x2[i]</code> </p><h2 id="kernel侧实现-1"><a href="#kernel侧实现-1" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><h3 id="1-完成select-v2-cpp文件-这里是算子的入口"><a href="#1-完成select-v2-cpp文件-这里是算子的入口" class="headerlink" title="1. 完成select_v2.cpp文件,这里是算子的入口"></a>1. 完成select_v2.cpp文件,这里是算子的入口</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span>  <span class="comment">// AscendC核心算子开发框架</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2.h&quot;</span>        <span class="comment">// 非广播场景的SelectV2算子实现</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2b.h&quot;</span>       <span class="comment">// 广播场景的SelectV2算子实现</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 算子入口函数，使用extern &quot;C&quot;确保C++函数能被C代码调用</span></span><br><span class="line"><span class="comment">// __global__表示这是一个设备端函数，__aicore__表示运行在AI Core上</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">select_v2</span><span class="params">(GM_ADDR c, GM_ADDR x1, GM_ADDR x2, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;  <span class="comment">// 这里有个细节，建议在最开始就定义好pipe对象，然后通过传参数</span></span><br><span class="line">                 <span class="comment">// 再进到Init中，有一定性能优化</span></span><br><span class="line">    <span class="comment">// 根据tiling key选择不同的实现策略</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">1</span>))&#123;  <span class="comment">// tiling key为1：非广播场景</span></span><br><span class="line">        KernelSelectV2 op;  <span class="comment">// 创建非广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(c,x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">2</span>))&#123;  <span class="comment">// tiling key为2：广播场景</span></span><br><span class="line">        KernelSelectV2BroadCast op;  <span class="comment">// 创建广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(c,x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-非广播场景实现-select-v2-h"><a href="#2-非广播场景实现-select-v2-h" class="headerlink" title="2. 非广播场景实现 (select_v2.h)"></a>2. 非广播场景实现 (select_v2.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;  <span class="comment">// 双缓冲机制，提高数据传输效率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非广播场景的SelectV2算子实现类（tiling key 1）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSelectV2</span>&#123; <span class="comment">// tiling key 1 正常情况不用广播</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSelectV2</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化tiling参数，从host侧传递的tiling数据中获取分块信息</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);  <span class="comment">// 获取tiling数据结构</span></span><br><span class="line">        totalLength = tiling_data.totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;    <span class="comment">// 每个tile的长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;      <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;          <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化算子，设置全局内存地址和缓冲区</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR c,GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);  <span class="comment">// 初始化tiling参数</span></span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);  <span class="comment">// 确保block数量不为0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置全局内存缓冲区，将GM地址转换为GlobalTensor</span></span><br><span class="line">        cGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">bool</span>*)c, <span class="keyword">this</span>-&gt;totalLength);      <span class="comment">// 条件张量</span></span><br><span class="line">        x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;totalLength); <span class="comment">// 输入张量x1</span></span><br><span class="line">        x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;totalLength); <span class="comment">// 输入张量x2</span></span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);    <span class="comment">// 输出张量y</span></span><br><span class="line">        </span><br><span class="line">        pipe = pipeIn;  <span class="comment">// 保存pipe指针</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化输入输出队列，使用双缓冲提高效率</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueC, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">bool</span>));      <span class="comment">// 条件队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX1, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1)); <span class="comment">// x1输入队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX2, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2)); <span class="comment">// x2输入队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));  <span class="comment">// 输出队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化临时缓冲区，用于条件处理</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(zeroBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));  <span class="comment">// 零值缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(cBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));     <span class="comment">// 条件转换缓冲区</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型初始化不同的临时缓冲区</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int32类型需要转换为float进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int8类型需要转换为half进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 主处理函数，按tile进行循环处理</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 处理完整的tile</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; ++ i) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i,  <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将数据从GM拷贝到UB（32B对齐后的长度）</span></span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 在UB中进行计算</span></span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将结果从UB拷回GM</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理剩余的不足一个tile的数据</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据输入函数：从全局内存拷贝数据到本地缓冲区</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 分配本地tensor</span></span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = inQueueC.<span class="built_in">AllocTensor</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 从全局内存拷贝数据到本地tensor</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(cLocal, cGm[progress * <span class="keyword">this</span>-&gt;tileLength], length);   <span class="comment">// 拷贝条件数据</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(x1Local, x1Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length); <span class="comment">// 拷贝x1数据</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(x2Local, x2Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length); <span class="comment">// 拷贝x2数据</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将tensor加入队列</span></span><br><span class="line">        inQueueC.<span class="built_in">EnQue</span>(cLocal);</span><br><span class="line">        inQueueX<span class="number">1.</span><span class="built_in">EnQue</span>(x1Local);</span><br><span class="line">        inQueueX<span class="number">2.</span><span class="built_in">EnQue</span>(x2Local);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算函数：执行条件选择运算</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从队列中取出输入tensor</span></span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = inQueueC.<span class="built_in">DeQue</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">DeQue</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">DeQue</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 条件处理：将bool类型转换为可用于Select操作的格式</span></span><br><span class="line">        LocalTensor&lt;half&gt; cTmpLocal = cBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        <span class="keyword">auto</span> intc = cLocal.<span class="keyword">template</span> <span class="built_in">ReinterpretCast</span>&lt;<span class="type">uint8_t</span>&gt;();  <span class="comment">// 将bool重新解释为uint8_t</span></span><br><span class="line">        LocalTensor&lt;half&gt; zeroLocal = zeroBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将uint8_t转换为half，然后与0比较生成选择掩码，这里是因为select的掩码只能是half类型</span></span><br><span class="line">        <span class="built_in">Cast</span>(cTmpLocal,intc,RoundMode::CAST_NONE,length);</span><br><span class="line">        <span class="built_in">Duplicate</span>(zeroLocal, <span class="built_in">half</span>(<span class="number">0</span>), length);  <span class="comment">// 填充零值</span></span><br><span class="line">        <span class="built_in">Compare</span>(zeroLocal,cTmpLocal, zeroLocal, CMPMODE::NE, length);  <span class="comment">// 生成选择掩码</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型执行不同的选择操作</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// float和half类型可以直接使用Select操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yLocal,zeroLocal,x1Local,x2Local,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int8类型需要先转换为half进行Select操作</span></span><br><span class="line">            LocalTensor&lt;half&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int32类型需要先转换为float进行Select操作</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 释放输入tensor</span></span><br><span class="line">        inQueueC.<span class="built_in">FreeTensor</span>(cLocal);</span><br><span class="line">        inQueueX<span class="number">1.F</span>reeTensor(x1Local);</span><br><span class="line">        inQueueX<span class="number">2.F</span>reeTensor(x2Local);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 数据输出函数：将计算结果从本地缓冲区拷贝到全局内存</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">        outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 队列和缓冲区定义</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueC;   <span class="comment">// 条件输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX1;  <span class="comment">// x1输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX2;  <span class="comment">// x2输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY; <span class="comment">// 输出队列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 全局内存tensor</span></span><br><span class="line">    GlobalTensor&lt;<span class="type">bool</span>&gt; cGm;      <span class="comment">// 条件张量</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X1&gt; x1Gm; <span class="comment">// 输入张量x1</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X2&gt; x2Gm; <span class="comment">// 输入张量x2</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_Y&gt; yGm;   <span class="comment">// 输出张量y</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 临时缓冲区（用于类型转换和条件处理）</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;  <span class="comment">// 临时缓冲区1</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;  <span class="comment">// 临时缓冲区2</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;  <span class="comment">// 临时缓冲区3</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; zeroBuffer;  <span class="comment">// 零值缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; cBuffer;     <span class="comment">// 条件转换缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 管道和参数</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    <span class="type">uint64_t</span> totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">    <span class="type">uint64_t</span> tileLength;   <span class="comment">// 每个tile长度</span></span><br><span class="line">    <span class="type">uint64_t</span> loopCount;    <span class="comment">// 循环次数</span></span><br><span class="line">    <span class="type">uint64_t</span> leftNum;      <span class="comment">// 剩余数据长度</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="3-广播场景实现-select-v2b-h"><a href="#3-广播场景实现-select-v2b-h" class="headerlink" title="3. 广播场景实现 (select_v2b.h)"></a>3. 广播场景实现 (select_v2b.h)</h3><p>广播场景的实现更加复杂，需要处理不同形状的输入张量。主要特点：</p><ul><li>支持多维张量的广播机制</li><li>动态计算每个输出元素对应的输入元素索引</li><li>逐元素计算，适用于形状不匹配的情况</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 广播场景的SelectV2算子实现类（tiling key 2）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSelectV2BroadCast</span>&#123;  <span class="comment">// 非对齐 广播case</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSelectV2BroadCast</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化广播相关的tiling参数</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling); </span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出张量的维度信息</span></span><br><span class="line">        y_dimensional = tiling_data.y_dimensional;  <span class="comment">// 输出张量维度数</span></span><br><span class="line">        y_ndarray = tiling_data.y_ndarray;          <span class="comment">// 输出张量各维度大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输入张量的维度信息</span></span><br><span class="line">        c_ndarray = tiling_data.c_ndarray;          <span class="comment">// 条件张量各维度大小</span></span><br><span class="line">        x1_ndarray = tiling_data.x1_ndarray;        <span class="comment">// 输入x1各维度大小</span></span><br><span class="line">        x2_ndarray = tiling_data.x2_ndarray;        <span class="comment">// 输入x2各维度大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 累积维度信息，用于索引计算</span></span><br><span class="line">        y_sumndarray = tiling_data.y_sumndarray;    <span class="comment">// 输出张量累积维度</span></span><br><span class="line">        c_sumndarray = tiling_data.c_sumndarray;    <span class="comment">// 条件张量累积维度</span></span><br><span class="line">        x1_sumndarray = tiling_data.x1_sumndarray;  <span class="comment">// 输入x1累积维度</span></span><br><span class="line">        x2_sumndarray = tiling_data.x2_sumndarray;  <span class="comment">// 输入x2累积维度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 张量长度信息</span></span><br><span class="line">        cSize = tiling_data.cSize;                  <span class="comment">// 条件张量大小</span></span><br><span class="line">        x1Size = tiling_data.x1Size;                <span class="comment">// x1张量大小</span></span><br><span class="line">        x2Size = tiling_data.x2Size;                <span class="comment">// x2张量大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 分块信息</span></span><br><span class="line">        totalLength = tiling_data.totalLength;      <span class="comment">// 输出总长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;        <span class="comment">// 每个tile长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;          <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;              <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化广播算子</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR c,GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置全局内存缓冲区，注意各张量的长度可能不同</span></span><br><span class="line">        cGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">bool</span>*)c, <span class="keyword">this</span>-&gt;cSize);           <span class="comment">// 条件张量</span></span><br><span class="line">        x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;x1Size);    <span class="comment">// 输入x1张量</span></span><br><span class="line">        x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;x2Size);    <span class="comment">// 输入x2张量</span></span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);  <span class="comment">// 输出张量</span></span><br><span class="line">        </span><br><span class="line">        pipe = pipeIn;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化临时缓冲区（广播场景不使用队列，而是直接使用缓冲区）</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(zeroBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));   <span class="comment">// 零值缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(cBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));      <span class="comment">// 条件转换缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferC,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y)); <span class="comment">// 条件临时缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX1,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));<span class="comment">// x1临时缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX2,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));<span class="comment">// x2临时缓冲区</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型初始化不同的临时缓冲区</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int32类型需要转换为float进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int8类型需要转换为half进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 广播场景的主处理函数</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取临时缓冲区用于存储广播后的数据</span></span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = tmpBufferC.<span class="built_in">Get</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = tmpBufferX<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = tmpBufferX<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 按tile处理数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i ++) &#123;               </span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength,cLocal,x1Local,x2Local);           </span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理剩余数据</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum,cLocal,x1Local,x2Local);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 广播场景的计算函数：逐元素计算广播索引</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">uint32_t</span> progress, <span class="type">uint32_t</span> length,LocalTensor&lt;<span class="type">bool</span>&gt; cLocal,LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local)</span> </span>&#123; </span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="type">uint32_t</span> offset = progress * <span class="keyword">this</span>-&gt;tileLength;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 逐元素处理，计算每个输出元素对应的输入元素索引</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">uint32_t</span> j = <span class="number">0</span>;j &lt; length;j ++)&#123;</span><br><span class="line">            <span class="type">uint32_t</span> c_start = <span class="number">0</span>;   <span class="comment">// 条件张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> x1_start = <span class="number">0</span>;  <span class="comment">// x1张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> x2_start = <span class="number">0</span>;  <span class="comment">// x2张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> index = j + offset;  <span class="comment">// 当前输出元素的全局索引</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据广播规则计算输入索引</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> k = <span class="number">0</span>; k &lt; <span class="keyword">this</span>-&gt;y_dimensional;k ++)&#123;</span><br><span class="line">                <span class="comment">// 如果条件张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;c_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    c_start += <span class="keyword">this</span>-&gt;c_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果x1张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;x1_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    x1_start += <span class="keyword">this</span>-&gt;x1_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果x2张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">this</span>-&gt;x2_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    x2_start += <span class="keyword">this</span>-&gt;x2_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);  </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 从全局内存获取对应位置的值</span></span><br><span class="line">            <span class="keyword">auto</span> c = cGm.<span class="built_in">GetValue</span>(c_start);   <span class="comment">// 获取条件值</span></span><br><span class="line">            <span class="keyword">auto</span> x1 = x1Gm.<span class="built_in">GetValue</span>(x1_start); <span class="comment">// 获取x1值</span></span><br><span class="line">            <span class="keyword">auto</span> x2 = x2Gm.<span class="built_in">GetValue</span>(x2_start); <span class="comment">// 获取x2值</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将值设置到本地tensor中</span></span><br><span class="line">            cLocal.<span class="built_in">SetValue</span>(j,c);</span><br><span class="line">            x1Local.<span class="built_in">SetValue</span>(j,x1);</span><br><span class="line">            x2Local.<span class="built_in">SetValue</span>(j,x2);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 条件处理：将bool类型转换为可用于Select操作的格式</span></span><br><span class="line">        LocalTensor&lt;half&gt; cTmpLocal = cBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        <span class="keyword">auto</span> intc = cLocal.<span class="keyword">template</span> <span class="built_in">ReinterpretCast</span>&lt;<span class="type">uint8_t</span>&gt;();  <span class="comment">// 将bool重新解释为uint8_t</span></span><br><span class="line">        LocalTensor&lt;half&gt; zeroLocal = zeroBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将uint8_t转换为half，然后与0比较生成选择掩码</span></span><br><span class="line">        <span class="built_in">Cast</span>(cTmpLocal,intc,RoundMode::CAST_NONE,length);</span><br><span class="line">        <span class="built_in">Duplicate</span>(zeroLocal, <span class="built_in">half</span>(<span class="number">0</span>), length);  <span class="comment">// 填充零值</span></span><br><span class="line">        <span class="built_in">Compare</span>(zeroLocal,cTmpLocal, zeroLocal, CMPMODE::NE, length);  <span class="comment">// 生成选择掩码</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型执行不同的选择操作</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// float和half类型可以直接使用Select操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yLocal,zeroLocal,x1Local,x2Local,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int8类型需要先转换为half进行Select操作</span></span><br><span class="line">            LocalTensor&lt;half&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int32类型需要先转换为float进行Select操作</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出函数：将结果拷贝到全局内存</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;  <span class="comment">// 原始地址 输出</span></span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">        outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 输出队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 全局内存tensor</span></span><br><span class="line">    GlobalTensor&lt;<span class="type">bool</span>&gt; cGm;      <span class="comment">// 条件张量</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X1&gt; x1Gm; <span class="comment">// 输入张量x1</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X2&gt; x2Gm; <span class="comment">// 输入张量x2</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_Y&gt; yGm;   <span class="comment">// 输出张量y</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 临时计算缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;   <span class="comment">// 临时缓冲区1</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;   <span class="comment">// 临时缓冲区2</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;   <span class="comment">// 临时缓冲区3</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferC;   <span class="comment">// 条件临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX1;  <span class="comment">// x1临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX2;  <span class="comment">// x2临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; zeroBuffer;   <span class="comment">// 零值缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; cBuffer;      <span class="comment">// 条件转换缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 管道和基本参数</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    <span class="type">uint64_t</span> totalLength;   <span class="comment">// 输出总长度</span></span><br><span class="line">    <span class="type">uint64_t</span> tileLength;    <span class="comment">// tile长度</span></span><br><span class="line">    <span class="type">uint64_t</span> loopCount;     <span class="comment">// 循环次数</span></span><br><span class="line">    <span class="type">uint64_t</span> leftNum;       <span class="comment">// 剩余长度</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 广播相关参数</span></span><br><span class="line">    <span class="type">uint32_t</span> y_dimensional;     <span class="comment">// 输出维度数</span></span><br><span class="line">    <span class="type">uint32_t</span> *c_sumndarray;     <span class="comment">// 条件张量累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *x1_sumndarray;    <span class="comment">// x1累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *x2_sumndarray;    <span class="comment">// x2累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *y_ndarray;        <span class="comment">// 输出各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *c_ndarray;        <span class="comment">// 条件张量各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *x1_ndarray;       <span class="comment">// x1各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *x2_ndarray;       <span class="comment">// x2各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *y_sumndarray;     <span class="comment">// 输出累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> cSize;             <span class="comment">// 条件张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size;            <span class="comment">// x1张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x2Size;            <span class="comment">// x2张量大小</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="host侧实现-1"><a href="#host侧实现-1" class="headerlink" title="host侧实现"></a>host侧实现</h2><p>host侧主要负责算子的注册、形状推理、tiling策略计算等功能。包含以下几个关键部分：</p><h3 id="1-Tiling数据结构定义-select-v2-tiling-h"><a href="#1-Tiling数据结构定义-select-v2-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (select_v2_tiling.h)"></a>1. Tiling数据结构定义 (select_v2_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(SelectV2TilingData)</span><br><span class="line">   <span class="comment">// 基础分块参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);    <span class="comment">// 总数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);      <span class="comment">// 循环次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);        <span class="comment">// 剩余数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);     <span class="comment">// 每个tile的长度</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 广播相关参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, y_dimensional);  <span class="comment">// 输出张量维度数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1TotalLength);  <span class="comment">// x1总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2TotalLength);  <span class="comment">// x2总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1Size);         <span class="comment">// x1大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2Size);         <span class="comment">// x2大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 维度数组（最大支持20维）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_ndarray);   <span class="comment">// 输出各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_ndarray);  <span class="comment">// x1各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_ndarray);  <span class="comment">// x2各维度大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 累积维度数组（用于索引计算）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_sumndarray);  <span class="comment">// 输出累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_sumndarray); <span class="comment">// x1累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_sumndarray); <span class="comment">// x2累积维度</span></span><br><span class="line"></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(SelectV2, SelectV2TilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-select-v2-cpp"><a href="#2-Tiling策略计算-select-v2-cpp" class="headerlink" title="2. Tiling策略计算 (select_v2.cpp)"></a>2. Tiling策略计算 (select_v2.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SelectV2算子的host侧实现文件</span></span><br><span class="line"><span class="comment">// 功能：根据条件张量condition选择x1或x2中的元素</span></span><br><span class="line"><span class="comment">// 支持广播机制和多种数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向上128字节对齐函数</span></span><br><span class="line"><span class="comment">// 参数：n - 元素个数，DataType - 数据类型字节数</span></span><br><span class="line"><span class="comment">// 返回：对齐后的元素个数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align128U</span><span class="params">(<span class="type">uint32_t</span> n,<span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">127</span>) &amp; ~<span class="number">127</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向下128字节对齐函数</span></span><br><span class="line"><span class="comment">// 参数：n - 元素个数，DataType - 数据类型字节数</span></span><br><span class="line"><span class="comment">// 返回：对齐后的元素个数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align128D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">127</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">// SelectV2算子的Tiling函数</span></span><br><span class="line"><span class="comment">// 功能：计算算子执行所需的tiling参数，包括内存分配、循环次数等</span></span><br><span class="line"><span class="comment">// 支持两种模式：1-非广播模式，2-广播模式</span></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化tiling数据结构</span></span><br><span class="line">    SelectV2TilingData tiling;</span><br><span class="line">    <span class="type">uint64_t</span> sizeofdatatype;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取平台信息和硬件资源</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> socVersion = ascendcPlatform.<span class="built_in">GetSocVersion</span>();</span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNum</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取输入张量的总长度（以x1为基准）</span></span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 根据数据类型确定每个元素的字节数</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">1</span>;  <span class="comment">// int8: 1字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt== ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;  <span class="comment">// float16/bfloat16: 2字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;  <span class="comment">// float32/int32: 4字节</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取三个输入张量的大小</span></span><br><span class="line">    <span class="type">uint32_t</span> cSize  = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();  <span class="comment">// condition张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// x1张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x2Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">2</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// x2张量大小</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 判断是否需要广播：如果三个张量大小不完全相等，则进入广播模式</span></span><br><span class="line">    <span class="keyword">if</span> (x1Size != x2Size || cSize != x1Size || cSize != x2Size)&#123;  </span><br><span class="line">        <span class="comment">// 设置tiling key为2，表示广播模式</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 定义各张量的维度数组（最大支持20维）</span></span><br><span class="line">        <span class="type">uint32_t</span> y_ndarray[<span class="number">20</span>], c_ndarray[<span class="number">20</span>], x1_ndarray[<span class="number">20</span>], x2_ndarray[<span class="number">20</span>];</span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional, c_dimensional, x1_dimensional, x2_dimensional;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 获取各张量的原始形状信息</span></span><br><span class="line">        <span class="keyword">auto</span> shape_y  = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_c = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x1 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x2 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">2</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 获取各张量的维度数</span></span><br><span class="line">        y_dimensional = shape_y.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        c_dimensional = shape_c.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        x1_dimensional = shape_x<span class="number">1.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        x2_dimensional = shape_x<span class="number">2.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到最大维度数，用于统一处理</span></span><br><span class="line">        <span class="type">uint32_t</span> max_dimensional = y_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (c_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = c_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x1_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x1_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x2_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x2_dimensional;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">// 将各张量的维度信息填充到统一长度的数组中</span></span><br><span class="line">        <span class="comment">// 不足的维度用1填充，实现维度对齐</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; max_dimensional; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; y_dimensional) &#123;</span><br><span class="line">                y_ndarray[y_dimensional - i - <span class="number">1</span>] = shape_y.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                y_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt;c_dimensional) &#123;</span><br><span class="line">                c_ndarray[c_dimensional - i - <span class="number">1</span>] = shape_c.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                c_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x1_dimensional) &#123;</span><br><span class="line">                x1_ndarray[x1_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">1.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x1_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x2_dimensional) &#123;</span><br><span class="line">                x2_ndarray[x2_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">2.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x2_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置维度信息到tiling数据中</span></span><br><span class="line">        tiling.<span class="built_in">set_y_dimensional</span>(max_dimensional);</span><br><span class="line">        tiling.<span class="built_in">set_y_ndarray</span>(y_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_c_ndarray</span>(c_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_ndarray</span>(x1_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_ndarray</span>(x2_ndarray);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算各张量的累积维度数组，用于广播时的索引计算</span></span><br><span class="line">        <span class="type">uint32_t</span> y_sumndarray[<span class="number">20</span>], c_sumndarray[<span class="number">20</span>],x1_sumndarray[<span class="number">20</span>], x2_sumndarray[<span class="number">20</span>];</span><br><span class="line">        y_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        c_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x1_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x2_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算累积乘积，用于多维索引转换为一维索引</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">1</span>; i &lt;= max_dimensional; i++)&#123;</span><br><span class="line">            y_sumndarray[i] = y_sumndarray[i - <span class="number">1</span>] * y_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            c_sumndarray[i] = c_sumndarray[i - <span class="number">1</span>] * c_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x1_sumndarray[i] = x1_sumndarray[i - <span class="number">1</span>] * x1_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x2_sumndarray[i] = x2_sumndarray[i - <span class="number">1</span>] * x2_ndarray[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置累积维度数组到tiling数据中</span></span><br><span class="line">        tiling.<span class="built_in">set_y_sumndarray</span>(y_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_c_sumndarray</span>(c_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_sumndarray</span>(x1_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_sumndarray</span>(x2_sumndarray);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算对齐后的总长度</span></span><br><span class="line">        totalLength = <span class="built_in">align128U</span>(y_sumndarray[max_dimensional],sizeofdatatype); </span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置各张量的对齐大小</span></span><br><span class="line">        tiling.<span class="built_in">set_cSize</span>(<span class="built_in">align128U</span>(cSize,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_x1Size</span>(<span class="built_in">align128U</span>(x1Size,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_x2Size</span>(<span class="built_in">align128U</span>(x2Size,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据数据类型计算每个tile的长度</span></span><br><span class="line">        <span class="comment">// 考虑UB内存限制和不同数据类型的内存占用</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength;</span><br><span class="line">        <span class="keyword">if</span>(dt == ge::DT_FLOAT16)&#123;        <span class="comment">// fp16: 需要更少的内存</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">14</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT)&#123;    <span class="comment">// fp32: 需要更多内存</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT32)&#123;     <span class="comment">// int32: 转换为fp32处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">36</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;      <span class="comment">// int8: 转换为fp16处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">20</span>,sizeofdatatype);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保tile长度不超过总长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 计算循环次数和剩余元素数量</span></span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = <span class="built_in">align128U</span>(totalLength % tileLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置tiling参数</span></span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        </span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">// 非广播模式：所有张量大小相等</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">1</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对总长度进行128字节对齐</span></span><br><span class="line">        totalLength = <span class="built_in">align128U</span>(totalLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型计算tile长度</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength;</span><br><span class="line">        <span class="keyword">if</span>(dt == ge::DT_FLOAT16)&#123;        <span class="comment">// fp16: 内存占用较少</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">18</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT)&#123;    <span class="comment">// fp32: 内存占用较多</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">30</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT32)&#123;     <span class="comment">// int32: 转换为fp32处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">42</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;      <span class="comment">// int8: 转换为fp16处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保tile长度不超过总长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算循环次数和剩余元素数量</span></span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = <span class="built_in">align128U</span>(totalLength % tileLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置tiling参数</span></span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// GM总地址128B对齐</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置单核执行</span></span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 保存tiling数据到上下文</span></span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置工作空间大小（SelectV2不需要额外工作空间）</span></span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="comment">// SelectV2算子的形状推理函数</span></span><br><span class="line"><span class="comment">// 功能：根据输入张量的形状推导输出张量的形状</span></span><br><span class="line"><span class="comment">// SelectV2的输出形状与x1的形状相同</span></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 获取x1张量的形状</span></span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 获取输出张量的形状指针</span></span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 设置输出形状与x1相同</span></span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="comment">// SelectV2算子定义类</span></span><br><span class="line"><span class="comment">// 功能：定义算子的输入输出规格、数据类型、格式等信息</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelectV2</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">SelectV2</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="comment">// 定义condition输入：布尔类型的条件张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;condition&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_BOOL, ge::DT_BOOL, ge::DT_BOOL, ge::DT_BOOL&#125;)  <span class="comment">// 支持布尔类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)  <span class="comment">// 支持ND格式</span></span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义x1输入：第一个选择张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 支持多种数值类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义x2输入：第二个选择张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 与x1相同的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义y输出：选择结果张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 与输入相同的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置形状推理函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置AI Core执行参数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);  <span class="comment">// 设置tiling函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>);  <span class="comment">// 支持ascend310b芯片</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册SelectV2算子</span></span><br><span class="line"><span class="built_in">OP_ADD</span>(SelectV2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关键技术要点-1"><a href="#关键技术要点-1" class="headerlink" title="关键技术要点"></a>关键技术要点</h2><h3 id="1-条件处理机制-："><a href="#1-条件处理机制-：" class="headerlink" title="1.条件处理机制 ："></a>1.条件处理机制 ：</h3><ul><li>将bool类型的条件重新解释为uint8_t</li><li>转换为half类型后与零值比较生成选择掩码</li><li>使用Compare操作生成适用于Select的掩码</li></ul><h3 id="2-数据类型适配-："><a href="#2-数据类型适配-：" class="headerlink" title="2.数据类型适配 ："></a>2.数据类型适配 ：</h3><ul><li>float和half类型直接支持Select操作</li><li>int8_t和int32_t需要先转换为half/float，执行Select后再转换回原类型</li></ul><h3 id="3-广播索引计算-："><a href="#3-广播索引计算-：" class="headerlink" title="3.广播索引计算 ："></a>3.广播索引计算 ：</h3><ul><li>根据输出索引和各维度信息计算对应的输入索引</li><li>支持任意维度的广播规则</li><li>逐元素处理确保广播语义正确</li></ul><h3 id="4-内存管理优化-："><a href="#4-内存管理优化-：" class="headerlink" title="4.内存管理优化 ："></a>4.内存管理优化 ：</h3><ul><li>非广播场景使用双缓冲队列提高数据传输效率</li><li>广播场景使用临时缓冲区减少内存拷贝开销</li><li>根据数据类型动态分配临时缓冲区</li></ul><h1 id="AddLayerNorm算子实现详解"><a href="#AddLayerNorm算子实现详解" class="headerlink" title="AddLayerNorm算子实现详解"></a>AddLayerNorm算子实现详解</h1><p>LayerNorm算子在深度学习，以及大语言模型中的应用及其广泛，其主要作用是对输入进行归一化处理，以提高模型的泛化能力和训练效率。而AddLayerNorm算子的应用场景与其类似，在进行LayerNorm操作前，有些时候会使用一些残差连接，这个时候就可以进行算子的融合，来提升模型在整网中的性能</p><h2 id="算法原理-1"><a href="#算法原理-1" class="headerlink" title="算法原理"></a>算法原理</h2><p>AddLayerNorm算子的数学表达式为：<br><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>z</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>x</mi><mo>+</mo><mtext>y</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>μ</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>C</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>z</mi><mi>i</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>σ</mi><mn>2</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>C</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>y</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>z</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⊙</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}z &amp;= x + \text{y} \\\mu &amp;= \frac{1}{C} \sum_{i=1}^{C} z_i \\\sigma^2 &amp;= \frac{1}{C} \sum_{i=1}^{C} (z_i - \mu)^2 \\y &amp;= \frac{z - \mu}{\sqrt{\sigma^2 + \epsilon}} \odot \gamma + \beta\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:10.8023em;vertical-align:-5.1512em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6512em;"><span style="top:-8.6395em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span><span style="top:-6.1512em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathnormal">μ</span></span></span><span style="top:-2.7452em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:0.0928em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.1512em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6512em;"><span style="top:-8.6395em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">y</span></span></span></span><span style="top:-6.1512em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.7452em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:0.0928em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em;"><span style="top:-2.1966em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9134em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.8734em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221l0 -0c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47zM834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1266em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.1512em;"><span></span></span></span></span></span></span></span></span></span></span></p><h2 id="算子实现"><a href="#算子实现" class="headerlink" title="算子实现"></a>算子实现</h2><h2 id="kernel侧实现-2"><a href="#kernel侧实现-2" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DTYPE_IN&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAddLayerNorm</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAddLayerNorm</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">        rowNum = tiling_data.rowNum;        <span class="comment">// 单核处理的 行数 小块</span></span><br><span class="line">        rowNumSp = tiling_data.rowNumSp;    <span class="comment">// 大块行数</span></span><br><span class="line">        rowLength = tiling_data.rowLength;  <span class="comment">// 每行长度</span></span><br><span class="line">        blockPivot = tiling_data.blockPivot;<span class="comment">// 大核数量</span></span><br><span class="line">        tileLoop = tiling_data.tileLoop;    <span class="comment">// 核内分块 每小块行数</span></span><br><span class="line">        tileLength = tiling_data.tileLength;<span class="comment">// 单块数据长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;  <span class="comment">// 单核 循环执行的次数</span></span><br><span class="line">        factor = tiling_data.factor;</span><br><span class="line">        mfactor = tiling_data.mfactor;      <span class="comment">// -1 / n  求均值系数</span></span><br><span class="line">        eps = tiling_data.eps;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR gamma, GM_ADDR beta, GM_ADDR z,</span></span></span><br><span class="line"><span class="params"><span class="function">                                GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;leftRow = <span class="keyword">this</span>-&gt;rowNum % <span class="keyword">this</span>-&gt;tileLoop;<span class="comment">// 尾块行数</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetBlockIdx</span>() &lt; <span class="keyword">this</span>-&gt;blockPivot) &#123;</span><br><span class="line">            <span class="comment">// 大核多处理一行</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;rowNum = <span class="keyword">this</span>-&gt;rowNumSp;</span><br><span class="line">            <span class="keyword">this</span>-&gt;leftRow += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;blockLength = <span class="keyword">this</span>-&gt;rowNum * <span class="keyword">this</span>-&gt;rowLength; <span class="comment">// 单核处理的数据量</span></span><br><span class="line">        <span class="type">uint32_t</span> offset = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetBlockIdx</span>() &lt; <span class="keyword">this</span>-&gt;blockPivot) &#123;</span><br><span class="line">            <span class="comment">// 大块 核</span></span><br><span class="line">            offset = <span class="keyword">this</span>-&gt;blockLength * <span class="built_in">GetBlockIdx</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 小核的数据偏移量</span></span><br><span class="line">            <span class="comment">// 每个大核多处理一行，总共 blockPivot 个大核，每行长度 rowLength</span></span><br><span class="line">            <span class="comment">// 大核总共多处理了 this-&gt;rowLength * this-&gt;blockPivot 数据量</span></span><br><span class="line">            offset = <span class="keyword">this</span>-&gt;blockLength * <span class="built_in">GetBlockIdx</span>() +</span><br><span class="line">            <span class="keyword">this</span>-&gt;rowLength * <span class="keyword">this</span>-&gt;blockPivot;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 当前核 输入输出数据偏移</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)x + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)y + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)z + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        </span><br><span class="line">        gammaGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)gamma, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        betaGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)beta, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueX, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueZ, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="number">64</span> * <span class="built_in">sizeof</span>(DTYPE_IN)); <span class="comment">// 存每行均值 这里最大 128 行</span></span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="number">64</span> * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueGamma, BUFFER_NUM, <span class="keyword">this</span>-&gt;rowLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueBeta, BUFFER_NUM, <span class="keyword">this</span>-&gt;rowLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        tmpTensor1 = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_IN&gt;(); <span class="comment">//提前申请，避免多次申请带来性能开销</span></span><br><span class="line">        tmpTensor2 = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 同理，gamma与beta是相同的，就长期留在核心内</span></span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; GammaLocal = queueGamma.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; BetaLocal = queueBeta.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(GammaLocal, gammaGm[<span class="number">0</span>], <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        <span class="built_in">DataCopy</span>(BetaLocal, betaGm[<span class="number">0</span>], <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        queueGamma.<span class="built_in">EnQue</span>(GammaLocal);</span><br><span class="line">        queueBeta.<span class="built_in">EnQue</span>(BetaLocal);</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; gammaLocal = queueGamma.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; betaLocal = queueBeta.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; ++i) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i, <span class="keyword">this</span>-&gt;tileLoop); <span class="comment">// 每次处理 tileLoop 行</span></span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLoop, gammaLocal, betaLocal);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLoop);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 尾块行数</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftRow &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow); <span class="comment">// 最后一次处理 leftRow 行</span></span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow, gammaLocal, betaLocal);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow);</span><br><span class="line">        &#125;</span><br><span class="line">        queueGamma.<span class="built_in">FreeTensor</span>(gammaLocal);</span><br><span class="line">        queueBeta.<span class="built_in">FreeTensor</span>(betaLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据拷贝</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; xLocal = queueX.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; yLocal = queueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * <span class="keyword">this</span>-&gt;tileLength],</span><br><span class="line">                 <span class="keyword">this</span>-&gt;rowLength * rowNum); <span class="comment">// 行数rowNum 每行长度 this-&gt;rowLength</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(yLocal, yGm[progress * <span class="keyword">this</span>-&gt;tileLength],</span><br><span class="line">                 <span class="keyword">this</span>-&gt;rowLength * rowNum);</span><br><span class="line"></span><br><span class="line">        queueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">        queueY.<span class="built_in">EnQue</span>(yLocal);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum, LocalTensor&lt;DTYPE_IN&gt; gammaLocal, LocalTensor&lt;DTYPE_IN&gt; betaLocal)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; xLocal = queueX.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; yLocal = queueY.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; zLocal = queueZ.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// x = x+y</span></span><br><span class="line">        <span class="built_in">Add</span>(xLocal, xLocal, yLocal, rowNum * <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// t = sum(x)</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="comment">// 求每一行数据的和</span></span><br><span class="line">            <span class="built_in">ReduceSum</span>&lt;DTYPE_IN&gt;(tmpTensor2[j], xLocal[buffIndex], tmpTensor1, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// z = sum * -1/rowLength</span></span><br><span class="line">        <span class="built_in">Muls</span>(zLocal, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;mfactor, rowNum); <span class="comment">// 求 均值 * -1</span></span><br><span class="line">        <span class="comment">// x = x - mean(x)</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="comment">// 减去 均值</span></span><br><span class="line">            <span class="built_in">Adds</span>(xLocal[buffIndex], xLocal[buffIndex], zLocal.<span class="built_in">GetValue</span>(j), <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 平方 z = (x - mean(x)) * (x - mean(x))</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">Mul</span>(zLocal, xLocal, xLocal, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="comment">// 每行 求 差平方和</span></span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="built_in">ReduceSum</span>&lt;DTYPE_IN&gt;(tmpTensor2[j], zLocal[buffIndex], tmpTensor1, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">Muls</span>(tmpTensor2, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;factor, rowNum);<span class="comment">// 均值</span></span><br><span class="line">        <span class="built_in">Adds</span>(tmpTensor2, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;eps, rowNum);   <span class="comment">// + eps</span></span><br><span class="line">        <span class="built_in">Sqrt</span>(tmpTensor2, tmpTensor2, rowNum);              <span class="comment">// 开平方</span></span><br><span class="line">        <span class="comment">// 上面得到 均方差  std</span></span><br><span class="line">        <span class="built_in">Duplicate</span>&lt;DTYPE_IN&gt;(tmpTensor1, <span class="number">1.0f</span>, <span class="keyword">this</span>-&gt;tileLoop);</span><br><span class="line">        <span class="built_in">Div</span>(tmpTensor2, tmpTensor1, tmpTensor2, rowNum);    <span class="comment">// 倒数</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 乘倒数 归一化 缩放 平移</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="built_in">Muls</span>(zLocal[buffIndex], xLocal[buffIndex], tmpTensor<span class="number">2.</span><span class="built_in">GetValue</span>(j), <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">            <span class="built_in">FusedMulAdd</span>(z[buffIndex],gammaLocal,zLocal[buffIndex],betaLocal,<span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        queueZ.<span class="built_in">EnQue</span>&lt;DTYPE_IN&gt;(zLocal);</span><br><span class="line">        queueX.<span class="built_in">FreeTensor</span>(xLocal);</span><br><span class="line">        queueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; zLocal = queueZ.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="comment">// 拷贝输出</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * <span class="keyword">this</span>-&gt;tileLength], zLocal, rowNum * <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        queueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1, tmpBuffer2;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueX;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueY;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueGamma, queueBeta;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; queueZ;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; yGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; gammaGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; betaGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; zGm;</span><br><span class="line">    LocalTensor&lt;DTYPE_IN&gt; tmpTensor1 ;</span><br><span class="line">    LocalTensor&lt;DTYPE_IN&gt; tmpTensor2;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint32_t</span> blockLength = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint32_t</span> leftRow = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowNum = <span class="number">341</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowNumSp = <span class="number">342</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowLength = <span class="number">1024</span>;      <span class="comment">// 每行 1024</span></span><br><span class="line">    <span class="type">uint32_t</span> blockPivot = <span class="number">16</span>;       <span class="comment">// 大核数量</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLoop = <span class="number">8</span>;          <span class="comment">// 每块 8 行</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLength = <span class="number">8</span> * <span class="number">1024</span>; <span class="comment">// 每块数据量  8*1024</span></span><br><span class="line">    <span class="type">uint32_t</span> loopCount = <span class="number">42</span>;</span><br><span class="line">    <span class="type">float</span> factor = <span class="number">0.0009765625</span>;</span><br><span class="line">    <span class="type">float</span> mfactor = <span class="number">-0.0009765625</span>;</span><br><span class="line">    <span class="type">float</span> eps = <span class="number">1e-5</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint32_t</span> coreDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> tileNum;</span><br><span class="line">    <span class="type">uint32_t</span> tileDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> tailDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> processDataNum;</span><br><span class="line">    </span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_layer_norm_custom</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">                                                            GM_ADDR x, GM_ADDR y, GM_ADDR gamma, GM_ADDR beta, GM_ADDR res_out, GM_ADDR workspace,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                            GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 编译器会传入参数 DTYPE_X DTYPE_Y DTYPE_GEMMA DTYPE_BETA</span></span><br><span class="line">    KernelAddLayerNorm&lt;DTYPE_X&gt; op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, gamma, beta, res_out, tiling);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="host侧实现-2"><a href="#host侧实现-2" class="headerlink" title="host侧实现"></a>host侧实现</h2><h3 id="1-Tiling数据结构定义-add-layer-norm-tiling-h"><a href="#1-Tiling数据结构定义-add-layer-norm-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (add_layer_norm_tiling.h)"></a>1. Tiling数据结构定义 (add_layer_norm_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(AddLayerNormCustomTilingData)</span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowNum);     <span class="comment">// 小块核行数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowNumSp);   <span class="comment">// 大块核行数 = rowNum+1</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowLength);  <span class="comment">// 每行长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, blockPivot); <span class="comment">// 大块核心数量</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, tileLoop);   <span class="comment">// 核内分块 每块 行数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, tileLength); <span class="comment">// 核内分块 每块 数据总 长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, loopCount);  <span class="comment">// 核内分块 次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, factor); <span class="comment">// 列数倒数 // 算子参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, mfactor);<span class="comment">// 负 列数倒数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, eps);    <span class="comment">// epsilon</span></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(AddLayerNormCustom, AddLayerNormCustomTilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-add-layer-norm-cpp"><a href="#2-Tiling策略计算-add-layer-norm-cpp" class="headerlink" title="2. Tiling策略计算 (add_layer_norm.cpp)"></a>2. Tiling策略计算 (add_layer_norm.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;add_layer_norm_custom_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/tiling_api.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> matmul_tiling;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">//const uint32_t BLOCK_DIM = 48; // 48核 需要自适应</span></span><br><span class="line"><span class="type">const</span> <span class="type">uint32_t</span> BLOCK_SIZE = <span class="number">32</span>;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    AddLayerNormCustomTilingData tiling;</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape = x1_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* x2_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape2 = x2_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* gamma_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape3 = gamma_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="comment">// 维度校验</span></span><br><span class="line">    <span class="keyword">if</span> ((shape.<span class="built_in">GetDimNum</span>() != <span class="number">2</span>) || (shape<span class="number">2.</span><span class="built_in">GetDimNum</span>() != <span class="number">2</span>)) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input data dim error, only support 2 dims&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> ((shape.<span class="built_in">GetDim</span>(<span class="number">0</span>) != shape<span class="number">2.</span><span class="built_in">GetDim</span>(<span class="number">0</span>)) || (shape.<span class="built_in">GetDim</span>(<span class="number">1</span>) != shape<span class="number">2.</span><span class="built_in">GetDim</span>(<span class="number">1</span>))) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input data shape error.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 数据类型校验</span></span><br><span class="line">    <span class="keyword">auto</span> x1_dtype = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">auto</span> x2_dtype = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span> (((x1_dtype != ge::DT_FLOAT) &amp;&amp; (x2_dtype != ge::DT_FLOAT)) &amp;&amp;</span><br><span class="line">        ((x1_dtype != ge::DT_FLOAT16) &amp;&amp; (x2_dtype != ge::DT_FLOAT16))) &#123;</span><br><span class="line">        <span class="comment">// 支持 DT_FLOAT 和 DT_FLOAT16</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input type error, only support float or float16.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> rowNum = shape.<span class="built_in">GetDim</span>(<span class="number">0</span>); <span class="comment">// 矩阵总行数</span></span><br><span class="line">    <span class="keyword">auto</span> colNum = shape.<span class="built_in">GetDim</span>(<span class="number">1</span>); <span class="comment">// 每行数据量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核数 自适应</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNumAiv</span>();</span><br><span class="line">    <span class="type">uint32_t</span> BLOCK_DIM = std::<span class="built_in">min</span>((<span class="type">int</span>)rowNum, (<span class="type">int</span>)aivNum);</span><br><span class="line">    <span class="type">uint32_t</span> SIZE_OF_DT = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (x1_dtype == ge::DataType::DT_FLOAT) SIZE_OF_DT = <span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> ub_size; <span class="comment">// 192kb = 192*1024byte</span></span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> coreRowNum = rowNum / BLOCK_DIM; <span class="comment">// 单核 总 行数</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">float</span>* epsilonAttr = context-&gt;<span class="built_in">GetAttrs</span>()-&gt;<span class="built_in">GetAttrPointer</span>&lt;<span class="type">float</span>&gt;(<span class="number">0</span>);</span><br><span class="line">    tiling.<span class="built_in">set_eps</span>(*epsilonAttr);</span><br><span class="line">    <span class="comment">// 核间分块</span></span><br><span class="line">    tiling.<span class="built_in">set_rowNum</span>(coreRowNum);<span class="comment">// 小块 行数</span></span><br><span class="line">    tiling.<span class="built_in">set_rowNumSp</span>(coreRowNum + <span class="number">1</span>); <span class="comment">// 大块行数</span></span><br><span class="line">    tiling.<span class="built_in">set_rowLength</span>(colNum);<span class="comment">// 每行长度</span></span><br><span class="line">    tiling.<span class="built_in">set_blockPivot</span>(rowNum - coreRowNum * BLOCK_DIM);<span class="comment">// 大核数量，余数行分配到大核上</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 核内分块 自适应</span></span><br><span class="line">    <span class="comment">//uint32_t tileLoop = 18;// 每块长度，应该按照ub尺寸和每行数据量计算一次可以计算多少行</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLoop = (<span class="type">uint32_t</span>)(ub_size / colNum / BUFFER_NUM / SIZE_OF_DT / <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    tiling.<span class="built_in">set_tileLoop</span>(tileLoop);<span class="comment">// 核类单次单块计算 行数</span></span><br><span class="line">    tiling.<span class="built_in">set_tileLength</span>(tileLoop * colNum);  <span class="comment">// 核类单次单块计算数据量</span></span><br><span class="line">    tiling.<span class="built_in">set_loopCount</span>(coreRowNum / tileLoop); <span class="comment">// 核内需要循环执行次数，尾块单独执行下</span></span><br><span class="line">    tiling.<span class="built_in">set_factor</span>(<span class="number">1.0f</span> / colNum);   <span class="comment">// 列数倒数</span></span><br><span class="line">    tiling.<span class="built_in">set_mfactor</span>(<span class="number">-1.0f</span> / colNum); <span class="comment">// 负 列数倒数</span></span><br><span class="line">    </span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(BLOCK_DIM);</span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(),</span><br><span class="line">                        context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// context-&gt;SetTilingKey(1);</span></span><br><span class="line">    <span class="comment">//printf(&quot;=========core_num: %d tile_loop:%d \n&quot;, BLOCK_DIM, tileLoop);</span></span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;  <span class="comment">// namespace optiling</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;  <span class="comment">// namespace ge</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AddLayerNormCustom</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">AddLayerNormCustom</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name) &#123;</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;gamma&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;beta&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;res_out&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Attr</span>(<span class="string">&quot;epsilon&quot;</span>).<span class="built_in">AttrType</span>(OPTIONAL).<span class="built_in">Float</span>(<span class="number">1e-05</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">SetTiling</span>(optiling::TilingFunc);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend910b&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(AddLayerNormCustom);</span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报2.0</title>
      <link href="/2025/06/07/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A52.0/"/>
      <url>/2025/06/07/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A52.0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-项目背景"><a href="#1-项目背景" class="headerlink" title="1. 项目背景"></a>1. 项目背景</h1><ul><li><strong>任务</strong>：利用强化学习提升基于多通道的睡眠阶段数据分类模型的性能遇到瓶颈  </li><li><strong>睡眠阶段</strong>：W, N1, N2, N3, REM  </li><li><strong>挑战</strong>：  <ul><li>大部份预测错误都出现在W-&gt;N1,N1-&gt;N2转换的时候</li><li>模型很容易将N1误判成W或者N2</li><li>强化学习奖励不及预期</li></ul></li></ul><h1 id="2-数据集概况"><a href="#2-数据集概况" class="headerlink" title="2. 数据集概况"></a>2. 数据集概况</h1><h2 id="2-1-数据规模"><a href="#2-1-数据规模" class="headerlink" title="2.1 数据规模"></a>2.1 数据规模</h2><ul><li><strong>总样本数</strong>：8,549个睡眠epoch</li><li><strong>受试者数量</strong>：10人（采用10-fold交叉验证）</li><li><strong>数据分布</strong>：每个fold包含790-966个样本不等</li><li><strong>全局变化率</strong>：19.08%（睡眠阶段转换频率）</li></ul><h2 id="2-2-睡眠阶段分布分析"><a href="#2-2-睡眠阶段分布分析" class="headerlink" title="2.2 睡眠阶段分布分析"></a>2.2 睡眠阶段分布分析</h2><h3 id="全局阶段分布"><a href="#全局阶段分布" class="headerlink" title="全局阶段分布"></a>全局阶段分布</h3><p>基于8,549个样本的统计分析：</p><div class="table-container"><table><thead><tr><th>睡眠阶段</th><th>样本数</th><th>占比</th><th>特征描述</th></tr></thead><tbody><tr><td>W (清醒)</td><td>1,651</td><td>19.3%</td><td>清醒状态，通常出现在睡眠开始和结束</td></tr><tr><td>N1 (浅睡)</td><td>1,215</td><td>14.2%</td><td>入睡过渡期，持续时间短</td></tr><tr><td>N2 (轻睡)</td><td>2,609</td><td>30.5%</td><td><strong>主要睡眠阶段</strong>，占比最高</td></tr><tr><td>N3 (深睡)</td><td>2,014</td><td>23.6%</td><td>深度睡眠，恢复性睡眠</td></tr><tr><td>REM (快眼动)</td><td>1,060</td><td>12.4%</td><td>做梦阶段，认知功能重要</td></tr></tbody></table></div><p><strong>关键发现</strong>：</p><ul><li>N2阶段占主导地位（30.5%），符合正常睡眠结构</li><li>N1阶段占比相对较低（14.2%），这解释了为什么N1容易被误分类</li><li>各阶段分布符合健康成人睡眠模式</li></ul><h2 id="2-3-睡眠阶段转换模式分析"><a href="#2-3-睡眠阶段转换模式分析" class="headerlink" title="2.3 睡眠阶段转换模式分析"></a>2.3 睡眠阶段转换模式分析</h2><h3 id="转换矩阵统计"><a href="#转换矩阵统计" class="headerlink" title="转换矩阵统计"></a>转换矩阵统计</h3><p>基于全局转换概率矩阵的关键发现：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>77.7%</td><td>18.4%</td><td>3.3%</td><td>0.2%</td><td>0.2%</td></tr><tr><td><strong>N1</strong></td><td>12.6%</td><td>53.5%</td><td>25.8%</td><td>0.1%</td><td>8.1%</td></tr><tr><td><strong>N2</strong></td><td>5.0%</td><td>6.4%</td><td><strong>83.0%</strong></td><td>4.2%</td><td>1.4%</td></tr><tr><td><strong>N3</strong></td><td>1.6%</td><td>0.3%</td><td>3.4%</td><td><strong>94.4%</strong></td><td>0.2%</td></tr><tr><td><strong>REM</strong></td><td>4.0%</td><td>8.5%</td><td>0.9%</td><td>0.0%</td><td><strong>86.7%</strong></td></tr></tbody></table></div><p><strong>转换模式特征</strong>：</p><ol><li><strong>高稳定性阶段</strong>：N3（94.4%）和REM（86.7%）具有很高的自转换概率</li><li><strong>过渡性阶段</strong>：N1的自转换概率较低（53.5%），容易向其他阶段转换</li><li><strong>问题转换</strong>：<ul><li>W→N1：18.4%的转换概率</li><li>N1→N2：25.8%的转换概率</li><li>N1→W：12.6%的反向转换</li></ul></li></ol><h3 id="最频繁转换统计"><a href="#最频繁转换统计" class="headerlink" title="最频繁转换统计"></a>最频繁转换统计</h3><ul><li><strong>N2→N2</strong>：2,163次（最稳定的睡眠阶段）</li><li><strong>N3→N3</strong>：1,899次（深睡眠的连续性）</li><li><strong>REM→REM</strong>：917次（快眼动期的持续性）</li><li><strong>W→W</strong>：1,282次（清醒状态的维持）</li></ul><h2 id="2-4-睡眠阶段持续时间分析"><a href="#2-4-睡眠阶段持续时间分析" class="headerlink" title="2.4 睡眠阶段持续时间分析"></a>2.4 睡眠阶段持续时间分析</h2><h3 id="各阶段持续时间统计（单位：epoch）"><a href="#各阶段持续时间统计（单位：epoch）" class="headerlink" title="各阶段持续时间统计（单位：epoch）"></a>各阶段持续时间统计（单位：epoch）</h3><div class="table-container"><table><thead><tr><th>阶段</th><th>平均值</th><th>标准差</th><th>中位数</th><th>最小值</th><th>最大值</th><th>四分位距</th></tr></thead><tbody><tr><td>W</td><td>4.47</td><td>10.60</td><td>1.0</td><td>1</td><td>145</td><td>1.0-3.0</td></tr><tr><td>N1</td><td>2.15</td><td>1.83</td><td>1.0</td><td>1</td><td>18</td><td>1.0-3.0</td></tr><tr><td>N2</td><td>5.85</td><td>7.08</td><td>3.0</td><td>1</td><td>51</td><td>1.0-7.0</td></tr><tr><td>N3</td><td>17.51</td><td>22.17</td><td>7.0</td><td>1</td><td>96</td><td>2.0-22.0</td></tr><tr><td>REM</td><td>7.41</td><td>10.15</td><td>4.0</td><td>1</td><td>66</td><td>2.0-8.0</td></tr></tbody></table></div><p><strong>持续时间特征</strong>：</p><ol><li><strong>N3阶段持续时间最长</strong>：平均17.5个epoch，体现深睡眠的连续性</li><li><strong>N1阶段持续时间最短</strong>：平均2.15个epoch，证实其过渡性质</li><li><strong>高变异性</strong>：所有阶段都显示较大的标准差，表明个体差异显著</li><li><strong>极值分析</strong>：W阶段最大持续145个epoch，可能对应长时间清醒期</li></ol><h2 id="2-5-个体差异分析"><a href="#2-5-个体差异分析" class="headerlink" title="2.5 个体差异分析"></a>2.5 个体差异分析</h2><h3 id="跨受试者变异性"><a href="#跨受试者变异性" class="headerlink" title="跨受试者变异性"></a>跨受试者变异性</h3><p>通过10-fold数据分析发现显著的个体差异：</p><p><strong>阶段分布差异示例</strong>：</p><ul><li>Fold 4：W占比高达32.9%（可能的睡眠障碍个体）</li><li>Fold 5：W占比仅6.7%（良好睡眠质量个体）</li><li>Fold 7：W占比38.6%（另一个高清醒比例个体）</li></ul><p><strong>变化率差异</strong>：</p><ul><li>最低变化率：11.5%（Fold 7）</li><li>最高变化率：20.4%（Fold 2）</li><li>平均变化率：19.08%</li></ul><h2 id="2-6-数据预处理挑战与策略"><a href="#2-6-数据预处理挑战与策略" class="headerlink" title="2.6 数据预处理挑战与策略"></a>2.6 数据预处理挑战与策略</h2><h3 id="主要挑战"><a href="#主要挑战" class="headerlink" title="主要挑战"></a>主要挑战</h3><ol><li><p><strong>类别不平衡</strong>：</p><ul><li>N2阶段样本过多（30.5%）</li><li>N1阶段样本相对较少（14.2%）</li><li>需要采用平衡策略</li></ul></li><li><p><strong>边界模糊性</strong>：</p><ul><li>W↔N1转换：31.0%的双向转换概率</li><li>N1↔N2转换：32.2%的双向转换概率</li><li>这些转换是分类错误的主要来源</li></ul></li><li><p><strong>个体差异</strong>：</p><ul><li>睡眠模式个体差异显著</li><li>需要个性化的特征提取策略</li></ul></li></ol><h3 id="预处理策略"><a href="#预处理策略" class="headerlink" title="预处理策略"></a>预处理策略</h3><ol><li><p><strong>数据增强</strong>：</p><ul><li>针对N1阶段进行过采样</li><li>使用SMOTE等技术平衡类别分布</li></ul></li><li><p><strong>特征工程</strong>：</p><ul><li>提取转换上下文特征</li><li>计算阶段持续时间特征</li><li>引入时序依赖性特征</li></ul></li><li><p><strong>标注质量控制</strong>：</p><ul><li>重点关注W-N1-N2边界区域</li><li>建立专家一致性检查机制</li></ul></li></ol><h2 id="2-7-对强化学习模型的启示"><a href="#2-7-对强化学习模型的启示" class="headerlink" title="2.7 对强化学习模型的启示"></a>2.7 对强化学习模型的启示</h2><p>基于数据分析结果，为强化学习模型设计提供以下指导：</p><ol><li><p><strong>奖励函数设计</strong>：</p><ul><li>对N1正确分类给予更高奖励</li><li>对W↔N1、N1↔N2错误转换给予更大惩罚</li></ul></li><li><p><strong>状态空间设计</strong>：</p><ul><li>包含前序睡眠阶段信息</li><li>考虑阶段持续时间特征</li><li>引入个体差异参数</li></ul></li><li><p><strong>动作空间优化</strong>：</p><ul><li>设计渐进式分类策略</li><li>优先处理高置信度分类</li><li>对边界案例采用保守策略</li></ul></li></ol><h1 id="3-详细数据分析"><a href="#3-详细数据分析" class="headerlink" title="3. 详细数据分析"></a>3. 详细数据分析</h1><h2 id="3-1-个体转移概率矩阵分析"><a href="#3-1-个体转移概率矩阵分析" class="headerlink" title="3.1 个体转移概率矩阵分析"></a>3.1 个体转移概率矩阵分析</h2><p>基于10个受试者的睡眠数据，以下是每个个体的详细转移概率矩阵分析，重点关注问题转换区域：</p><h3 id="受试者1-Fold-0-样本数：920"><a href="#受试者1-Fold-0-样本数：920" class="headerlink" title="受试者1 (Fold 0) - 样本数：920"></a>受试者1 (Fold 0) - 样本数：920</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>74.4%</td><td>24.4%</td><td>1.3%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>13.2%</td><td>51.8%</td><td>28.9%</td><td>0.0%</td><td>6.1%</td></tr><tr><td><strong>N2</strong></td><td>4.1%</td><td>2.5%</td><td><strong>88.8%</strong></td><td>3.6%</td><td>1.1%</td></tr><tr><td><strong>N3</strong></td><td>3.4%</td><td>0.0%</td><td>3.9%</td><td><strong>92.7%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.0%</td><td>6.9%</td><td>0.0%</td><td>0.0%</td><td><strong>89.1%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换率24.4%（高于平均）</li><li>N1自维持率51.8%（低于平均）</li><li>N2稳定性88.8%（高于平均）</li></ul><h3 id="受试者2-Fold-1-样本数：907"><a href="#受试者2-Fold-1-样本数：907" class="headerlink" title="受试者2 (Fold 1) - 样本数：907"></a>受试者2 (Fold 1) - 样本数：907</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>70.4%</td><td>24.5%</td><td>5.1%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>8.5%</td><td>53.2%</td><td>24.8%</td><td>0.0%</td><td>13.5%</td></tr><tr><td><strong>N2</strong></td><td>3.4%</td><td>6.5%</td><td><strong>84.5%</strong></td><td>3.7%</td><td>1.9%</td></tr><tr><td><strong>N3</strong></td><td>1.0%</td><td>0.0%</td><td>4.6%</td><td><strong>93.9%</strong></td><td>0.5%</td></tr><tr><td><strong>REM</strong></td><td>2.0%</td><td>14.3%</td><td>0.7%</td><td>0.0%</td><td><strong>83.0%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N2直接转换5.1%（异常高）</li><li>N1→REM转换13.5%（显著高于平均）</li><li>REM→N1转换14.3%（异常高）</li></ul><h3 id="受试者3-Fold-2-样本数：790"><a href="#受试者3-Fold-2-样本数：790" class="headerlink" title="受试者3 (Fold 2) - 样本数：790"></a>受试者3 (Fold 2) - 样本数：790</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>51.3%</td><td>23.1%</td><td>21.8%</td><td>2.6%</td><td>1.3%</td></tr><tr><td><strong>N1</strong></td><td>10.9%</td><td>43.8%</td><td>35.9%</td><td>0.0%</td><td>9.4%</td></tr><tr><td><strong>N2</strong></td><td>8.0%</td><td>4.8%</td><td><strong>81.1%</strong></td><td>3.6%</td><td>2.4%</td></tr><tr><td><strong>N3</strong></td><td>1.7%</td><td>0.0%</td><td>1.7%</td><td><strong>96.6%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.9%</td><td>5.8%</td><td>1.9%</td><td>0.0%</td><td><strong>87.4%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W自维持率仅51.3%（最低）</li><li>W→N2转换21.8%（异常高）</li><li>N1→N2转换35.9%（最高）</li><li>该个体睡眠转换最不稳定</li></ul><h3 id="受试者4-Fold-3-样本数：760"><a href="#受试者4-Fold-3-样本数：760" class="headerlink" title="受试者4 (Fold 3) - 样本数：760"></a>受试者4 (Fold 3) - 样本数：760</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>83.5%</td><td>15.1%</td><td>0.7%</td><td>0.0%</td><td>0.7%</td></tr><tr><td><strong>N1</strong></td><td>7.3%</td><td>53.3%</td><td>27.7%</td><td>0.7%</td><td>10.9%</td></tr><tr><td><strong>N2</strong></td><td>2.6%</td><td>11.1%</td><td><strong>80.3%</strong></td><td>5.1%</td><td>0.9%</td></tr><tr><td><strong>N3</strong></td><td>1.3%</td><td>1.9%</td><td>4.4%</td><td><strong>91.8%</strong></td><td>0.6%</td></tr><tr><td><strong>REM</strong></td><td>5.6%</td><td>15.6%</td><td>0.0%</td><td>0.0%</td><td><strong>78.9%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性83.5%（较高）</li><li>N2→N1转换11.1%（异常高）</li><li>REM→N1转换15.6%（最高）</li></ul><h3 id="受试者5-Fold-4-样本数：910"><a href="#受试者5-Fold-4-样本数：910" class="headerlink" title="受试者5 (Fold 4) - 样本数：910"></a>受试者5 (Fold 4) - 样本数：910</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>86.9%</td><td>9.4%</td><td>3.7%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>15.7%</td><td>34.3%</td><td>32.9%</td><td>0.0%</td><td>17.1%</td></tr><tr><td><strong>N2</strong></td><td>6.4%</td><td>3.4%</td><td><strong>85.3%</strong></td><td>3.8%</td><td>1.1%</td></tr><tr><td><strong>N3</strong></td><td>2.1%</td><td>0.5%</td><td>2.6%</td><td><strong>94.9%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>8.6%</td><td>9.9%</td><td>0.0%</td><td>0.0%</td><td><strong>81.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性86.9%（最高）</li><li>N1自维持率仅34.3%（最低）</li><li>N1→REM转换17.1%（最高）</li><li>该个体W阶段占比32.9%，可能存在睡眠障碍</li></ul><h3 id="受试者6-Fold-5-样本数：819"><a href="#受试者6-Fold-5-样本数：819" class="headerlink" title="受试者6 (Fold 5) - 样本数：819"></a>受试者6 (Fold 5) - 样本数：819</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>38.2%</td><td>52.7%</td><td>9.1%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>12.1%</td><td>51.5%</td><td>25.0%</td><td>0.0%</td><td>11.4%</td></tr><tr><td><strong>N2</strong></td><td>4.5%</td><td>6.3%</td><td><strong>82.6%</strong></td><td>4.9%</td><td>1.7%</td></tr><tr><td><strong>N3</strong></td><td>0.8%</td><td>0.0%</td><td>4.9%</td><td><strong>94.3%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>2.1%</td><td>17.7%</td><td>1.0%</td><td>0.0%</td><td><strong>79.2%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换52.7%（最高）</li><li>W自维持率仅38.2%（第二低）</li><li>REM→N1转换17.7%（第二高）</li><li>该个体入睡转换非常活跃</li></ul><h3 id="受试者7-Fold-6-样本数：780"><a href="#受试者7-Fold-6-样本数：780" class="headerlink" title="受试者7 (Fold 6) - 样本数：780"></a>受试者7 (Fold 6) - 样本数：780</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>79.4%</td><td>14.7%</td><td>4.9%</td><td>0.5%</td><td>0.5%</td></tr><tr><td><strong>N1</strong></td><td>33.9%</td><td>35.5%</td><td>21.0%</td><td>0.0%</td><td>9.7%</td></tr><tr><td><strong>N2</strong></td><td>7.1%</td><td>3.2%</td><td><strong>75.5%</strong></td><td>12.9%</td><td>1.3%</td></tr><tr><td><strong>N3</strong></td><td>1.9%</td><td>0.0%</td><td>5.3%</td><td><strong>92.0%</strong></td><td>0.8%</td></tr><tr><td><strong>REM</strong></td><td>4.2%</td><td>6.3%</td><td>1.0%</td><td>0.0%</td><td><strong>88.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>N1→W反向转换33.9%（最高）</li><li>N1自维持率35.5%（第二低）</li><li>N2→N3转换12.9%（最高）</li><li>该个体N1阶段极不稳定</li></ul><h3 id="受试者8-Fold-7-样本数：966"><a href="#受试者8-Fold-7-样本数：966" class="headerlink" title="受试者8 (Fold 7) - 样本数：966"></a>受试者8 (Fold 7) - 样本数：966</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>92.8%</td><td>7.2%</td><td>0.0%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>10.1%</td><td>60.6%</td><td>22.9%</td><td>0.0%</td><td>6.4%</td></tr><tr><td><strong>N2</strong></td><td>3.6%</td><td>7.2%</td><td><strong>85.6%</strong></td><td>2.6%</td><td>1.0%</td></tr><tr><td><strong>N3</strong></td><td>1.4%</td><td>0.0%</td><td>2.1%</td><td><strong>96.5%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>4.1%</td><td>1.4%</td><td>0.0%</td><td>0.0%</td><td><strong>94.5%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W稳定性92.8%（最高）</li><li>N3稳定性96.5%（最高）</li><li>REM稳定性94.5%（最高）</li><li>该个体睡眠结构最稳定，W占比38.6%</li></ul><h3 id="受试者9-Fold-8-样本数：935"><a href="#受试者9-Fold-8-样本数：935" class="headerlink" title="受试者9 (Fold 8) - 样本数：935"></a>受试者9 (Fold 8) - 样本数：935</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>60.8%</td><td>35.8%</td><td>1.7%</td><td>0.8%</td><td>0.8%</td></tr><tr><td><strong>N1</strong></td><td>10.2%</td><td>48.5%</td><td>35.9%</td><td>0.0%</td><td>5.4%</td></tr><tr><td><strong>N2</strong></td><td>5.6%</td><td>9.5%</td><td><strong>81.1%</strong></td><td>3.1%</td><td>0.8%</td></tr><tr><td><strong>N3</strong></td><td>1.8%</td><td>0.9%</td><td>2.2%</td><td><strong>94.7%</strong></td><td>0.4%</td></tr><tr><td><strong>REM</strong></td><td>7.9%</td><td>11.1%</td><td>3.2%</td><td>0.0%</td><td><strong>77.8%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>W→N1转换35.8%（第二高）</li><li>N1→N2转换35.9%（第二高）</li><li>N2→N1转换9.5%（较高）</li><li>REM稳定性77.8%（最低）</li></ul><h3 id="受试者10-Fold-9-样本数：762"><a href="#受试者10-Fold-9-样本数：762" class="headerlink" title="受试者10 (Fold 9) - 样本数：762"></a>受试者10 (Fold 9) - 样本数：762</h3><p><strong>转移概率矩阵</strong>：</p><div class="table-container"><table><thead><tr><th>从\到</th><th>W</th><th>N1</th><th>N2</th><th>N3</th><th>REM</th></tr></thead><tbody><tr><td><strong>W</strong></td><td>62.1%</td><td>36.3%</td><td>1.6%</td><td>0.0%</td><td>0.0%</td></tr><tr><td><strong>N1</strong></td><td>15.1%</td><td>70.2%</td><td>13.8%</td><td>0.0%</td><td>0.9%</td></tr><tr><td><strong>N2</strong></td><td>6.4%</td><td>10.4%</td><td><strong>79.2%</strong></td><td>2.3%</td><td>1.7%</td></tr><tr><td><strong>N3</strong></td><td>0.9%</td><td>0.0%</td><td>1.8%</td><td><strong>97.3%</strong></td><td>0.0%</td></tr><tr><td><strong>REM</strong></td><td>0.7%</td><td>1.5%</td><td>1.5%</td><td>0.0%</td><td><strong>96.3%</strong></td></tr></tbody></table></div><p><strong>关键特征</strong>：</p><ul><li>N1稳定性70.2%（最高）</li><li>N3稳定性97.3%（最高）</li><li>REM稳定性96.3%（第二高）</li><li>N1→N2转换仅13.8%（最低）</li><li>该个体N1阶段占比28.6%（最高）</li></ul><h2 id="3-2-个体差异总结"><a href="#3-2-个体差异总结" class="headerlink" title="3.2 个体差异总结"></a>3.2 个体差异总结</h2><h3 id="转移模式分类"><a href="#转移模式分类" class="headerlink" title="转移模式分类"></a>转移模式分类</h3><p>基于转移概率特征，可将10个受试者分为以下类型：</p><p><strong>1. 稳定型（Fold 7, Fold 9）</strong>：</p><ul><li>各阶段自维持概率高</li><li>转换相对保守</li><li>睡眠结构规律</li></ul><p><strong>2. 过渡型（Fold 2, Fold 8）</strong>：</p><ul><li>W-N1-N2转换频繁</li><li>睡眠阶段边界模糊</li><li>分类难度最高</li></ul><p><strong>3. 清醒主导型（Fold 4, Fold 7）</strong>：</p><ul><li>W阶段占比异常高（&gt;30%）</li><li>可能存在睡眠障碍</li><li>需要特殊处理策略</li></ul><p><strong>4. 平衡型（Fold 0, Fold 1, Fold 3, Fold 5, Fold 6）</strong>：</p><ul><li>各阶段分布相对均衡</li><li>转移模式接近群体平均</li><li>代表典型睡眠模式</li></ul><h3 id="对模型训练的影响"><a href="#对模型训练的影响" class="headerlink" title="对模型训练的影响"></a>对模型训练的影响</h3><p><strong>1. 数据不平衡问题</strong>：</p><ul><li>个体间W阶段占比差异巨大（6.7%-38.6%）</li><li>N1阶段个体差异显著（7.7%-28.6%）</li><li>需要个体化的采样策略</li></ul><p><strong>2. 转移模式多样性</strong>：</p><ul><li>W→N1转换率：7.2%-52.7%</li><li>N1→N2转换率：13.8%-35.9%</li><li>需要多样化的特征表示</li></ul><p><strong>3. 模型泛化挑战</strong>：</p><ul><li>个体睡眠模式差异巨大</li><li>单一模型难以适应所有个体</li><li>建议采用个体适应或元学习方法</li></ul><hr><h1 id="4-模型改进方案：多专家模型架构"><a href="#4-模型改进方案：多专家模型架构" class="headerlink" title="4. 模型改进方案：多专家模型架构"></a>4. 模型改进方案：多专家模型架构</h1><h2 id="4-1-问题分析与改进动机"><a href="#4-1-问题分析与改进动机" class="headerlink" title="4.1 问题分析与改进动机"></a>4.1 问题分析与改进动机</h2><h3 id="现有模型性能特征"><a href="#现有模型性能特征" class="headerlink" title="现有模型性能特征"></a>现有模型性能特征</h3><p>基于数据分析发现，当前睡眠阶段分类模型存在明显的性能不均衡：</p><p><strong>优势阶段</strong>：</p><ul><li><strong>N3（深睡）</strong>：自维持概率94.4%，分类准确率高</li><li><strong>REM（快眼动）</strong>：自维持概率86.7%，特征相对明确</li></ul><p><strong>困难阶段</strong>：</p><ul><li><strong>W（清醒）</strong>：与N1混淆严重，个体差异大（占比6.7%-38.6%）</li><li><strong>N1（浅睡）</strong>：过渡性强，自维持概率仅53.5%</li><li><strong>N2（轻睡）</strong>：虽然稳定性较好（83.0%），但与N1边界模糊</li></ul><h3 id="核心问题识别"><a href="#核心问题识别" class="headerlink" title="核心问题识别"></a>核心问题识别</h3><ol><li><strong>阶段特征差异性</strong>：稳定阶段（N3、REM）与过渡阶段（W、N1、N2）具有本质不同的特征模式</li><li><strong>转换复杂性</strong>：W↔N1↔N2之间的频繁转换（18.4%、25.8%、12.6%）增加了分类难度</li><li><strong>个体差异性</strong>：不同受试者在过渡阶段表现出巨大差异，单一模型难以兼顾</li></ol><h2 id="4-2-多专家模型设计方案"><a href="#4-2-多专家模型设计方案" class="headerlink" title="4.2 多专家模型设计方案"></a>4.2 多专家模型设计方案</h2><h3 id="4-2-1-架构设计理念"><a href="#4-2-1-架构设计理念" class="headerlink" title="4.2.1 架构设计理念"></a>4.2.1 架构设计理念</h3><p>借鉴大语言模型中的混合专家（Mixture of Experts, MOE）思想，设计层次化的多专家睡眠阶段分类系统：</p><p><strong>核心思想</strong>：</p><ul><li>让每个专家模型专注于特定类型睡眠阶段的识别</li><li>避免”一刀切”模型在不同阶段上的性能妥协</li><li>实现”因材施教”的个性化分类策略</li></ul><h3 id="4-2-2-层次化分类架构"><a href="#4-2-2-层次化分类架构" class="headerlink" title="4.2.2 层次化分类架构"></a>4.2.2 层次化分类架构</h3><p><strong>第一层：粗分类器（阶段类型识别）</strong></p><ul><li><strong>目标</strong>：区分稳定阶段 vs 过渡阶段</li><li><strong>输入</strong>：原始多通道睡眠信号特征</li><li><strong>输出</strong>：二分类结果<ul><li>类别A：稳定阶段（N3、REM）</li><li>类别B：过渡阶段（W、N1、N2）</li></ul></li></ul><p><strong>第二层：专家分类器（细粒度识别）</strong></p><ul><li><strong>稳定阶段专家</strong>：专门区分N3 vs REM<ul><li>利用两阶段的高稳定性特征</li><li>重点关注深睡眠与快眼动的生理差异</li></ul></li><li><strong>过渡阶段专家</strong>：专门处理W vs N1 vs N2<ul><li>针对性处理高混淆的三分类问题</li><li>集成个体差异适应机制</li></ul></li></ul><h3 id="4-2-3-专家模型特化策略"><a href="#4-2-3-专家模型特化策略" class="headerlink" title="4.2.3 专家模型特化策略"></a>4.2.3 专家模型特化策略</h3><p><strong>稳定阶段专家优化</strong>：</p><ul><li><strong>特征选择</strong>：重点关注脑电波频域特征、肌电信号强度</li><li><strong>训练策略</strong>：利用高纯度样本进行对比学习</li></ul><p><strong>过渡阶段专家优化</strong>：</p><ul><li><strong>特征工程</strong>：增强时序特征、上下文信息</li><li><strong>数据增强</strong>：针对N1稀少样本进行合成</li><li><strong>个体适应</strong>：集成个体睡眠模式先验知识</li></ul><h2 id="4-3-实施策略与技术路线"><a href="#4-3-实施策略与技术路线" class="headerlink" title="4.3 实施策略与技术路线"></a>4.3 实施策略与技术路线</h2><h3 id="4-3-1-数据划分策略"><a href="#4-3-1-数据划分策略" class="headerlink" title="4.3.1 数据划分策略"></a>4.3.1 数据划分策略</h3><p><strong>训练数据重组</strong>：</p><ul><li><strong>粗分类器训练集</strong>：使用全部8,549个样本，标签重新编码为稳定/过渡</li><li><strong>稳定专家训练集</strong>：3,074个样本（N3: 2,014 + REM: 1,060）</li><li><strong>过渡专家训练集</strong>：5,475个样本（W: 1,651 + N1: 1,215 + N2: 2,609）</li></ul><p><strong>交叉验证适配</strong>：</p><ul><li>保持10-fold结构，确保个体差异的充分表示</li><li>每个fold内同时训练三个子模型</li><li>使用集成学习融合不同fold的专家知识</li></ul><h3 id="4-3-2-模型训练流程"><a href="#4-3-2-模型训练流程" class="headerlink" title="4.3.2 模型训练流程"></a>4.3.2 模型训练流程</h3><p><strong>阶段一：粗分类器训练</strong></p><ol><li>特征提取：使用现有的多通道特征工程</li><li>标签转换：将5分类转换为2分类</li><li>评估指标：重点关注召回率平衡</li></ol><p><strong>阶段二：专家模型训练</strong></p><ol><li><strong>稳定专家</strong>：<ul><li>深度特征学习，关注频域稳定性</li><li>对比学习增强N3与REM的区分度</li></ul></li><li><strong>过渡专家</strong>：<ul><li>序列建模，捕获W-N1-N2转换模式</li><li>注意力机制突出关键时间窗口</li><li>元学习适应个体差异</li></ul></li></ol><p><strong>阶段三：端到端优化</strong></p><ol><li>联合训练微调整体系统</li><li>损失函数设计：加权多任务学习</li><li>推理优化：级联推理加速</li></ol><h3 id="4-3-3-评估与验证"><a href="#4-3-3-评估与验证" class="headerlink" title="4.3.3 评估与验证"></a>4.3.3 评估与验证</h3><p><strong>分层评估策略</strong>：</p><ul><li><strong>粗分类性能</strong>：稳定vs过渡的二分类准确率</li><li><strong>专家性能</strong>：各专家在对应子任务上的表现</li><li><strong>整体性能</strong>：端到端5分类的综合指标</li></ul><p><strong>关键指标</strong>：</p><ul><li>整体准确率提升幅度</li><li>困难阶段（W、N1、N2）的F1-score改善</li><li>个体间性能方差减小</li><li>推理速度与计算开销</li></ul><h2 id="4-4-预期效果与优势分析"><a href="#4-4-预期效果与优势分析" class="headerlink" title="4.4 预期效果与优势分析"></a>4.4 预期效果与优势分析</h2><h3 id="4-4-1-方法优势"><a href="#4-4-1-方法优势" class="headerlink" title="4.4.1 方法优势"></a>4.4.1 方法优势</h3><p><strong>技术优势</strong>：</p><ol><li><strong>专业化分工</strong>：每个模型专注于最擅长的任务</li><li><strong>个体适应性</strong>：过渡专家可针对不同睡眠模式优化</li><li><strong>可解释性</strong>：层次化决策过程更易理解和调试</li><li><strong>扩展性</strong>：可根据新数据灵活调整专家配置</li></ol><p><strong>实用优势</strong>：</p><ol><li><strong>鲁棒性提升</strong>：减少单点故障风险</li><li><strong>部署灵活性</strong>：可根据计算资源选择性部署专家</li><li><strong>持续优化</strong>：可独立优化各专家而不影响整体</li></ol><h3 id="4-4-2-潜在挑战与解决方案"><a href="#4-4-2-潜在挑战与解决方案" class="headerlink" title="4.4.2 潜在挑战与解决方案"></a>4.4.2 潜在挑战与解决方案</h3><p><strong>挑战1：计算复杂度增加</strong></p><ul><li>解决方案：模型压缩、知识蒸馏、边缘计算优化</li></ul><p><strong>挑战2：粗分类器错误传播</strong></p><ul><li>解决方案：置信度阈值、软决策融合、错误纠正机制</li></ul><p><strong>挑战3：数据不平衡加剧</strong></p><ul><li>解决方案：专门的采样策略、生成式数据增强</li></ul><hr><h1 id="5-总结与展望"><a href="#5-总结与展望" class="headerlink" title="5. 总结与展望"></a>5. 总结与展望</h1><p>本项目通过对8,549个睡眠epoch的深入分析，揭示了睡眠阶段分类中的关键挑战和改进机会。多专家模型架构为解决现有模型在不同睡眠阶段上的性能不均衡问题提供了一个有前景的解决方案。</p><p><strong>核心贡献</strong>：</p><ol><li>系统分析了10个受试者的睡眠模式差异和转移特征</li><li>识别了W-N1-N2过渡阶段的分类难点</li><li>提出了基于MOE思想的层次化多专家分类架构</li><li>设计了完整的实施策略和评估方案</li></ol><p><strong>创新价值</strong>：</p><ul><li>将大模型领域的专家混合思想引入睡眠医学</li><li>提供了个体化睡眠分析的新思路</li><li>为睡眠障碍诊断提供了技术支撑</li></ul><p>通过这种”因材施教”的专家模型设计，我们有望显著提升睡眠阶段分类的准确性，特别是在困难的过渡阶段，为睡眠健康监测和临床诊断提供更可靠的技术支持。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>楼道数据分析</title>
      <link href="/2025/05/23/%E6%A5%BC%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/2025/05/23/%E6%A5%BC%E9%81%93%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><strong>5. 模型比较与分析</strong>  </p><p>在相同数据集和训练设置下，对比 LeNet-5、AlexNet、VGG 系列、MobileNet 系列和 ResNet 系列等模型的关键指标，可以得到以下结论：</p><div class="table-container"><table><thead><tr><th style="text-align:center">模型</th><th style="text-align:center">平均准确率</th><th style="text-align:center">平均精确率</th><th style="text-align:center">平均召回率</th><th style="text-align:center">平均 F1 分数</th><th style="text-align:center">参数量（≈）</th><th style="text-align:center">推理速度（≈）</th></tr></thead><tbody><tr><td style="text-align:center">LeNet-5</td><td style="text-align:center">59.41%</td><td style="text-align:center">46.30%</td><td style="text-align:center">58.10%</td><td style="text-align:center">44.35%</td><td style="text-align:center">~0.06M</td><td style="text-align:center">非常快（N=1ms）</td></tr><tr><td style="text-align:center">AlexNet</td><td style="text-align:center">67.82%</td><td style="text-align:center">62.00%</td><td style="text-align:center">65.97%</td><td style="text-align:center">62.16%</td><td style="text-align:center">~60M</td><td style="text-align:center">较快（10ms）</td></tr><tr><td style="text-align:center">VGG16</td><td style="text-align:center">73.02%</td><td style="text-align:center">72.01%</td><td style="text-align:center">73.40%</td><td style="text-align:center">70.80%</td><td style="text-align:center">~138M</td><td style="text-align:center">慢（20ms）</td></tr><tr><td style="text-align:center">VGG19</td><td style="text-align:center">74.00%</td><td style="text-align:center">71.83%</td><td style="text-align:center">72.66%</td><td style="text-align:center">70.55%</td><td style="text-align:center">~143M</td><td style="text-align:center">很慢（25ms）</td></tr><tr><td style="text-align:center">MobileNetV2</td><td style="text-align:center">62.82%</td><td style="text-align:center">49.79%</td><td style="text-align:center">60.92%</td><td style="text-align:center">52.19%</td><td style="text-align:center">~3.4M</td><td style="text-align:center">快（5ms）</td></tr><tr><td style="text-align:center">MobileNetV3</td><td style="text-align:center">58.90%</td><td style="text-align:center">34.39%</td><td style="text-align:center">58.25%</td><td style="text-align:center">43.25%</td><td style="text-align:center">~5.4M</td><td style="text-align:center">快（5ms）</td></tr><tr><td style="text-align:center">ResNet34</td><td style="text-align:center">73.97%</td><td style="text-align:center">73.55%</td><td style="text-align:center">75.19%</td><td style="text-align:center">73.31%</td><td style="text-align:center">~21.8M</td><td style="text-align:center">中等（15ms）</td></tr><tr><td style="text-align:center">ResNet50</td><td style="text-align:center">74.15%</td><td style="text-align:center">73.63%</td><td style="text-align:center">74.29%</td><td style="text-align:center">71.72%</td><td style="text-align:center">~25.6M</td><td style="text-align:center">中等（18ms）</td></tr></tbody></table></div><ul><li><p><strong>总体表现</strong>：</p><ul><li>VGG 与 ResNet 系列在准确率和召回率上表现最佳，ResNet50 以 74.15% 的平均准确率略胜 VGG19。</li><li>轻量级网络 MobileNetV2/V3 即便参数量小、推理快，但精确率和 F1 分数下降明显，表明在本任务中容量受限对分类性能影响较大。</li><li>经典浅层网络 LeNet-5 与 AlexNet 虽然推理速度快，但与更深、更复杂的模型相比，性能存在较大差距（相差约15–20个百分点）。</li></ul></li><li><p><strong>模型复杂度 vs. 性能</strong>：</p><ul><li>随着模型深度和参数量增加，准确率整体趋于提升，但边际效益递减——VGG19（143M 参数）相比 VGG16（138M 参数）增长仅≈0.98%。</li><li>ResNet 引入的残差结构，令更深网络仍能保持有效梯度传播，因此 ResNet34/50 在相似规模下性能优于同类非残差网络。</li></ul></li><li><p><strong>数据增强的作用</strong>：</p><ul><li>在基础几何和颜色变换之外，加入 MixUp、CutMix 与 Random Erasing 等高级增强后，所有模型的泛化能力均有明显提升。</li><li>尤其对轻量化模型（MobileNet 系列），高级增强帮助其在小模型容量下获得更稳定的决策边界，减少过拟合现象。</li></ul></li></ul><hr><h3 id="三、实验感悟和总结"><a href="#三、实验感悟和总结" class="headerlink" title="三、实验感悟和总结"></a>三、实验感悟和总结</h3><ol><li><p><strong>工具链与框架</strong></p><ul><li>熟练掌握了 PyTorch 的模型定义、数据加载（DataLoader）、训练与验证流程；</li><li>深入理解了 NumPy、matplotlib、PIL、OpenCV 在数据预处理与可视化中的配合与使用。</li></ul></li><li><p><strong>实验设计与迭代</strong></p><ul><li>从简单到复杂分阶段实施：先用 LeNet-5 快速验证流程，再逐步引入更深网络，避免从一开始就陷入长时间的训练等待；</li><li>比较不同网络结构、损失函数与优化器、学习率调度器对收敛速度与最终性能的影响，培养了科学实验的思路。</li></ul></li><li><p><strong>性能与资源权衡</strong></p><ul><li>在实际部署场景中，需要在准确率、模型大小与推理速度间进行折中；</li><li>轻量化模型在资源受限环境（如嵌入式设备）有明显优势，但在对性能要求高的场景下，需考虑使用中等规模的残差网络或裁剪／量化等技术。</li></ul></li><li><p><strong>团队合作与问题定位</strong></p><ul><li>多人协作实验中，通过版本管理与日志记录能更快地回溯错误；</li><li>在模型训练中遇到收敛缓慢、过拟合等问题时，通过可视化损失曲线和混淆矩阵，快速定位并调整超参数或增强策略。</li></ul></li></ol><hr><h3 id="四、思考题"><a href="#四、思考题" class="headerlink" title="四、思考题"></a>四、思考题</h3><p>（一）<strong>近年来目标检测方法和训练的趋势</strong></p><ol><li><strong>Transformer 与自注意力机制</strong><ul><li>DETR 系列将 Detection 转化为序列预测，无需手工设计 Anchor，简化了后处理流程；</li></ul></li><li><strong>Anchor-free 方法</strong><ul><li>如 FCOS、CenterNet 等，直接预测中心点或关键点，提高速度并简化设计；</li></ul></li><li><strong>多任务与统一架构</strong><ul><li>单一骨干网络同时输出分类、检测、分割结果，推动了通用视觉模型的发展；</li></ul></li><li><strong>自监督预训练</strong><ul><li>如 MoCo、SimCLR 为下游检测任务提供了更具泛化能力的预训练模型。</li></ul></li></ol><p>（二）<strong>几种基础大模型及其训练方案</strong></p><ol><li><strong>BERT（双向 Transformer）</strong><ul><li>预训练任务：Masked Language Modeling、Next Sentence Prediction；</li></ul></li><li><strong>GPT 系列（自回归 Transformer）</strong><ul><li>通过海量文本进行语言模型训练，生成式下游任务效果突出；</li></ul></li><li><strong>ViT（Vision Transformer）</strong><ul><li>将图像分割成 patch，按序列方式输入 Transformer，结合大规模数据与强正则化训练；</li></ul></li><li><strong>混合架构</strong><ul><li>如 ConvNext、Swin Transformer，将卷积与自注意力融合，兼顾效率与性能。</li></ul></li></ol><p>（三）<strong>感兴趣的前沿方向</strong></p><ul><li><strong>多模态学习</strong>：视觉语言预训练（如 CLIP、DALL·E）；</li><li><strong>自监督与无监督学习</strong>：减少标注依赖，探索更通用的表征；</li><li><strong>联邦学习与隐私保护</strong>：在数据不出设备前提下进行协同训练；</li><li><strong>神经架构搜索（NAS）</strong>：自动化设计轻量高效网络；</li><li><strong>图神经网络与时空建模</strong>：应用于视频理解及动态场景感知。</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>项目汇报1.0</title>
      <link href="/2025/05/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A51.0/"/>
      <url>/2025/05/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A51.0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-项目背景"><a href="#1-项目背景" class="headerlink" title="1. 项目背景"></a>1. 项目背景</h1><ul><li><strong>任务</strong>：利用强化学习提升基于多通道的睡眠阶段数据分类模型的性能  </li><li><strong>睡眠阶段</strong>：W, N1, N2, N3, REM  </li><li><strong>挑战</strong>：  <ul><li>序列预测需保持时序平滑  </li><li>不同阶段在整夜睡眠中出现的时间分布不同  </li><li>阶段之间的转移概率有先验知识</li></ul></li></ul><h1 id="2-现有数据背景"><a href="#2-现有数据背景" class="headerlink" title="2. 现有数据背景"></a>2. 现有数据背景</h1><p>基于现有原始MVF模型，可以得到下列真值与预测值图像的对比如下<br><img src="/img/combined-1.png" alt="image.png"><br>可以观察到，绝大部分数据的错误点都在真值的拐点处，并且真实值的波动性较大，而实际值的图像较为平滑，所以选择了以下的方式构建了强化学习的奖励函数：</p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>cls</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mrow><mi mathvariant="normal">A</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">y</mi></mrow><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>sm</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>N</mi></munderover><mn mathvariant="bold">1</mn><mo stretchy="false">{</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo mathvariant="normal">≠</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">}</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>trans</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>N</mi></munderover><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>P</mi><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mtext> </mtext><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub></mrow></msub><mo>+</mo><mi>ϵ</mi><mo fence="true">)</mo></mrow><mo>+</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>r</mi><mtext>time</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mn mathvariant="bold">1</mn><mrow><mo fence="true">(</mo><mi>t</mi><mi mathvariant="normal">/</mi><mi>N</mi><mo>∈</mo><mtext>期望时间区间</mtext><mo stretchy="false">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>R</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>α</mi><mtext> </mtext><msub><mi>r</mi><mtext>cls</mtext></msub><mo>+</mo><mi>β</mi><mtext> </mtext><msub><mi>r</mi><mtext>sm</mtext></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><msub><mi>r</mi><mtext>trans</mtext></msub><mo>+</mo><mi>δ</mi><mtext> </mtext><msub><mi>r</mi><mtext>time</mtext></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}r_\text{cls} &amp;= \mathrm{Accuracy}(y, \hat y) \\r_\text{sm}  &amp;= 1 - \frac{1}{N-1} \sum_{t=2}^N \mathbf{1}\{\hat y_t \neq \hat y_{t-1}\} \\r_\text{trans} &amp;= \frac{1}{N-1}\sum_{t=2}^N \log\left(P_{\hat y_{t-1},\,\hat y_t} + \epsilon\right) + 1 \\r_\text{time} &amp;= \frac{1}{N}\sum_{t=1}^N \mathbf{1}\left(t/N \in \text{期望时间区间}(\hat y_t)\right) \\R &amp;= \alpha\,r_\text{cls}    + \beta\,r_\text{sm}    + \gamma\,r_\text{trans}    + \delta\,r_\text{time}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:13.1863em;vertical-align:-6.3432em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.8432em;"><span style="top:-9.8315em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">cls</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-7.3432em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">sm</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9477em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">trans</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.5523em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">time</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:1.8548em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:6.3432em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:6.8432em;"><span style="top:-9.8315em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.01389em;">Accuracy</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-7.3432em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">1</span><span class="mopen">{</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span><span style="top:-3.9477em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2025em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2918em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-0.5523em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">1</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal">t</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord cjk_fallback">期望时间区间</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:1.8548em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">cls</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">sm</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">trans</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">time</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:6.3432em;"><span></span></span></span></span></span></span></span></span></span></span><h2 id="分别解释来说"><a href="#分别解释来说" class="headerlink" title="分别解释来说"></a>分别解释来说</h2><h3 id="1-对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性"><a href="#1-对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性" class="headerlink" title="1.对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性"></a>1.对于r-cls而言，目的是为了保证准确性在奖励函数占据主导方向，保证稳住准确性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类精度奖励 r_cls</span></span><br><span class="line">r_cls = accuracy_score(targets, preds)</span><br></pre></td></tr></table></figure><h3 id="2-对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励"><a href="#2-对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励" class="headerlink" title="2.对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励"></a>2.对于r-sm而言，目的是为了保证序列预测的平滑性，对于长期稳定的预测做出奖励</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 平滑度分量 r_sm</span></span><br><span class="line">r_sm = np.mean(preds[<span class="number">1</span>:] != preds[:-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="3-对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励"><a href="#3-对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励" class="headerlink" title="3.对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励"></a>3.对于r-trans而言，目的是奖励符合真实转移概率的预测，对正常状态转移进行奖励</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># idx: 验证集真实标签序列的类别索引</span></span><br><span class="line">idx = vr_l.argmax(axis=<span class="number">1</span>)           <span class="comment"># e.g. shape (N,), 值在 [0, C-1]</span></span><br><span class="line"><span class="comment"># C: 类别数</span></span><br><span class="line">C = <span class="built_in">int</span>(idx.<span class="built_in">max</span>()) + <span class="number">1</span>              <span class="comment"># 类别编号从 0 开始</span></span><br><span class="line"><span class="comment"># 初始化转移计数矩阵</span></span><br><span class="line">P = np.zeros((C, C), dtype=<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 统计相邻标签的转移次数</span></span><br><span class="line"><span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(idx[:-<span class="number">1</span>], idx[<span class="number">1</span>:]):</span><br><span class="line">    P[a, b] += <span class="number">1</span></span><br><span class="line"><span class="comment"># 加入微小平滑因子，转换为概率</span></span><br><span class="line">P = (P + <span class="number">1e-6</span>) / (P.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) + <span class="number">1e-6</span>)</span><br><span class="line"><span class="comment"># 利用上面构建的转移矩阵 P, 从中提取对应的转移概率</span></span><br><span class="line">logs = np.log([P[preds[j-<span class="number">1</span>], preds[j]] + <span class="number">1e-8</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(preds))])</span><br><span class="line">r_trans = np.mean(logs) + <span class="number">1.0</span></span><br></pre></td></tr></table></figure><h3 id="4-对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中"><a href="#4-对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中" class="headerlink" title="4.对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中"></a>4.对于r-time而言，目的是为了使其在时间阶段上匹配真实分布，每段睡眠阶段应该出现在合理的时间段中</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class_time = &#123;</span><br><span class="line">    <span class="number">0</span>: (<span class="number">0.0</span>, <span class="number">0.2</span>), <span class="number">1</span>: (<span class="number">0.2</span>, <span class="number">0.4</span>), <span class="number">2</span>: (<span class="number">0.4</span>, <span class="number">0.6</span>),</span><br><span class="line">    <span class="number">3</span>: (<span class="number">0.6</span>, <span class="number">0.8</span>), <span class="number">4</span>: (<span class="number">0.8</span>, <span class="number">1.0</span>)</span><br><span class="line">&#125;</span><br><span class="line">norm_t = np.arange(<span class="built_in">len</span>(preds)) / <span class="built_in">len</span>(preds)</span><br><span class="line">r_time = np.mean([</span><br><span class="line">    class_time[p][<span class="number">0</span>] &lt;= t &lt;= class_time[p][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> p, t <span class="keyword">in</span> <span class="built_in">zip</span>(preds, norm_t)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h3 id="其中各权重："><a href="#其中各权重：" class="headerlink" title="其中各权重："></a>其中各权重：</h3><pre><code>α（准确率权重）： 1.0β（平滑性）：    0.1γ（转移一致性）： 1.0δ（时间匹配）：   0.1</code></pre><h3 id="主要训练模块如下："><a href="#主要训练模块如下：" class="headerlink" title="主要训练模块如下："></a>主要训练模块如下：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于策略的梯度更新</span></span><br><span class="line">model.train()</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="keyword">for</span> feat_b, stft_b, label_b <span class="keyword">in</span> tr_loader:</span><br><span class="line">    feat_b = feat_b.to(device)</span><br><span class="line">    stft_b = stft_b.to(device)</span><br><span class="line">    logits = model(feat_b, stft_b)</span><br><span class="line">    dist = Categorical(logits=logits)</span><br><span class="line">    a = dist.sample()</span><br><span class="line">    lp = dist.log_prob(a)</span><br><span class="line">    <span class="comment"># per-sample update accumulation</span></span><br><span class="line">    loss = - lp.mean() * reward  </span><br><span class="line">    loss.backward()  <span class="comment"># free graph after each backward</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><h3 id="在针对fold8的微调中，性能从原始的0-61提升至0-71，但除了这一数据以外其余数据几乎不提升性能"><a href="#在针对fold8的微调中，性能从原始的0-61提升至0-71，但除了这一数据以外其余数据几乎不提升性能" class="headerlink" title="在针对fold8的微调中，性能从原始的0.61提升至0.71，但除了这一数据以外其余数据几乎不提升性能"></a>在针对fold8的微调中，性能从原始的0.61提升至0.71，但除了这一数据以外其余数据几乎不提升性能</h3><p><img src="/img/val_acc.png" alt="image.png"></p><h3 id="如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下"><a href="#如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下" class="headerlink" title="如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下"></a>如果将epochs调至50或更多时，几乎所有fold都出现先上升后下降，然后进入平台期的状态，或者直接下降进入平台期间，如下</h3><p><img src="/img/combined_acc.png" alt="image.png"></p><h2 id="推断情况可能如下："><a href="#推断情况可能如下：" class="headerlink" title="推断情况可能如下："></a>推断情况可能如下：</h2><h3 id="1-模型后期处于过拟合状态，无法泛化到测试集中"><a href="#1-模型后期处于过拟合状态，无法泛化到测试集中" class="headerlink" title="1.模型后期处于过拟合状态，无法泛化到测试集中"></a>1.模型后期处于过拟合状态，无法泛化到测试集中</h3><h3 id="2-参数组合还需要进一步调整"><a href="#2-参数组合还需要进一步调整" class="headerlink" title="2.参数组合还需要进一步调整"></a>2.参数组合还需要进一步调整</h3><h3 id="3-模型本身容量不够，需要增加模型的复杂度"><a href="#3-模型本身容量不够，需要增加模型的复杂度" class="headerlink" title="3.模型本身容量不够，需要增加模型的复杂度"></a>3.模型本身容量不够，需要增加模型的复杂度</h3><h3 id="4-奖励函数的机制还需要进一步设计"><a href="#4-奖励函数的机制还需要进一步设计" class="headerlink" title="4.奖励函数的机制还需要进一步设计"></a>4.奖励函数的机制还需要进一步设计</h3><h3 id="5-更换性能更好的算法，例如PPO"><a href="#5-更换性能更好的算法，例如PPO" class="headerlink" title="5.更换性能更好的算法，例如PPO"></a>5.更换性能更好的算法，例如PPO</h3><h2 id="下面是一些废案"><a href="#下面是一些废案" class="headerlink" title="下面是一些废案"></a>下面是一些废案</h2><h2 id="1-ActorCritic-算法部分"><a href="#1-ActorCritic-算法部分" class="headerlink" title="1. ActorCritic 算法部分"></a>1. ActorCritic 算法部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ActorCritic</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_model, hidden_dim, n_actions</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.base = base_model</span><br><span class="line">        feat_dim = <span class="number">5</span></span><br><span class="line">        <span class="comment"># Policy head</span></span><br><span class="line">        <span class="variable language_">self</span>.pi = nn.Sequential(</span><br><span class="line">            nn.Linear(feat_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, n_actions)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Value head</span></span><br><span class="line">        <span class="variable language_">self</span>.v = nn.Sequential(</span><br><span class="line">            nn.Linear(feat_dim, hidden_dim),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(hidden_dim, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, feat, stft</span>):</span><br><span class="line">        <span class="comment"># 从 base_model 获得特征 embedding</span></span><br><span class="line">        emb = <span class="variable language_">self</span>.base(feat, stft)</span><br><span class="line">        <span class="comment"># 返回策略 logits 和状态值（去掉最后一维）</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.pi(emb), <span class="variable language_">self</span>.v(emb).squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><p><strong>结构说明</strong>  </p><ul><li><strong>base_model</strong>：预训练的睡眠网络（MVFSleepNet），用于提取状态表示。  </li><li><strong>策略网络（π）</strong>：输入维度 <code>feat_dim=5</code>，隐藏层维度 <code>hidden_dim</code>，输出维度等于动作数 <code>n_actions</code>，输出为 logits。  </li><li><strong>价值网络（V）</strong>：同样输入 <code>feat_dim</code>，隐藏维度 <code>hidden_dim</code>，输出为标量状态价值。  </li></ul></li><li><p><strong>前向过程</strong>  </p><ol><li>将原始特征 <code>feat</code> 与 STFT 特征 <code>stft</code> 输入 <code>base_model</code>，得到 embedding 向量 <code>emb</code>。  </li><li><code>pi(emb)</code> 生成每个动作的 logits，用于构造离散分布。  </li><li><code>v(emb)</code> 生成对应的状态价值，并用 <code>squeeze(-1)</code> 去除多余维度。</li></ol></li></ul><h2 id="2-collect-rollout-函数"><a href="#2-collect-rollout-函数" class="headerlink" title="2. collect_rollout 函数"></a>2. collect_rollout 函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">collect_rollout</span>(<span class="params">ac_model, data_loader, P, device</span>):</span><br><span class="line">    ac_model.<span class="built_in">eval</span>()</span><br><span class="line">    states, actions, logps, values = [], [], [], []</span><br><span class="line">    rewards, dones = [], []</span><br><span class="line">    prev_act = <span class="literal">None</span></span><br><span class="line">    correct, total = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> feat_b, stft_b, label_b <span class="keyword">in</span> data_loader:</span><br><span class="line">            feat_b = feat_b.to(device)</span><br><span class="line">            stft_b = stft_b.to(device)</span><br><span class="line">            labels = label_b.argmax(dim=<span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向并采样动作</span></span><br><span class="line">            logits, value = ac_model(feat_b, stft_b)</span><br><span class="line">            dist = Categorical(logits=logits)</span><br><span class="line">            a = dist.sample()</span><br><span class="line">            lp = dist.log_prob(a)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 统计训练集预测准确率</span></span><br><span class="line">            correct += (a == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">            total += a.numel()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存状态、动作、LogProb、价值</span></span><br><span class="line">            states.append((feat_b, stft_b))</span><br><span class="line">            actions.append(a)</span><br><span class="line">            logps.append(lp)</span><br><span class="line">            values.append(value)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 逐样本计算奖励</span></span><br><span class="line">            y_true = labels.cpu().numpy()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(a.size(<span class="number">0</span>)):</span><br><span class="line">                r = compute_reward(a[i].item(), y_true[i], prev_act, P)</span><br><span class="line">                rewards.append(r)</span><br><span class="line">                dones.append(<span class="number">0</span>)</span><br><span class="line">                prev_act = a[i].item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接成张量</span></span><br><span class="line">    actions = torch.cat(actions).to(device)</span><br><span class="line">    logps   = torch.cat(logps).to(device)</span><br><span class="line">    values  = torch.cat(values).to(device)</span><br><span class="line">    rewards = torch.tensor(rewards, dtype=torch.float32, device=device)</span><br><span class="line">    dones   = torch.tensor(dones, dtype=torch.float32, device=device)</span><br><span class="line"></span><br><span class="line">    train_acc = correct / total</span><br><span class="line">    <span class="keyword">return</span> states, actions, logps, values, rewards, dones, train_acc</span><br></pre></td></tr></table></figure><ul><li><strong>主要功能</strong>  <ul><li>在环境（这里用的是静态数据集）中执行一次 rollout，采样一系列 <code>(状态, 动作)</code>，并计算相应的即时奖励。  </li><li><strong>输入</strong>  <ul><li><code>ac_model</code>：ActorCritic 模型  </li><li><code>data_loader</code>：训练数据迭代器（batch_size=1，逐样本执行）  </li><li><code>P</code>：状态转移概率矩阵，用于转移奖励计算  </li></ul></li><li><strong>输出</strong>  <ul><li><code>states</code>：每一步的 <code>(feat, stft)</code> 张量对列表  </li><li><code>actions</code>：动作序列张量  </li><li><code>logps</code>：对应的动作 log-probabilities  </li><li><code>values</code>：Critic 网络给出的状态价值  </li><li><code>rewards</code>：即时奖励序列  </li><li><code>dones</code>：终止标志序列（此处始终为 0）  </li><li><code>train_acc</code>：Rollout 期间的分类准确率  </li></ul></li></ul></li></ul><h2 id="3-PPO-更新（ppo-update-函数）"><a href="#3-PPO-更新（ppo-update-函数）" class="headerlink" title="3. PPO 更新（ppo_update 函数）"></a>3. PPO 更新（ppo_update 函数）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ppo_update</span>(<span class="params">ac_model, opt_groups, rollout_data,</span></span><br><span class="line"><span class="params">               device, ppo_epochs, mb_size</span>):</span><br><span class="line">    ac_model.train()</span><br><span class="line">    states, actions, old_logps, values, rewards, dones = rollout_data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 计算 Returns 和 GAE 优势</span></span><br><span class="line">    returns, advs = [], []</span><br><span class="line">    gae = <span class="number">0</span></span><br><span class="line">    next_value = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(rewards))):</span><br><span class="line">        delta = rewards[t] + gamma * next_value * (<span class="number">1</span>-dones[t]) - values[t]</span><br><span class="line">        gae = delta + gamma * gae_lambda * (<span class="number">1</span>-dones[t]) * gae</span><br><span class="line">        advs.insert(<span class="number">0</span>, gae)</span><br><span class="line">        next_value = values[t]</span><br><span class="line">        returns.insert(<span class="number">0</span>, gae + values[t])</span><br><span class="line">    returns = torch.stack(returns).to(device)</span><br><span class="line">    advs    = torch.stack(advs).to(device)</span><br><span class="line">    advs    = (advs - advs.mean()) / (advs.std() + <span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 多轮小批量更新</span></span><br><span class="line">    total_pi_loss = total_v_loss = total_ent = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(ppo_epochs):</span><br><span class="line">        idxs = torch.randperm(<span class="built_in">len</span>(rewards), device=device)</span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(idxs), mb_size):</span><br><span class="line">            mb = idxs[start:start+mb_size]</span><br><span class="line">            <span class="comment"># 准备小批量数据</span></span><br><span class="line">            feat_mb = torch.cat([states[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> mb], <span class="number">0</span>)</span><br><span class="line">            stft_mb = torch.cat([states[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> mb], <span class="number">0</span>)</span><br><span class="line">            a_mb     = actions[mb]</span><br><span class="line">            old_lp_mb= old_logps[mb]</span><br><span class="line">            R_mb     = returns[mb]</span><br><span class="line">            A_mb     = advs[mb]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向计算新策略</span></span><br><span class="line">            logits, V_mb = ac_model(feat_mb, stft_mb)</span><br><span class="line">            dist = Categorical(logits=logits)</span><br><span class="line">            lp_new = dist.log_prob(a_mb)</span><br><span class="line">            ratio = torch.exp(lp_new - old_lp_mb)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># PPO Clip-Objective</span></span><br><span class="line">            surr1 = ratio * A_mb</span><br><span class="line">            surr2 = torch.clamp(ratio, <span class="number">1</span>-clip_eps, <span class="number">1</span>+clip_eps) * A_mb</span><br><span class="line">            loss_pi = -torch.<span class="built_in">min</span>(surr1, surr2).mean() \</span><br><span class="line">                      - entropy_coef * dist.entropy().mean()</span><br><span class="line">            <span class="comment"># Value loss (MSE)</span></span><br><span class="line">            loss_v = nn.MSELoss()(V_mb, R_mb)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            <span class="keyword">for</span> opt <span class="keyword">in</span> opt_groups: opt.zero_grad()</span><br><span class="line">            (loss_pi + loss_v).backward()</span><br><span class="line">            <span class="keyword">for</span> opt <span class="keyword">in</span> opt_groups: opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累积统计</span></span><br><span class="line">            total_pi_loss += loss_pi.item()</span><br><span class="line">            total_v_loss  += loss_v.item()</span><br><span class="line">            total_ent     += dist.entropy().mean().item()</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平均损失与熵</span></span><br><span class="line">    <span class="keyword">return</span> total_pi_loss/count, total_v_loss/count, total_ent/count</span><br></pre></td></tr></table></figure><ol><li><p><strong>计算 Returns 与 GAE 优势</strong>  </p><ul><li>采用通用优势估计（GAE）公式：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>δ</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>r</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>A</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>δ</mi><mi>t</mi></msub><mo>+</mo><mi>γ</mi><mtext> </mtext><mi>λ</mi><mtext> </mtext><msub><mi>A</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}\delta_t &amp;= r_t + \gamma\,V(s_{t+1}) - V(s_t),\\A_t      &amp;= \delta_t + \gamma\,\lambda\,A_{t+1}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0379em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span></span></span></span></span></span>  </li><li>并同时构造蒙特卡洛 Return：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>R</mi><mi>t</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>A</mi><mi>t</mi></msub><mo>+</mo><mi>V</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}R_t &amp;= A_t + V(s_t)\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5em;vertical-align:-0.5em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em;"><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em;"><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span></span></span></span></span></span>  </li><li>最终对 advantages 进行归一化（零均值和单位方差）。</li></ul></li><li><p><strong>PPO Clip 目标</strong>  </p><ul><li>计算策略比率：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi mathvariant="normal">o</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">d</mi></mrow></msub></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo></mrow><annotation encoding="application/x-tex">r_t(\theta) = \exp\bigl(\log\pi_\theta(a_t\mid s_t) - \log\pi_{\theta_{\mathrm{old}}}(a_t\mid s_t)\bigr)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mop">exp</span><span class="mopen"><span class="delimsizing size1">(</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0059em;vertical-align:-0.2559em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">old</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="delimsizing size1">)</span></span></span></span></span>  </li><li>采用 clipped surrogate objective：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">P</mi></mrow></msup><mo>=</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><mi>min</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><msub><mi>r</mi><mi>t</mi></msub><mtext> </mtext><msub><mi>A</mi><mi>t</mi></msub><mo separator="true">,</mo><mtext>  </mtext><mrow><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">p</mi></mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo separator="true">,</mo><mn>1</mn><mo>−</mo><mi>ϵ</mi><mo separator="true">,</mo><mn>1</mn><mo>+</mo><mi>ϵ</mi><mo stretchy="false">)</mo><mtext> </mtext><msub><mi>A</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo></mrow><annotation encoding="application/x-tex">L^{\mathrm{CLIP}} = -\mathbb{E}_t\Bigl[\min\bigl(r_t\,A_t,\;\mathrm{clip}(r_t,1-\epsilon,1+\epsilon)\,A_t\bigr)\Bigr]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">CLIP</span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen"><span class="delimsizing size2">[</span></span><span class="mop">min</span><span class="mopen"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathrm">clip</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϵ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord mathnormal">ϵ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing size1">)</span></span><span class="mclose"><span class="delimsizing size2">]</span></span></span></span></span>  </li><li>加上熵正则化以鼓励探索：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>β</mi><mtext> </mtext><mi>H</mi><mo stretchy="false">[</mo><mi>π</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">-\beta\,H[\pi]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mclose">]</span></span></span></span></li></ul></li><li><p><strong>价值函数更新</strong>  </p><ul><li>简单的均方误差损失：  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mi>V</mi></msup><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>t</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi>R</mi><mi>t</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">]</mo></mrow><annotation encoding="application/x-tex">L^V = \mathbb{E}_t\bigl[(V_\theta(s_t) - R_t)^2\bigr]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing size1">]</span></span></span></span></span></li></ul></li><li><p><strong>多轮与小批量</strong>  </p><ul><li>在同一次 rollout 数据上重复多轮 (<code>ppo_epochs</code>) 更新。  </li><li>每轮将数据打乱并拆分为多个小批量 (<code>mb_size</code>)。</li></ul></li></ol><p>但存在的问题是，模型基本上是不收敛的，acc会急剧下降到一个特别低的水平。</p><h2 id="改进方向"><a href="#改进方向" class="headerlink" title="改进方向"></a>改进方向</h2><h3 id="1-对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移"><a href="#1-对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移" class="headerlink" title="1. 对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移"></a>1. 对转移矩阵下手，重新设计转移矩阵，考虑重新设计更复杂，更贴近真实的转移矩阵，或者干脆设计一个新的模型，学习过程中怎么贴近真实的转移</h3><h3 id="2-模型架构本身复杂度不够，无法学习到所有的特征"><a href="#2-模型架构本身复杂度不够，无法学习到所有的特征" class="headerlink" title="2. 模型架构本身复杂度不够，无法学习到所有的特征"></a>2. 模型架构本身复杂度不够，无法学习到所有的特征</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器登陆指南</title>
      <link href="/2025/03/21/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%99%BB%E9%99%86%E6%8C%87%E5%8D%97/"/>
      <url>/2025/03/21/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%99%BB%E9%99%86%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>在使用ssh登陆服务器的过程中，有一些特殊的场景，比如说使用vscode远程连接主机，每次都需要手动输入密码，非常繁琐，以及有的服务器上并没有“魔法”条件，这个时候就需要一些特殊的手段，本篇主要记录一些解决方案。</p><h2 id="1-SSH免密登录配置"><a href="#1-SSH免密登录配置" class="headerlink" title="1. SSH免密登录配置"></a>1. SSH免密登录配置</h2><h3 id="1-1-生成SSH密钥对"><a href="#1-1-生成SSH密钥对" class="headerlink" title="1.1 生成SSH密钥对"></a>1.1 生成SSH密钥对</h3><p>首先在本地机器上生成SSH密钥对：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C <span class="string">&quot;your_email@example.com&quot;</span></span><br></pre></td></tr></table></figure><p>按提示操作，可以直接回车使用默认路径 <code>~/.ssh/id_rsa</code> ，也可以设置密码短语（推荐）。</p><h4 id="1-2-将公钥复制到服务器"><a href="#1-2-将公钥复制到服务器" class="headerlink" title="1.2 将公钥复制到服务器"></a>1.2 将公钥复制到服务器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id username@server_ip</span><br></pre></td></tr></table></figure><h3 id="1-3-配置SSH客户端"><a href="#1-3-配置SSH客户端" class="headerlink" title="1.3 配置SSH客户端"></a>1.3 配置SSH客户端</h3><p>编辑本地 <code>~/.ssh/config 文件</code>，添加服务器配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Host myserver</span><br><span class="line">    HostName server_ip_or_domain</span><br><span class="line">    User username</span><br><span class="line">    Port 22</span><br><span class="line">    IdentityFile ~/.ssh/id_rsa</span><br><span class="line">    ServerAliveInterval 60</span><br><span class="line">    ServerAliveCountMax 3</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> share </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基于4卡昇腾910B服务器部署DeepSeek的踩坑日记</title>
      <link href="/2025/02/25/DeepSeek%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
      <url>/2025/02/25/DeepSeek%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>最近终于在昇腾910B的服务器上跑通了DeepSeek的模型，期间踩了无数的坑，记录一下这些折磨人的经历。<br>选择的框架是llamafactory + torch_npu<br>首先，学校的服务器虽然查询 <code>npu-smi info</code> 显示为4卡910B，但实际上是910A。导致在安装cann的时候有一堆的问题。<br>接下来就是cann的版本区别，在8.0.RC3这个版本下，910A推理模型会缺失一些算子，但910B却不会，这一点坑了我好久。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">File &quot;/usr/local/Ascend/atb-models/atb_llm/utils/data/weight_wrapper.py&quot;, line 49, in __init__</span><br><span class="line">^^^^^^^    ^self.placeholder = torch.zeros(1, dtype=torch.float16, device=&quot;npu&quot;)^</span><br><span class="line">^^^^^^^^^ ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span><br><span class="line">^^RuntimeError^: ^call aclnnInplaceZero failed, detail:EZ9999: Inner Error!</span><br><span class="line">EZ9999: [PID: 3454] 2025-02-21-23:08:46.559.394 Parse dynamic kernel config fail.</span><br><span class="line">TraceBack (most recent call last):</span><br><span class="line">AclOpKernelInit failed opType</span><br><span class="line">ZerosLike ADD_TO_LAUNCHER_LIST_AICORE failed.</span><br><span class="line"></span><br><span class="line">[ERROR] 2025-02-21-23:08:46 (PID:3454, Device:2, RankID:2) ERR01100 OPS call acl api failed</span><br><span class="line"></span><br><span class="line">File &quot;/usr/local/Ascend/atb-models/atb_llm/utils/data/weight_wrapper.py&quot;, line 49, in __init__</span><br><span class="line">self.placeholder = torch.zeros(1, dtype=torch.float16, device=&quot;npu&quot;)</span><br><span class="line">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span><br><span class="line">RuntimeError: call aclnnInplaceZero failed, detail:EZ9999: Inner Error!</span><br></pre></td></tr></table></figure><br>后面尝试更新了最新的cann包8.0.0版本以及对应的910的kernels，这里打910B的kernels都不行。到这里不过至少没有算子的报错了，但变成了另外的报错：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Sync:torch_npu/csrc/framework/OpCommand.cpp:190 NPU error, error code is 507018</span><br><span class="line">[ERROR] 2025-02-25-21:55:56 (PID:72781, Device:0, RankID:-1) ERR00100 PTA call acl api failed</span><br><span class="line">[Error]: The aicpu execution is abnormal. </span><br><span class="line">        Rectify the fault based on the error information in the ascend log.</span><br><span class="line">E39999: Inner Error!</span><br><span class="line">E39999: [PID: 72781] 2025-02-25-21:55:56.347.048 An exception occurred during AICPU execution, stream_id:2, task_id:1918, errcode:21008, msg:inner error[FUNC:ProcessAicpuErrorInfo][FILE:device_error_proc.cc][LINE:832]</span><br><span class="line">        TraceBack (most recent call last):</span><br><span class="line">       rtStreamSynchronizeWithTimeout execute failed, reason=[aicpu exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]</span><br><span class="line">       synchronize stream failed, runtime result = 507018[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]</span><br></pre></td></tr></table></figure><br>这个问题弄的我很头疼，让我排查问题排查了很久，一度搁置了这个问题，直到我偶然在github的issue里面发现了相似的报错，最终导向了关闭do_sample这个选项，猜测应该也是某个算子缺了。<br>直到这里，才能正常的推理下去</p><p>现在即使是能正常推理，推理的效果也极其差劲，下面为同框架同模型在单卡3090ti与单卡910A上的对比</p><h3 id="如图为3090ti单卡"><a href="#如图为3090ti单卡" class="headerlink" title="如图为3090ti单卡"></a>如图为3090ti单卡</h3><p><img src="/img/3090ti_7B.png" alt="image.png"></p><h3 id="如图为910A单卡"><a href="#如图为910A单卡" class="headerlink" title="如图为910A单卡"></a>如图为910A单卡</h3><p><img src="/img/910_7B.png" alt="image.png"></p><p>并且在调取单卡占用率时，3090ti能几乎顶满100%的使用率，而910A仅能有最高30%左右的使用率，核心空置率非常的高</p><p>希望后期cann版本更新能优化一下吧，不过很可能910A被抛弃了</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> Ascend </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>鹰眼项目重构</title>
      <link href="/2025/02/19/EagleEyes/"/>
      <url>/2025/02/19/EagleEyes/</url>
      
        <content type="html"><![CDATA[<h1 id="羽毛球轨迹预测系统-Badminton-Trajectory-Prediction"><a href="#羽毛球轨迹预测系统-Badminton-Trajectory-Prediction" class="headerlink" title="羽毛球轨迹预测系统 (Badminton Trajectory Prediction)"></a>羽毛球轨迹预测系统 (Badminton Trajectory Prediction)</h1><p>基于YOLOv5目标检测与LSTM时序建模的羽毛球运动轨迹预测系统(重构版)</p><h2 id="🚀-功能特性"><a href="#🚀-功能特性" class="headerlink" title="🚀 功能特性"></a>🚀 功能特性</h2><ul><li><strong>高精度检测</strong>: 采用YOLOv5实时检测羽毛球位置</li><li><strong>轨迹建模</strong>: 使用深度LSTM网络学习运动模式</li><li><strong>可视化分析</strong>: 生成轨迹对比图与训练曲线</li><li><strong>多步预测</strong>: 支持任意长度的轨迹预测</li></ul><h2 id="📦-环境要求"><a href="#📦-环境要求" class="headerlink" title="📦 环境要求"></a>📦 环境要求</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ultralytics/yolov5</span><br><span class="line"><span class="built_in">cd</span> yolov5</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="🗂-项目结构"><a href="#🗂-项目结构" class="headerlink" title="🗂 项目结构"></a>🗂 项目结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">EagleEyes/</span><br><span class="line">├── input_videos/          # 原始视频存储目录</span><br><span class="line">├── trajectories/          # 提取的轨迹CSV文件</span><br><span class="line">├── saved_models/          # 训练好的模型参数</span><br><span class="line">├── prediction_results/    # 预测结果可视化</span><br><span class="line">├── extract.py             # 轨迹提取脚本</span><br><span class="line">├── train.py               # LSTM训练脚本</span><br><span class="line">└── predict.py             # 预测与可视化脚本</span><br></pre></td></tr></table></figure><h2 id="🛠-使用指南"><a href="#🛠-使用指南" class="headerlink" title="🛠 使用指南"></a>🛠 使用指南</h2><ol><li><p>轨迹提取</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python extract.py \</span><br><span class="line">    --video_dir input_videos \</span><br><span class="line">    --output_dir trajectories \</span><br><span class="line">    --visualize </span><br></pre></td></tr></table></figure></li><li><p>模型训练</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py \</span><br><span class="line">    --data_dir ./trajectories \</span><br><span class="line">    --save_dir ./saved_models \</span><br><span class="line">    --epochs 500 \</span><br><span class="line">    --batch_size 64</span><br></pre></td></tr></table></figure></li><li><p>轨迹预测</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python predict.py \</span><br><span class="line">    --model_path ./saved_models/model_epoch500.pt \</span><br><span class="line">    --trajectory_file ./trajectories/test1.csv \</span><br><span class="line">    --output_dir ./prediction_results</span><br></pre></td></tr></table></figure><h2 id="⚙-参数说明"><a href="#⚙-参数说明" class="headerlink" title="⚙ 参数说明"></a>⚙ 参数说明</h2><h3 id="训练参数-train-py"><a href="#训练参数-train-py" class="headerlink" title="训练参数 (train.py)"></a>训练参数 (train.py)</h3><p>| 参数名         | 默认值 | 说明               |<br>|————————|————|——————————|<br>| —seq_len      | 30     | 输入序列长度（帧数） |<br>| —pred_steps   | 10     | 预测步长            |<br>| —hidden_size  | 128    | LSTM隐藏层维度      |<br>| —num_layers   | 3      | LSTM堆叠层数        |</p><h3 id="预测参数-predict-py"><a href="#预测参数-predict-py" class="headerlink" title="预测参数 (predict.py)"></a>预测参数 (predict.py)</h3><p>| 参数名           | 默认值 | 说明               |<br>|—————————|————|——————————|<br>| —observed_ratio | 0.3    | 输入观测比例         |<br>| —predict_steps  | 10     | 预测帧数            |<br>| —line_width     | 2      | 可视化线条粗细      |</p><h2 id="📊-结果示例"><a href="#📊-结果示例" class="headerlink" title="📊 结果示例"></a>📊 结果示例</h2></li></ol><h3 id="轨迹对比图"><a href="#轨迹对比图" class="headerlink" title="轨迹对比图"></a>轨迹对比图</h3><p><img src="path_to_image" alt="prediction"></p><ul><li><strong>蓝色实线</strong>: 实际观测轨迹</li><li><strong>红色虚线</strong>: 模型预测轨迹<h3 id="训练曲线"><a href="#训练曲线" class="headerlink" title="训练曲线"></a>训练曲线</h3></li></ul><p><img src="path_to_image" alt="training_curves"></p><ul><li>左: 训练损失下降曲线</li><li>右: 测试集相对误差</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AtlasChatR1项目</title>
      <link href="/2025/02/02/AtlasChatR1/"/>
      <url>/2025/02/02/AtlasChatR1/</url>
      
        <content type="html"><![CDATA[<h1 id="DeepSeek-R1-1-5B-模型在昇腾-Atlas-200I-DK-A2-上的推理项目"><a href="#DeepSeek-R1-1-5B-模型在昇腾-Atlas-200I-DK-A2-上的推理项目" class="headerlink" title="DeepSeek R1 1.5B 模型在昇腾 Atlas 200I DK A2 上的推理项目"></a>DeepSeek R1 1.5B 模型在昇腾 Atlas 200I DK A2 上的推理项目</h1><p>项目基于 DeepSeek 最新的 R1 1.5B 模型，在昇腾 Atlas 200I DK A2 设备上进行推理，并使用 int8 量化,并将模型转换为 OM 模型以便在板上运行。以下是项目简介。</p><hr><h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>本项目旨在将 DeepSeek R1 1.5B 模型部署到昇腾 Atlas 200I DK A2 设备上，通过 int8 量化优化模型推理性能。项目包含以下主要功能：</p><ol><li><strong>模型导出</strong>：将 DeepSeek R1 1.5B 模型导出为 ONNX 格式。</li><li><strong>模型量化</strong>：将 ONNX 模型量化为 int8 格式。</li><li><strong>模型推理与测评</strong>：在 Atlas 200I DK A2 设备上运行推理，并测评模型的推理速度和显存占用。</li></ol><hr><h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><h2 id=""><a href="#" class="headerlink" title=""></a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DeepSeek-Atlas-Chat/</span><br><span class="line">├── export.py # 将 DeepSeek R1 模型导出为 ONNX 格式</span><br><span class="line">├── quant.py # 将 ONNX 模型量化为 int8 格式</span><br><span class="line">├── eval.py # 测评模型推理速度和显存占用</span><br><span class="line">├── onnx_model_output/ # 存放从原始 R1 模型导出的 ONNX 模型</span><br><span class="line">├── deepseek_quant8.onnx # 自动生成的 int8 量化后的 ONNX 模型</span><br><span class="line">└── README.md # 项目说明文档</span><br></pre></td></tr></table></figure></h2><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><ul><li><strong>硬件</strong>：昇腾 Atlas 200I DK A2，理论上也可以在其他310B设备运行</li><li><strong>软件</strong>：<ul><li>Python 3.9 或更高版本</li><li>ONNX 1.10.0 或更高版本</li><li>昇腾 CANN 工具包（推荐版本 8.0.0RC3）</li><li>PyTorch 2.0.0 及以上</li><li>ONNX Runtime（可选，用于本地测试）</li></ul></li></ul><hr><h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><h3 id="1-请先自行下载DeepSeek-R1-Distill-Qwen-1-5B模型"><a href="#1-请先自行下载DeepSeek-R1-Distill-Qwen-1-5B模型" class="headerlink" title="1. 请先自行下载DeepSeek-R1-Distill-Qwen-1.5B模型"></a>1. 请先自行下载DeepSeek-R1-Distill-Qwen-1.5B模型</h3><h3 id="2-导出-ONNX-模型"><a href="#2-导出-ONNX-模型" class="headerlink" title="2. 导出 ONNX 模型"></a>2. 导出 ONNX 模型</h3><p>运行 <code>export.py</code> 脚本，将 DeepSeek R1 1.5B 模型导出为 ONNX 格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python export.py -m /path/to/DeepSeek-R1-Distill-Qwen-1.5B</span><br></pre></td></tr></table></figure><p>若设备支持cuda或者mps，可在运行时加上<code>-d cuda</code>或者<code>-d mps</code></p><h3 id="3-量化-ONNX-模型为-int8-格式"><a href="#3-量化-ONNX-模型为-int8-格式" class="headerlink" title="3. 量化 ONNX 模型为 int8 格式"></a>3. 量化 ONNX 模型为 int8 格式</h3><p>运行 quant.py 脚本，将 ONNX 模型量化为 int8 格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python quant.py</span><br></pre></td></tr></table></figure><p>量化后的模型将保存为 <code>deepseek_quant8.onnx</code></p><h3 id="4-测评模型推理性能"><a href="#4-测评模型推理性能" class="headerlink" title="4. 测评模型推理性能"></a>4. 测评模型推理性能</h3><p>运行 eval.py 脚本，测评模型在 转换量化前后的推理速度：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python eval.py</span><br></pre></td></tr></table></figure><br>得到结果大致如下，设备性能不同可能得到不同的结果，结果符合从fp32到int8的性能提升<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">测试 PyTorch 模型...</span><br><span class="line">PyTorch 模型平均推理时间: 0.2651 秒</span><br><span class="line">PyTorch 模型每秒处理 token 数量: 37.72 tokens/s</span><br><span class="line"></span><br><span class="line">测试 ONNX 模型...</span><br><span class="line">ONNX 模型平均推理时间: 0.0611 秒</span><br><span class="line">ONNX 模型每秒处理 token 数量: 163.77 tokens/s</span><br><span class="line"></span><br><span class="line">ONNX 模型相较于 PyTorch 模型推理速度提升: 4.34 倍</span><br></pre></td></tr></table></figure></p><h3 id="5-部署算子"><a href="#5-部署算子" class="headerlink" title="5. 部署算子"></a>5. 部署算子</h3><p>因为<code>cann</code>的算子清单中没有<code>MatMulIntegar</code>,<code>DynamicQuantizeLinear</code>,<code>DequantizeLinear</code>算子，所以就需要自己将算子补上，否则atc工具无法转换成om模型，后续的推理也无法正常运行<br>首先安装<code>protoc</code>，这是算子部署build.sh需要的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装protoc==1.13.0, 找一空闲目录下载</span></span><br><span class="line">wget  https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/wanzutao/tiny-llama/protobuf-all-3.13.0.tar.gz</span><br><span class="line">tar -zxvf protobuf-all-3.13.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> protobuf-3.13.0</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install autoconf automake libtool</span><br><span class="line">./autogen.sh</span><br><span class="line">./configure</span><br><span class="line">make -j4</span><br><span class="line">make install</span><br><span class="line"><span class="built_in">sudo</span> ldconfig</span><br><span class="line">protoc --version <span class="comment"># 查看版本号</span></span><br></pre></td></tr></table></figure></p><p>随后部署算子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> matmul_integer_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cp</span> dynamic_quantize_linear_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cp</span> dequantize_linear_plugin.cc /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx/framework/onnx_plugin/</span><br><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/ascend-toolkit/latest/tools/msopgen/template/custom_operator_sample/DSL/Onnx </span><br></pre></td></tr></table></figure><br>打开<code>build.sh</code>，添加如下四个环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> ASCEND_TENSOR_COMPILER_INCLUDE=/usr/local/Ascend/ascend-toolkit/latest/include</span><br><span class="line"><span class="built_in">export</span> TOOLCHAIN_DIR=/usr</span><br><span class="line"><span class="built_in">export</span> AICPU_KERNEL_TARGET=cust_aicpu_kernels</span><br><span class="line"><span class="built_in">export</span> AICPU_SOC_VERSION=Ascend310B4</span><br></pre></td></tr></table></figure><br>编译部署算子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./build.sh </span><br><span class="line"><span class="built_in">cd</span> build_out/</span><br><span class="line">./custom_opp_ubuntu_aarch64.run</span><br></pre></td></tr></table></figure></p><h3 id="6-转换-ONNX-模型为-OM-模型"><a href="#6-转换-ONNX-模型为-OM-模型" class="headerlink" title="6. 转换 ONNX 模型为 OM 模型"></a>6. 转换 ONNX 模型为 OM 模型</h3><p>使用昇腾 ATC 工具将量化后的 ONNX 模型转换为 OM 模型：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">atc --model=/root/AtlasChatR1/modified_model.onnx \</span><br><span class="line">    --framework=5 \</span><br><span class="line">    --output=deepseek_om_model \</span><br><span class="line">    --input_format=ND \</span><br><span class="line">    --input_shape=<span class="string">&quot;input_ids:-1,-1;attention_mask:-1,-1&quot;</span> \</span><br><span class="line">    --dynamic_dims=<span class="string">&quot;1,64,1,64;8,128,8,128;16,256,16,256&quot;</span> \</span><br><span class="line">    --soc_version=Ascend310B4 \</span><br><span class="line">    --precision_mode=allow_fp32_to_fp16</span><br></pre></td></tr></table></figure><br>这一步的时间会很长，耐心等待</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
          <category> Ascend </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AI-Mario项目</title>
      <link href="/2024/12/23/AI-Mario/"/>
      <url>/2024/12/23/AI-Mario/</url>
      
        <content type="html"><![CDATA[<h1 id="超级马里奥-DQN-智能体"><a href="#超级马里奥-DQN-智能体" class="headerlink" title="超级马里奥 DQN 智能体"></a>超级马里奥 DQN 智能体</h1><p>该项目实现了一个使用 <strong>DQN</strong> 的智能体来玩 <strong>超级马里奥</strong>。智能体通过强化学习来最大化奖励，并学习在环境中采取最优动作。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><strong>Gym Super Mario Bros 环境</strong>：使用 gym-super-mario-bros 库创建马里奥环境。</li><li><strong>DQN</strong>：使用 PyTorch 实现 DQN 训练智能体。</li><li><strong>经验回放缓冲区</strong>：存储和采样游戏状态以稳定训练过程。</li><li><strong>目标网络（Target Network）</strong>：使用单独的目标网络来提高训练的稳定性。</li><li><strong>Epsilon-贪婪策略</strong>：在训练过程中平衡探索与利用。<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2></li></ul><ol><li>克隆本仓库：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/xxxkkw/AI-Mario.git</span><br></pre></td></tr></table></figure></li><li>安装所需的依赖：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>注：这里一定严格按照环境内的版本，要不然有bug<h3 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h3></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">├── models/                 <span class="comment"># 保存的模型将存储在这里</span></span><br><span class="line">├── train.py                <span class="comment"># 主要训练脚本</span></span><br><span class="line">├── agent.py                <span class="comment"># DQN 智能体实现</span></span><br><span class="line">├── run.py                  <span class="comment"># 测试游戏</span></span><br><span class="line">├── replay_buffer.py        <span class="comment"># 经验回放缓冲区</span></span><br><span class="line">├── config.py               <span class="comment"># 超参数配置文件</span></span><br><span class="line">├── init_env.py             <span class="comment"># 马里奥环境设置和包装</span></span><br><span class="line">├── requirements.txt        <span class="comment"># Python 依赖库</span></span><br><span class="line">├── final_model1-1.dat      <span class="comment"># 模型文件</span></span><br><span class="line">├── final_model1-2.dat      <span class="comment"># 模型文件</span></span><br><span class="line">└── README.md               <span class="comment"># 项目文档</span></span><br></pre></td></tr></table></figure><ol><li>使用前必读：<br>项目内置已经训练好的一个模型，可以使用<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run.py</span><br></pre></td></tr></table></figure>来尝试玩一下已经训练好的模型。如果你想自己从头开始训练模型，只需要<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py</span><br></pre></td></tr></table></figure>这样就能从头开始训练属于你的模型了.想玩别的关卡或者训练别的关卡，只需在命令行中输入时添加—level参数即可<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --level 1-1</span><br></pre></td></tr></table></figure>或者已经把某个模型训练到了一半，想继续训练，只需<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --model path_to_your_model</span><br></pre></td></tr></table></figure>此外，项目内置两个关卡的模型，1-1以及1-2，可以体验一下<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run.py --level 1-2</span><br></pre></td></tr></table></figure>玩的开心！</li></ol>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，CRC代码</title>
      <link href="/2024/11/28/CRC/"/>
      <url>/2024/11/28/CRC/</url>
      
        <content type="html"><![CDATA[<p>代码实现了CRC（循环冗余校验）编码和解码的过程，应用于RFID实验中。在通信系统中，CRC是一种常用的错误检测技术，能够帮助检测传输数据中的误码。代码首先定义了消息比特和生成多项式，然后进行多项式除法来计算CRC校验码，并将其附加到原始消息比特中，生成编码后的帧。随后通过模拟接收到的码字进行CRC解码，检测接收数据是否存在误码。最后，代码通过图形化展示了编码前后的消息比特序列，以及是否存在错误的检测结果。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">clear all</span><br><span class="line">L = <span class="number">16</span>;                       <span class="comment">%一帧中的消息比特个数</span></span><br><span class="line">poly = [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>];         <span class="comment">%%此参数代表CRC编码使用的生成多项式，这里是x^4 + x^2 + x + 1</span></span><br><span class="line">N1 = <span class="built_in">length</span>(poly)<span class="number">-1</span>;          <span class="comment">%%此参数代表生成多项式的次数，用于确定消息比特左移的位数</span></span><br><span class="line"><span class="comment">%msg = randi([0 1], 1, L);      %消息比特（这里使用了自定义的消息比特序列代替随机生成）</span></span><br><span class="line">msg = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>];</span><br><span class="line">msg1 = [msg <span class="built_in">zeros</span>(<span class="number">1</span>,N1)];     <span class="comment">%消息比特左移，为后续的除法运算做准备，左移的位数等于生成多项式的次数</span></span><br><span class="line">[q,r]=deconv(msg1,poly);    <span class="comment">%%此过程是进行多项式除法，msg1为被除数（左移后的消息比特序列），poly为除数（生成多项式），q为商，r为余数</span></span><br><span class="line">r = <span class="built_in">mod</span>(<span class="built_in">abs</span>(r),<span class="number">2</span>);            <span class="comment">%%此过程是对余数进行模2运算，确保结果为0或1，符合CRC编码在GF(2)上的运算规则</span></span><br><span class="line">crc = r(L + <span class="number">1</span>:<span class="keyword">end</span>);             <span class="comment">%%此参数代表提取出的CRC校验码，即余数的后N1位</span></span><br><span class="line">frame = [msg crc];            <span class="comment">%%此参数代表构建的编码后的帧，由原始消息比特和CRC校验码组成</span></span><br><span class="line"><span class="comment">% 假设接收到的码字是frame，进行CRC解码</span></span><br><span class="line">rec_frame = frame; </span><br><span class="line">[q1,r1]=deconv([rec_frame <span class="built_in">zeros</span>(<span class="number">1</span>,N1)],poly); </span><br><span class="line">r1 = <span class="built_in">mod</span>(<span class="built_in">abs</span>(r1),<span class="number">2</span>);</span><br><span class="line">msg</span><br><span class="line">frame</span><br><span class="line">r1</span><br><span class="line"><span class="comment">%画图显示</span></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">stem(msg)</span><br><span class="line">title(<span class="string">&#x27;编码器输入信号&#x27;</span>)</span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">stem(frame)</span><br><span class="line">title(<span class="string">&#x27;编码器输出信号&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span>(all(r1(:) == <span class="number">0</span>))     <span class="comment">%</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">&quot;接收码字没有错误！&quot;</span>)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">&quot;接收码字中有误码！&quot;</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，Parity代码</title>
      <link href="/2024/11/28/Parity/"/>
      <url>/2024/11/28/Parity/</url>
      
        <content type="html"><![CDATA[<p>代码实现了奇偶校验（Parity Check）在RFID实验中的应用，奇偶校验是一种简单但有效的错误检测方法，能够检测传输数据中的单个比特错误。</p><h2 id="代码主要功能"><a href="#代码主要功能" class="headerlink" title="代码主要功能"></a>代码主要功能</h2><ol><li><strong>输入矩阵大小</strong>：用户通过输入行数和列数，生成一个随机的二进制矩阵 <code>A</code>，代表待校验的数据。</li><li><strong>选择奇偶校验类型</strong>：用户可以选择奇校验或偶校验，程序根据选择为每一行数据生成相应的校验位，并将其附加到矩阵的最后一列。</li><li><strong>校验位计算</strong>：<ul><li><strong>偶校验</strong>：如果行中1的个数为奇数，添加校验位1，使得1的个数变为偶数；如果为偶数，则添加0。</li><li><strong>奇校验</strong>：如果行中1的个数为偶数，添加校验位1，使得1的个数变为奇数；如果为奇数，则添加0。</li></ul></li><li><strong>错误检测</strong>：代码通过手动引入错误，然后再次进行奇偶校验，逐行检查数据是否正确，输出检查结果。</li><li><strong>循环操作</strong>：用户可以多次选择不同的校验类型进行实验，直到选择结束校验（输入9）。</li></ol><p>该代码通过奇偶校验位的计算和检测，演示了如何在数据传输过程中发现错误，是RFID实验中基础的错误检测机制之一。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">clear all;<span class="comment">%清除工作空间的所有变量</span></span><br><span class="line">m = input(<span class="string">&#x27;请输入行:&#x27;</span>);<span class="comment">%input(&#x27; &#x27;);用于向计算机输入一个参数 </span></span><br><span class="line">n = input(<span class="string">&#x27;请输入列:&#x27;</span>);</span><br><span class="line">A = randi([<span class="number">0</span> <span class="number">1</span>],m,n)<span class="comment">%randint(m,n)产生的是一个m*n维的矩阵，矩阵的元素或者是0或者是1，是随机的并显示A</span></span><br><span class="line">B=A;<span class="comment">%A暂存在B，</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    A=B;<span class="comment">%避免循环中A中信码改变</span></span><br><span class="line">    sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">    l = input(<span class="string">&#x27;请选择奇偶校验(0:偶校验 1:奇校验 9:结束校验):&#x27;</span>);<span class="comment">%;不回显</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span> || l == <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:n            <span class="comment">%%计算矩阵A中每一行的元素之和，从第1列到第n列</span></span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);<span class="comment">%</span></span><br><span class="line">                x = sum(<span class="built_in">i</span>);<span class="comment">%</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> l == <span class="number">0</span>             <span class="comment">%%选择偶校验（l == 0）的情况下执行的操作</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span> <span class="comment">%</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">1</span>; <span class="comment">%</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">0</span>; <span class="comment">%</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> l == <span class="number">1</span>              <span class="comment">%%选择奇校验（l == 1）的情况下执行的操作</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span><span class="comment">%</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">0</span>;<span class="comment">%</span></span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    A(<span class="built_in">i</span>,n+<span class="number">1</span>) = <span class="number">1</span>;<span class="comment">%</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span>    </span><br><span class="line">     <span class="keyword">else</span> <span class="keyword">if</span> l == <span class="number">9</span></span><br><span class="line">            fprintf(<span class="string">&#x27;退出校验~\n&#x27;</span>);<span class="comment">%设置显示格式 </span></span><br><span class="line">            <span class="keyword">break</span>;<span class="comment">%跳出循环</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            fprintf(<span class="string">&#x27;非法输入！！\n&#x27;</span>);</span><br><span class="line">            <span class="keyword">continue</span>;<span class="comment">%结束本次循环</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    fprintf(<span class="string">&#x27;补校验位：&#x27;</span>)</span><br><span class="line">    A<span class="comment">%显示加入校验位后的矩阵</span></span><br><span class="line">    <span class="comment">%</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">0</span>    </span><br><span class="line">       A(<span class="number">1</span>,<span class="number">2</span>) = ~A(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">        sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m          <span class="comment">%%检查添加校验位后的矩阵数据的正确性，逐行检查</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:(n+<span class="number">1</span>)  <span class="comment">%</span></span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);</span><br><span class="line">                x = sum(<span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">0</span>  <span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据正确！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">else</span>   <span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据有错！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> l == <span class="number">1</span> <span class="comment">%</span></span><br><span class="line">      A(<span class="number">3</span>,<span class="number">1</span>)=~A(<span class="number">3</span>,<span class="number">1</span>);</span><br><span class="line">      A</span><br><span class="line">      sum = <span class="built_in">zeros</span>(<span class="number">1</span>,m);<span class="comment">%zeros(1,m)创建一个1行m列的零矩阵</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m    <span class="comment">%%检查添加校验位后的矩阵数据的正确性，逐行检查</span></span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:(n+<span class="number">1</span>)  </span><br><span class="line">                sum(<span class="built_in">i</span>) = sum(<span class="built_in">i</span>) + A(<span class="built_in">i</span>,<span class="built_in">j</span>);</span><br><span class="line">                x = sum(<span class="built_in">i</span>);</span><br><span class="line">           <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">rem</span>(x,<span class="number">2</span>) == <span class="number">1</span><span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据正确！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">else</span><span class="comment">%</span></span><br><span class="line">                fprintf(<span class="string">&#x27;第%d行数据有错！\n&#x27;</span>, <span class="built_in">i</span>);</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span>                  </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，LinearBlockCode代码</title>
      <link href="/2024/11/28/LinearBlockCode/"/>
      <url>/2024/11/28/LinearBlockCode/</url>
      
        <content type="html"><![CDATA[<p>代码实现了线性分组码（Linear Block Code, LBC）的编码和解码过程，用于RFID实验。线性分组码是一种常见的编码技术，能够帮助检测和纠正传输过程中的误码。</p><h2 id="代码主要流程"><a href="#代码主要流程" class="headerlink" title="代码主要流程"></a>代码主要流程</h2><ol><li><strong>生成矩阵 G</strong>：首先构建生成矩阵 <code>G</code>，用于将原始消息比特映射为编码后的码字。</li><li><strong>编码过程</strong>：定义消息比特矩阵 <code>A</code>，通过矩阵乘法将 <code>A</code> 和生成矩阵 <code>G</code> 相乘，得到编码后的码字 <code>C</code>。</li><li><strong>校验矩阵 H</strong>：通过辅助函数 <code>gen2par</code>，利用生成矩阵 <code>G</code> 生成校验矩阵 <code>H</code>，用于错误检测。</li><li><strong>译码过程</strong>：输入接收到的7位码字，通过与校验矩阵 <code>H</code> 计算综合矢量 <code>S</code>，定位出错误比特位置，并修正错误，输出正确的码字。</li></ol><p>代码不仅实现了编码和译码，还包括错误检测与纠错功能，是RFID通信实验的重要部分。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">gen2par_example</span><span class="params">()</span></span></span><br><span class="line">    clear all;</span><br><span class="line">    G1 = <span class="built_in">eye</span>(<span class="number">4</span>);</span><br><span class="line">    G2 = [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>;</span><br><span class="line">          <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>;</span><br><span class="line">          <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>;</span><br><span class="line">          <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>];</span><br><span class="line">    G = [G1,G2];</span><br><span class="line">    fprintf(<span class="string">&#x27;生成矩阵为：G= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(G);</span><br><span class="line">    A = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>;];</span><br><span class="line">    fprintf(<span class="string">&#x27;原码为：A= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(A);</span><br><span class="line">    C1 = A*G;</span><br><span class="line">    C = <span class="built_in">mod</span>(C1,<span class="number">2</span>);</span><br><span class="line">    fprintf(<span class="string">&#x27;输出的编码为：C= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(C);</span><br><span class="line">    H = gen2par(G);</span><br><span class="line">    fprintf(<span class="string">&#x27;校验矩阵为：H= \n&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(H);</span><br><span class="line">    <span class="comment">%%以下输入接收到的码字，译出原码</span></span><br><span class="line">    Rev = input(<span class="string">&#x27;请输入7位接收码字，用空格隔开：&#x27;</span>,<span class="string">&#x27;s&#x27;</span>);</span><br><span class="line">    Rev = str2num(Rev);</span><br><span class="line">    S1 = Rev*(H&#x27;);</span><br><span class="line">    S = <span class="built_in">mod</span>(S1,<span class="number">2</span>);</span><br><span class="line">    E = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">7</span>;</span><br><span class="line">        Hi = H(:,[<span class="built_in">i</span>]);</span><br><span class="line">        Sum = S+Hi&#x27;;</span><br><span class="line">        Sum = <span class="built_in">mod</span>(Sum,<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> (all(Sum(:)==<span class="number">0</span>));</span><br><span class="line">            fprintf(<span class="string">&#x27;接收码字中错误码位是第：&#x27;</span>);</span><br><span class="line">            <span class="built_in">disp</span>(<span class="built_in">i</span>);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            E(<span class="number">1</span>, <span class="built_in">i</span>)=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">end</span>;</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line">    Cr = <span class="built_in">mod</span>((Rev + E),<span class="number">2</span>);</span><br><span class="line">    fprintf(<span class="string">&#x27;正确接收码字：Cr=&#x27;</span>);</span><br><span class="line">    <span class="built_in">disp</span>(Cr);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">H</span> = <span class="title">gen2par</span><span class="params">(G)</span></span></span><br><span class="line">    [k,n]=<span class="built_in">size</span>(G);</span><br><span class="line">    P = G(:,k + <span class="number">1</span>:n);</span><br><span class="line">    I = <span class="built_in">eye</span>(n - k);</span><br><span class="line">    H = [P&#x27;,I];</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>最小生成树模板</title>
      <link href="/2024/11/22/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E6%A8%A1%E6%9D%BF/"/>
      <url>/2024/11/22/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<h1 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h1><h2 id="根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）"><a href="#根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）" class="headerlink" title="根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）"></a>根据输入创建无向网。分别用Prim算法和Kruskal算法构建最小生成树。（假设：输入数据的最小生成树唯一。）</h2><h2 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h2><pre><code>顶点数nn个顶点边数mm条边信息,格式为：顶点1 顶点2 权值Prim算法的起点v</code></pre><h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><pre><code>输出最小生成树的权值之和</code></pre><p>对两种算法，按树的生长顺序，输出边信息(Kruskal中边顶点按数组序号升序输出)</p><p>题目是标准的Kruskal和Prim的板子，直接往里套就行，关键的是Kruskal和Prim的逻辑。<br>先介绍Kruskal算法。</p><h2 id="kruskal-算法的基本步骤："><a href="#kruskal-算法的基本步骤：" class="headerlink" title="kruskal 算法的基本步骤："></a>kruskal 算法的基本步骤：</h2><h3 id="边的排序："><a href="#边的排序：" class="headerlink" title="边的排序："></a>边的排序：</h3><pre><code>将图中所有的边按权重从小到大排序。</code></pre><h3 id="初始化并查集："><a href="#初始化并查集：" class="headerlink" title="初始化并查集："></a>初始化并查集：</h3><pre><code>使用并查集数据结构来判断两个顶点是否属于同一集合（即是否在同一个连通分量中）。</code></pre><h3 id="逐条检查边："><a href="#逐条检查边：" class="headerlink" title="逐条检查边："></a>逐条检查边：</h3><pre><code>遍历排序后的边，检查该边连接的两个点是否属于不同的连通分量，如果是，则将这条边加入到最小生成树中，合并这两个点成一个连通分量，若这两个点在同一个连通分量中，则加入这条边会形成环，因此跳过这条边。</code></pre><h3 id="停止条件："><a href="#停止条件：" class="headerlink" title="停止条件："></a>停止条件：</h3><pre><code>当加入了 n-1 条边时，最小生成树已经构建完成，其中 n 是图中顶点的数量。</code></pre><h2 id="在代码中的实现是这样的"><a href="#在代码中的实现是这样的" class="headerlink" title="在代码中的实现是这样的"></a>在代码中的实现是这样的</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">int</span> n, m, f[<span class="number">1010</span>], cnt = <span class="number">0</span>, sum = <span class="number">0</span>, won = <span class="number">0</span>;</span><br><span class="line">string s[<span class="number">1010</span>], st;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">edge</span> &#123; <span class="comment">// 这里使用结构体存边，便于排序以及存储以及遍历</span></span><br><span class="line">    <span class="type">int</span> u, v, w;</span><br><span class="line">&#125; tree[<span class="number">2010</span>];</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">cmp</span><span class="params">(edge x, edge y)</span> </span>&#123;  <span class="comment">// 重载运算符，在后续的排序里面会用到</span></span><br><span class="line">    <span class="keyword">return</span> x.w &lt; y.w;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 并查集最核心的操作，查询父节点，也就是用于判断是否在同一联通分量里面</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;   <span class="comment">// 如果x不是自己的父节点</span></span><br><span class="line">    <span class="keyword">if</span> (x != f[x])  <span class="comment">// 递归找到x的根节点，并压缩路径</span></span><br><span class="line">        f[x] = <span class="built_in">find</span>(f[x]);  <span class="comment">// 返回x的根节点</span></span><br><span class="line">    <span class="keyword">return</span> f[x];</span><br><span class="line">&#125;</span><br><span class="line">map&lt;string,<span class="type">int</span>&gt; mp; <span class="comment">//映射节点字符串与编号</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">vis</span><span class="params">(n + <span class="number">1</span>, <span class="literal">false</span>)</span></span>; <span class="comment">// 访问标记数组，记录哪些节点已经加入MST</span></span><br><span class="line"><span class="comment">// Lambda表达式，用于定义优先队列的比较规则：比较边的权重，较小的权重具有较高优先级</span></span><br><span class="line"><span class="keyword">auto</span> edgeCmp = [](edge a, edge b) &#123; <span class="keyword">return</span> a.w &gt; b.w; &#125;;</span><br><span class="line"><span class="comment">// 优先队列，存储边，按权重从小到大排列</span></span><br><span class="line">priority_queue&lt;edge, vector&lt;edge&gt;, <span class="keyword">decltype</span>(edgeCmp)&gt; <span class="built_in">pq</span>(edgeCmp);</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">()</span></span>&#123;  <span class="comment">//建图过程</span></span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i ++)&#123;</span><br><span class="line">        cin &gt;&gt; s[i];</span><br><span class="line">        mp[s[i]] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    cin &gt;&gt; m;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= m;i ++)&#123;</span><br><span class="line">        string u,v;</span><br><span class="line">        <span class="type">int</span> w;</span><br><span class="line">        cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;</span><br><span class="line">        tree[i].u = mp[u];</span><br><span class="line">        tree[i].v = mp[v];</span><br><span class="line">        tree[i].w = w;</span><br><span class="line">     &#125;</span><br><span class="line">    cin &gt;&gt; st;</span><br><span class="line">    <span class="type">int</span> start = mp[st];</span><br><span class="line">    vis[start] = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;  <span class="comment">// 将所有与起点相连的边加入优先队列</span></span><br><span class="line">        <span class="keyword">if</span> (tree[i].u == start || tree[i].v == start) &#123;</span><br><span class="line">            pq.<span class="built_in">push</span>(tree[i]);  <span class="comment">// 将起点相连的所有边压入优先队列</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">kruskal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;kruskal:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;  <span class="comment">// 初始化并查集，f[i]表示第i个顶点的父节点</span></span><br><span class="line">        f[i] = i;  <span class="comment">// 每个节点的父节点初始化为自己</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">sort</span>(tree + <span class="number">1</span>, tree + m + <span class="number">1</span>, cmp);  <span class="comment">// 对所有的边按权重进行升序排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;  <span class="comment">// 遍历所有的边，选择不形成环的边加入MST</span></span><br><span class="line">        <span class="type">int</span> e1 = <span class="built_in">find</span>(tree[i].u), e2 = <span class="built_in">find</span>(tree[i].v);  <span class="comment">// 找到这条边的两个顶点的根</span></span><br><span class="line">        <span class="keyword">if</span> (e1 != e2) &#123;  <span class="comment">// 如果这两个顶点不在同一个连通分量中</span></span><br><span class="line">            f[e1] = e2;  <span class="comment">// 合并这两个集合</span></span><br><span class="line">            <span class="comment">// 输出这条边</span></span><br><span class="line">            string city1 = s[tree[i].u];</span><br><span class="line">            string city2 = s[tree[i].v];</span><br><span class="line">            <span class="keyword">if</span> (city1 &gt; city2) <span class="built_in">swap</span>(city1, city2);</span><br><span class="line">            cout &lt;&lt; city1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; city2 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; tree[i].w &lt;&lt; endl;</span><br><span class="line">            sum += tree[i].w;  <span class="comment">// 累加权重</span></span><br><span class="line">            cnt++;  <span class="comment">// 增加已加入的边数</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (cnt == n - <span class="number">1</span>) &#123;</span><br><span class="line">            won = <span class="number">1</span>;  <span class="comment">// 如果已加入 n-1 条边，则完成了MST</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Prim算法步骤"><a href="#Prim算法步骤" class="headerlink" title="Prim算法步骤"></a>Prim算法步骤</h2><h3 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h3><pre><code>vis：这是一个访问标记数组，用来标记哪些顶点已经被加入到MST。它的大小为 n+1，初始值全为 false。edgeCmp：这是一个比较函数，定义了优先队列的排序规则，优先选择权重较小的边。pq：这是一个优先队列，存储边的类型 edge。它按照 edge.w 从小到大排序。</code></pre><h3 id="选择起点："><a href="#选择起点：" class="headerlink" title="选择起点："></a>选择起点：</h3><pre><code>通过 find_idx(st) 找到用户输入的起点在 s[] 中的索引 start。标记起点为已访问：vis[start] = true。遍历所有边，将与起点相连的边压入优先队列 pq。</code></pre><h3 id="循环处理优先队列："><a href="#循环处理优先队列：" class="headerlink" title="循环处理优先队列："></a>循环处理优先队列：</h3><pre><code>从优先队列中不断取出当前权重最小的边 currentEdge。通过 currentEdge.u 和 currentEdge.v 获取这条边的两个顶点。如果 u 和 v 都已经被访问（即它们已经在MST中），则跳过这条边，因为加入这条边会形成环。如果其中一个顶点未被访问，则确定要加入MST的顶点（next），并将它标记为已访问。</code></pre><h3 id="输出："><a href="#输出：" class="headerlink" title="输出："></a>输出：</h3><pre><code>根据字典顺序输出加入MST的边的两个顶点和对应的权重。若 city1 的字典顺序比 city2 大，则交换两者，保证输出时小的顶点在前。</code></pre><h3 id="更新优先队列："><a href="#更新优先队列：" class="headerlink" title="更新优先队列："></a>更新优先队列：</h3><pre><code>遍历所有边，将与刚加入MST的顶点 next 相连且另一端未访问的边加入优先队列。</code></pre><h3 id="继续循环："><a href="#继续循环：" class="headerlink" title="继续循环："></a>继续循环：</h3><pre><code>不断重复从优先队列中取出最小边、加入MST、更新优先队列的过程，直到优先队列为空或者所有顶点都被访问。</code></pre><h2 id="代码实现如下"><a href="#代码实现如下" class="headerlink" title="代码实现如下"></a>代码实现如下</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">prim</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;prim:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">while</span> (!pq.<span class="built_in">empty</span>()) &#123; <span class="comment">// 开始处理优先队列中的边</span></span><br><span class="line">        <span class="comment">// 取出优先队列中权重最小的边</span></span><br><span class="line">        edge currentEdge = pq.<span class="built_in">top</span>();</span><br><span class="line">        pq.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="type">int</span> u = currentEdge.u;  <span class="comment">// 当前边的起点</span></span><br><span class="line">        <span class="type">int</span> v = currentEdge.v;  <span class="comment">// 当前边的终点</span></span><br><span class="line">        <span class="type">int</span> w = currentEdge.w;  <span class="comment">// 当前边的权重</span></span><br><span class="line">        <span class="comment">// 如果u和v都已经在MST中，跳过这条边，因为它会形成环</span></span><br><span class="line">        <span class="keyword">if</span> (vis[u] &amp;&amp; vis[v]) <span class="keyword">continue</span>;</span><br><span class="line">        <span class="comment">// 确定下一个要加入MST的顶点（u或v中尚未访问的那个）</span></span><br><span class="line">        <span class="type">int</span> next = vis[u] ? v : u;</span><br><span class="line">        <span class="comment">// 标记这个顶点为已访问</span></span><br><span class="line">        vis[next] = <span class="literal">true</span>;</span><br><span class="line">        string city1 = s[u];</span><br><span class="line">        string city2 = s[v];</span><br><span class="line">        cout &lt;&lt; city1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; city2 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; w &lt;&lt; endl;</span><br><span class="line">        sum += w; <span class="comment">// 将这条边的权重加到总权重上</span></span><br><span class="line">        <span class="comment">// 遍历所有边，将与新加入顶点相连且未访问过的顶点加入优先队列</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; i++) &#123;</span><br><span class="line">            <span class="comment">// 如果这条边连接的顶点之一是刚加入MST的顶点，且另一端尚未加入MST</span></span><br><span class="line">            <span class="keyword">if</span> ((tree[i].u == next &amp;&amp; !vis[tree[i].v]) ||</span><br><span class="line">                (tree[i].v == next &amp;&amp; !vis[tree[i].u])) &#123;</span><br><span class="line">                pq.<span class="built_in">push</span>(tree[i]);  <span class="comment">// 将这条边压入优先队列</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二叉树构建与遍历</title>
      <link href="/2024/10/21/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/"/>
      <url>/2024/10/21/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%81%8D%E5%8E%86/</url>
      
        <content type="html"><![CDATA[<p>给出一颗二叉树的逻辑结构，并且建立该二叉树的二叉链式存储结构，分别输出二叉树的先序，中序，后序遍历<br>构建的整体思路就是依靠递归，分别构建左右子树，不为空就继续往下构建子树，直到结束<br>遍历也是差不多的思路，从根节点开始，不为空就继续向下递归，前中后只是输出的顺序不一样，本质上来说遍历的时候经过都是一样的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//节点的基本组成，包含本节点数据，左右子树的指针</span></span><br><span class="line">    <span class="type">char</span> data;</span><br><span class="line">    Node *lch;</span><br><span class="line">    Node *rch;</span><br><span class="line">    Node *parent;</span><br><span class="line">    <span class="built_in">Node</span>(<span class="type">char</span> c) : <span class="built_in">data</span>(c), <span class="built_in">lch</span>(<span class="literal">NULL</span>), <span class="built_in">rch</span>(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TREE</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Node* root;</span><br><span class="line">    ll pos;</span><br><span class="line">    string tree_str;</span><br><span class="line">    <span class="built_in">TREE</span>() : <span class="built_in">root</span>(<span class="literal">NULL</span>), <span class="built_in">pos</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">create_tree</span><span class="params">(<span class="type">const</span> string&amp; s)</span> </span>&#123;</span><br><span class="line">        pos = <span class="number">0</span>;</span><br><span class="line">        tree_str = s;</span><br><span class="line">        root = <span class="built_in">create</span>(); <span class="comment">//这里就是从根节点开始往下</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Node* <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//递归构建子树</span></span><br><span class="line">        <span class="keyword">if</span>(pos &gt;= tree_str.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        <span class="type">char</span> c = tree_str[pos++];</span><br><span class="line">        <span class="keyword">if</span> (c == <span class="string">&#x27;#&#x27;</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        Node* node = <span class="keyword">new</span> <span class="built_in">Node</span>(c);</span><br><span class="line">        node-&gt;lch = <span class="built_in">create</span>();</span><br><span class="line">        node-&gt;rch = <span class="built_in">create</span>();</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">pre</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//先序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">        <span class="built_in">pre</span>(node-&gt;lch);</span><br><span class="line">        <span class="built_in">pre</span>(node-&gt;rch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">in</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//中序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="built_in">in</span>(node-&gt;lch);</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">        <span class="built_in">in</span>(node-&gt;rch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">post</span><span class="params">(Node* node)</span> </span>&#123; <span class="comment">//后序遍历</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="built_in">post</span>(node-&gt;lch);</span><br><span class="line">        <span class="built_in">post</span>(node-&gt;rch);</span><br><span class="line">        cout &lt;&lt; node-&gt;data;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">pre</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">        <span class="built_in">in</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">        <span class="built_in">post</span>(root);</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">leaves</span><span class="params">(Node* p)</span> </span>&#123;  <span class="comment">//这里顺便放上遍历叶子节点的函数</span></span><br><span class="line">        <span class="keyword">if</span> (p) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!p-&gt;lch &amp;&amp; !p-&gt;rch)</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">leaves</span>(p-&gt;lch);</span><br><span class="line">            <span class="built_in">leaves</span>(p-&gt;rch);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Parents</span><span class="params">(Node* p)</span> </span>&#123;  <span class="comment">//遍历父节点</span></span><br><span class="line">        <span class="keyword">if</span> (p) &#123;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;lch &amp;&amp; (!p-&gt;lch-&gt;lch &amp;&amp; !p-&gt;lch-&gt;rch))</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">Parents</span>(p-&gt;lch);</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;rch &amp;&amp; (!p-&gt;rch-&gt;lch &amp;&amp; !p-&gt;rch-&gt;rch))</span><br><span class="line">                cout &lt;&lt; p-&gt;data &lt;&lt; <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">            <span class="built_in">Parents</span>(p-&gt;rch);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    ll t;</span><br><span class="line">    cin &gt;&gt; t;</span><br><span class="line">    <span class="keyword">while</span> (t--) &#123;</span><br><span class="line">        string s;</span><br><span class="line">        cin &gt;&gt; s;</span><br><span class="line">        TREE tree;</span><br><span class="line">        tree.<span class="built_in">create_tree</span>(s);</span><br><span class="line">        tree.<span class="built_in">display</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AscendC算子中级认证--指导向</title>
      <link href="/2024/10/21/AscendC%E7%AE%97%E5%AD%90%E4%B8%AD%E7%BA%A7%E8%AE%A4%E8%AF%81--%E6%8C%87%E5%AF%BC%E5%90%91/"/>
      <url>/2024/10/21/AscendC%E7%AE%97%E5%AD%90%E4%B8%AD%E7%BA%A7%E8%AE%A4%E8%AF%81--%E6%8C%87%E5%AF%BC%E5%90%91/</url>
      
        <content type="html"><![CDATA[<p>AscendC算子中级认证的题目是模拟numpy中的sinh算子，编写基于AscendC的算子sinh，命名为sinhCustom，并编写kernel侧代码，host侧代码，使用aclnn算子调用测试<br>sinh的算法实现为： sinh(x) = (exp(x) - exp(-x)) / 2.0<br>首先在kernel侧，完成sinh_custom.cpp文件<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;                        <span class="comment">//开启双缓冲，实现流水并行</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSinh</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSinh</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123; <span class="comment">// 获取host侧传入的tiling参数，尽量避免在kernel侧计算</span></span><br><span class="line">        TilingData tiling_data;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">        totalLength = tiling_data.totalLength;          <span class="comment">// 总数据长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;            <span class="comment">// 单tile长度，也就是根据ub确定下来的每次能处理的最大长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;              <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;                  <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR z, GM_ADDR tiling, TPipe* pipeIn)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化全局内存，获取host侧传入的x和z的地址以及数据长度，单核场景下无需考虑地址偏移</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X *)x, <span class="keyword">this</span>-&gt;totalLength);     </span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Z *)z, <span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">        pipe = pipeIn;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化队列，队列大小对应的每次能计算的数据量，大小为：数据类型 * 每次能计算的数据量 * 队列大小</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));     </span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Z));</span><br><span class="line">        <span class="comment">// 初始化计算所需的临时内存，大小为：数据类型 * 每次能计算的数据量</span></span><br><span class="line">        <span class="comment">// 这里因为是临时内存，所以无需考虑双缓冲，因为获取时就在核心内</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer4, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// loopCount为计算次数，在数据量较大时，核心装不下所有的数据，所以就需要分块计算</span></span><br><span class="line">        <span class="comment">// 每块的大小为tileLength，最后的尾块的长度为leftNum</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123; </span><br><span class="line">            <span class="built_in">CopyIn</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 拷贝输入数据到队列中</span></span><br><span class="line">    <span class="comment">// 这里的progress是计算次数，length是每次能计算的数据量</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="built_in">AllocTensor</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">        inQueueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心计算函数，取决于具体的算子实现</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.<span class="built_in">DeQue</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_Z&gt; zLocal = outQueueZ.<span class="built_in">AllocTensor</span>&lt;DTYPE_Z&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor1 = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor2 = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor3 = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X&gt; tmpTensor4 = tmpBuffer<span class="number">4.</span><span class="built_in">Get</span>&lt;DTYPE_X&gt;();</span><br><span class="line">        </span><br><span class="line">        DTYPE_X inputVal1 = <span class="number">-1</span>;</span><br><span class="line">        DTYPE_X inputVal2 = <span class="number">0.5</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">Muls</span>(tmpTensor1, xLocal, inputVal1, length);</span><br><span class="line">        <span class="built_in">Exp</span>(tmpTensor2, tmpTensor1, length);</span><br><span class="line">        <span class="built_in">Exp</span>(tmpTensor3, xLocal, length);</span><br><span class="line">        <span class="built_in">Sub</span>(tmpTensor4, tmpTensor3, tmpTensor2, length);</span><br><span class="line">        <span class="built_in">Muls</span>(zLocal, tmpTensor4, inputVal2, length);</span><br><span class="line">        </span><br><span class="line">        outQueueZ.<span class="built_in">EnQue</span>&lt;DTYPE_Z&gt;(zLocal);</span><br><span class="line">        inQueueX.<span class="built_in">FreeTensor</span>(xLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拷贝输出数据到全局内存中</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_Z&gt; zLocal = outQueueZ.<span class="built_in">DeQue</span>&lt;DTYPE_Z&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * <span class="keyword">this</span>-&gt;tileLength], zLocal, length);</span><br><span class="line">        outQueueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 一些初始化</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    GlobalTensor&lt;DTYPE_X&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_Z&gt; zGm;</span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1, tmpBuffer2, tmpBuffer3, tmpBuffer4;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> totalLength;</span><br><span class="line">    <span class="type">uint64_t</span> tileLength;</span><br><span class="line">    <span class="type">uint64_t</span> loopCount;</span><br><span class="line">    <span class="type">uint64_t</span> leftNum;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">sinh_custom</span><span class="params">(GM_ADDR x, GM_ADDR z, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    KernelSinh op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, z, tiling, &amp;pipe);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>接下来是host侧的文件<br>sinh_custom.cpp的修改：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sinh_custom_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算向上32对齐</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32U</span><span class="params">(<span class="type">uint32_t</span> n,<span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 数据向下32对齐</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">31</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  </span><br><span class="line">    SinhCustomTilingData tiling;</span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">//数据总长度</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    totalLength = <span class="built_in">align32U</span>(totalLength,sizeofdatatype);              <span class="comment">// 数据向上32B对齐，这里是因为在Gm中地址必须32B对齐</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*  </span></span><br><span class="line"><span class="comment">        向下32对齐的最大分块长度，这里需要基于ub的大小，再根据在kernel侧计算时所有所需的空间大小来确定</span></span><br><span class="line"><span class="comment">        这里的计算方式是：分块长度为tilelength，单个队列所需的空间大小为 tileLength * BufferNum * sizeofdatatype</span></span><br><span class="line"><span class="comment">        再考虑上所需要的临时空间的大小，这里的临时空间大小为：tileLength * sizeofdatatype</span></span><br><span class="line"><span class="comment">        所以在这个算子中，所需的空间大小为：tilelength * BufferNum * sizeofdatatype * 2 +</span></span><br><span class="line"><span class="comment">        tileLength * sizeofdatatype * 4 = tileLength * (2 * 2 * 2 + 4 * 2) = tileLength * 16</span></span><br><span class="line"><span class="comment">        实际计算过程中需要将这个数向下取整，防止超出Ub的大小</span></span><br><span class="line"><span class="comment">        这里的ub_size是根据不同的处理器来确定的，这里以Ascend310B为例，ub_size为253952B</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">16</span>,sizeofdatatype);     </span><br><span class="line">    tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">    <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">    <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">    tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">    tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">    tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">    tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// Gm总地址32B对齐</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">    <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">    <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">    <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">    <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(<span class="number">1</span>);</span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SinhCustom</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//这里是msopgen自动生成的，表明数据的输入输出的类型还有具体有哪些输入输出</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">SinhCustom</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;z&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>); <span class="comment">//具体放在什么处理器上运行</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(SinhCustom);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>sinh_custom_tilling.h文件：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这里主要就是定义一下</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(SinhCustomTilingData)</span><br><span class="line">  <span class="comment">//增加类对象</span></span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);</span><br><span class="line">    <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);</span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(SinhCustom, SinhCustomTilingData)</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>至于在AscendC中为什么要分为Gm以及Ub，这里简单解释一下：<br>Gm是全局内存，用于存放完整的输入输出数据，而Ub是核心内临时存储空间，它的大小很有限，所以需要将输入输出数据分成小块来处理，每次分块大小的根据就是基于Ub的实际大小以及每次计算过程中所需要的空间来分配，尽可能的提升计算效率。此外，还有一些关于广播等的操作，以后再补充。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AscendC算子</title>
      <link href="/2024/10/20/AscendC%E7%AE%97%E5%AD%90/"/>
      <url>/2024/10/20/AscendC%E7%AE%97%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>AscendC算子原生支持C和C++标准规范,主要运行在Ascend系列产品上。因为是直接运行在npu上的算子函数，所以涉及到比较多的内存处理，包括一些数据搬移，内存管理，队列管理，还是比较的繁琐，但好在官方提供了编程范式，只需要按照所给的框架就能完成算子的实现。<br>开发者主要做的就是确定任务，设计算子，实现计算功能。<br>明确矢量算子的输入以及输出。Ascend C提供的矢量计算接口的操作元素都为LocalTensor，输入数据需要先搬运进AI Core的内部存储Local Memory，然后使用自定义Compute函数计算接口完成，得到最终结果，再搬出到外部存储Global Memory上。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TOTAL_LENGTH = <span class="number">8</span> * <span class="number">2048</span>;                            <span class="comment">// total length of data</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> USE_CORE_NUM = <span class="number">8</span>;                                   <span class="comment">// num of core used</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BLOCK_LENGTH = TOTAL_LENGTH / USE_CORE_NUM;         <span class="comment">// length computed of each core</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TILE_NUM = <span class="number">8</span>;                                       <span class="comment">// split data into 8 tiles for each core</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;                                     <span class="comment">// tensor num for each queue</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> TILE_LENGTH = BLOCK_LENGTH / TILE_NUM / BUFFER_NUM; <span class="comment">// seperate to 2 parts, due to double buffer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAdd</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span> <span class="comment">//初始化输入输出</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)x + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)y + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half *)z + BLOCK_LENGTH * <span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueY, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> <span class="comment">//实现流水操作</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int32_t</span> loopCount = TILE_NUM * BUFFER_NUM;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; loopCount; i++) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i);</span><br><span class="line">            <span class="built_in">Compute</span>(i);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//数据拷贝，入队</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; xLocal = inQueueX.<span class="built_in">AllocTensor</span>&lt;half&gt;();</span><br><span class="line">        LocalTensor&lt;half&gt; yLocal = inQueueY.<span class="built_in">AllocTensor</span>&lt;half&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * TILE_LENGTH], TILE_LENGTH);</span><br><span class="line">        <span class="built_in">DataCopy</span>(yLocal, yGm[progress * TILE_LENGTH], TILE_LENGTH);</span><br><span class="line">        inQueueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">        inQueueY.<span class="built_in">EnQue</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//核心计算过程，算法实现最核心的部分</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; xLocal = inQueueX.<span class="built_in">DeQue</span>&lt;half&gt;(); <span class="comment">//这两个LocalTensor就是实际函数的输入值，通过一系列数据搬移到了这，开始计算</span></span><br><span class="line">        LocalTensor&lt;half&gt; yLocal = inQueueY.<span class="built_in">DeQue</span>&lt;half&gt;();</span><br><span class="line">        LocalTensor&lt;half&gt; zLocal = outQueueZ.<span class="built_in">AllocTensor</span>&lt;half&gt;(); <span class="comment">//初始化输出对象，等下准备丢进输出队列</span></span><br><span class="line">        <span class="built_in">Add</span>(zLocal, xLocal, yLocal, TILE_LENGTH);</span><br><span class="line">        outQueueZ.<span class="built_in">EnQue</span>&lt;half&gt;(zLocal); <span class="comment">//在这里丢进输出队列</span></span><br><span class="line">        inQueueX.<span class="built_in">FreeTensor</span>(xLocal); <span class="comment">//释放空间</span></span><br><span class="line">        inQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress)</span> <span class="comment">//数据搬出</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        LocalTensor&lt;half&gt; zLocal = outQueueZ.<span class="built_in">DeQue</span>&lt;half&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * TILE_LENGTH], zLocal, TILE_LENGTH);</span><br><span class="line">        outQueueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX, inQueueY;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueZ;</span><br><span class="line">    GlobalTensor&lt;half&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;half&gt; yGm;</span><br><span class="line">    GlobalTensor&lt;half&gt; zGm;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span> <span class="comment">//核函数，作为整个功能的接口</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    KernelAdd op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, z);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
            <tag> Ascend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于yolov5的羽毛球轨迹识别</title>
      <link href="/2024/10/18/yolov5/"/>
      <url>/2024/10/18/yolov5/</url>
      
        <content type="html"><![CDATA[<p>yolov5是一种很流行的目标检测系统，基于这套系统，我们可以很轻松的开发各种识别物体的项目，不过需要自己准备数据集，以及一定的计算资源。<br>本质上来说，yolov5也是一个基于深度学习的视觉识别系统，效果很不错，就省去了自己开发的过程。同时还可以在源代码上修改，来实现自己的需求。<br>首先从部署yolov5开始：<br>部署的环境是基于python的，为了方便管理，我们使用anaconda创建一个新的虚拟环境，以便跟别的环境隔离开，这样就不会冲突。<br>在命令行中输入<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n yolov5 python=3.10</span><br></pre></td></tr></table></figure><br>然后再输入<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate yolov5</span><br></pre></td></tr></table></figure><br>这样就创建好并且进入了一个新的环境内。接下来克隆官方仓库并且安装依赖项<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ultralytics/yolov5</span><br><span class="line">cd yolov5</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><br>如果有N卡的话还得下载对应的cuda<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br></pre></td></tr></table></figure><br>到这里yolov5的环境就配置好了。随便跑点样例实验一下。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --device 0</span><br></pre></td></tr></table></figure><br>这就是一个最简单的训练的代码，使用的是官方的数据集，训练后的模型存储在 runs/train/exp/weights/best.pt<br>尝试用模型检测一下<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python detect.py --device 0</span><br></pre></td></tr></table></figure><br>检测的结果会在 runs/detect/exp中<br>上面是一些比较简单的配置还有验证的过程，接下来的是最重要的，想要对一个物体进行识别，首先得有数据集，然后基于这个数据集进行训练，因为网上实在没有羽毛球的模型，我就自己框了大概1500张图，分割三分之一作为验证集，剩下的作为训练集。框图可以用这个<a href="http://makesense.bimant.com/">网站</a><br>框图之后会得到一份标签集，可以使用下面的代码分割训练集验证集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line">image_folder = <span class="string">&#x27;path/to/images&#x27;</span>  <span class="comment"># 图片文件夹路径</span></span><br><span class="line">label_folder = <span class="string">&#x27;path/to/labels&#x27;</span>  <span class="comment"># 标签文件夹路径</span></span><br><span class="line"></span><br><span class="line">val_image_folder = <span class="string">&#x27;path/to/val_images&#x27;</span>  <span class="comment"># 验证集图片存放路径</span></span><br><span class="line">val_label_folder = <span class="string">&#x27;path/to/val_labels&#x27;</span>  <span class="comment"># 验证集标签存放路径</span></span><br><span class="line"></span><br><span class="line">os.makedirs(val_image_folder, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(val_label_folder, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">image_files = <span class="built_in">sorted</span>(os.listdir(image_folder))</span><br><span class="line">label_files = <span class="built_in">sorted</span>(os.listdir(label_folder))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(image_files) != <span class="built_in">len</span>(label_files):</span><br><span class="line"><span class="keyword">raise</span> ValueError(<span class="string">&quot;图片和标签数量不匹配！请检查文件夹内容。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, image_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(image_files):</span><br><span class="line"><span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">3</span> == <span class="number">0</span>:  <span class="comment"># 每三张图片选一张</span></span><br><span class="line"><span class="comment"># 获取对应的标签文件名</span></span><br><span class="line">label_file = label_files[i]</span><br><span class="line"></span><br><span class="line">        image_path = os.path.join(image_folder, image_file)</span><br><span class="line">        label_path = os.path.join(label_folder, label_file)</span><br><span class="line">        </span><br><span class="line">        shutil.move(image_path, os.path.join(val_image_folder, image_file))</span><br><span class="line">        shutil.move(label_path, os.path.join(val_label_folder, label_file))</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;验证集划分完成！&quot;</span>)</span><br></pre></td></tr></table></figure><br>然后再对分割好的数据集去训练<br>下面是基于项目需求，对代码的修改<br>首先添加一个元组，并且生成一个背景，用于绘制我们的轨迹<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_centers = []</span><br><span class="line">canvas = np.ones((im0s.shape[<span class="number">0</span>], im0s.shape[<span class="number">1</span>], <span class="number">3</span>), dtype=np.uint8) * <span class="number">255</span></span><br></pre></td></tr></table></figure><br>用来存储我们识别到的羽毛球在空间中的坐标<br>然后在识别到目标之后，把原代码的框选修改为点<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_center = (xyxy[<span class="number">0</span>] + xyxy[<span class="number">2</span>]) / <span class="number">2</span></span><br><span class="line">y_center = (xyxy[<span class="number">1</span>] + xyxy[<span class="number">3</span>]) / <span class="number">2</span></span><br><span class="line"><span class="comment">#LOGGER.info(&quot;x_center: %f, y_center: %f&quot;, x_center, y_center)</span></span><br><span class="line">all_centers.append((x_center, y_center))</span><br><span class="line">radius = <span class="number">10</span></span><br><span class="line">color = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">cv2.circle(imc, (<span class="built_in">int</span>(x_center), <span class="built_in">int</span>(y_center)), radius, color, thickness=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>然后再遍历我们的坐标，将点绘制在背景上<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x_center , y_center <span class="keyword">in</span> all_centers:</span><br><span class="line">    cv2.circle(canvas, (<span class="built_in">int</span>(x_center), <span class="built_in">int</span>(y_center)), <span class="number">10</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">save_path = increment_path(Path(project) / name, exist_ok=exist_ok)</span><br><span class="line">save_path.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">final_save_path = save_path / <span class="string">&quot;all_centers.jpg&quot;</span></span><br><span class="line">cv2.imwrite(<span class="built_in">str</span>(final_save_path), canvas)</span><br></pre></td></tr></table></figure><br>然后就可以得到羽毛球的轨迹啦<br>其实最开始是打算做类似鹰眼的轨迹识别加预测，但是预测的过程太过于复杂，折腾了一堆东西没有什么进展就over了</p>]]></content>
      
      
      <categories>
          
          <category> 项目 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RFID实验，FM0编解码代码</title>
      <link href="/2024/10/17/FM0/"/>
      <url>/2024/10/17/FM0/</url>
      
        <content type="html"><![CDATA[<p>使用matlab编写的一份用于编解码信号的.m文件<br>密勒码解码过程可以表述为：以 2 倍的数据时钟码读入，进行每两位转换一次，01 和 10 都转换为 1，00 和 11 都转换为 0，这样即完成解码得到原始 NRZ 码，本实验无起始同步和停止过程<br>本代码参照密勒码的文件修改<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>]; <span class="comment">% 输入的二进制数据</span></span><br><span class="line">FM0 = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="number">2</span> * <span class="built_in">length</span>(x)); <span class="comment">% 生成FM0编码,对应两个编码位</span></span><br><span class="line">state = <span class="number">0</span>; <span class="comment">% 初始化状态，初始为0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 对输入数据进行FM0编码</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">length</span>(x)</span><br><span class="line">    <span class="keyword">if</span> x(<span class="built_in">i</span>) == <span class="number">1</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>) = ~state; <span class="comment">% 当当前数据位为1时，第一个码元是当前状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 状态翻转</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span>) = state; <span class="comment">% 第二个码元是翻转后的状态</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span><span class="number">-1</span>) = ~state; <span class="comment">% 当当前数据位为0时，第一个码元是当前状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 状态翻转</span></span><br><span class="line">        FM0(<span class="number">2</span>*<span class="built_in">i</span>) = ~state; <span class="comment">% 第二个码元是翻转后的状态的反转</span></span><br><span class="line">        state = ~state; <span class="comment">% 再次翻转状态以保持为下一位做准备</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>); <span class="comment">% 绘制原始输入数据</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(x)<span class="number">-1</span>, x, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示输入数据</span></span><br><span class="line">title(<span class="string">&#x27;原始数据&#x27;</span>); <span class="comment">% 设置标题为&quot;原始数据&quot;</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>); <span class="comment">% 绘制编码后的FM0结果</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(FM0)<span class="number">-1</span>, FM0, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示FM0编码结果</span></span><br><span class="line">title(<span class="string">&#x27;FM0 编码结果&#x27;</span>); <span class="comment">% 设置标题为&quot;FM0 编码结果&quot;</span></span><br><span class="line"><span class="comment">% 创建存储解码结果的向量，其长度为FM0编码长度的一半</span></span><br><span class="line">decoded_data = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">length</span>(FM0) / <span class="number">2</span>); </span><br><span class="line"><span class="comment">% 解码循环，从FM0编码结果中恢复原始数据</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">2</span>:<span class="built_in">length</span>(FM0)<span class="number">-2</span></span><br><span class="line">    <span class="comment">% 如果两个相邻的FM0码元不同且下一对码元相同</span></span><br><span class="line">    <span class="keyword">if</span> (FM0(<span class="built_in">i</span>) ~= FM0(<span class="built_in">i</span>+<span class="number">1</span>)) &amp;&amp; (FM0(<span class="built_in">i</span>+<span class="number">1</span>) == FM0(<span class="built_in">i</span>+<span class="number">2</span>)) </span><br><span class="line">        decoded_data((<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">1</span>; <span class="comment">% 则解码为1</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        decoded_data((<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">0</span>; <span class="comment">% 否则解码为0</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>); <span class="comment">% 绘制解码后的数据</span></span><br><span class="line">stairs(<span class="number">0</span>:<span class="built_in">length</span>(decoded_data)<span class="number">-1</span>, decoded_data, <span class="string">&#x27;r&#x27;</span>); <span class="comment">% 使用阶梯图显示解码后的数据</span></span><br><span class="line">title(<span class="string">&#x27;FM0 解码结果&#x27;</span>); <span class="comment">% 设置标题为&quot;FM0 解码结果&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> RFID </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>随便写点</title>
      <link href="/2024/10/15/start/"/>
      <url>/2024/10/15/start/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到我的博客! 如果感兴趣的话就多逛逛。不定期更新项目的经历，记录自己走过的路。这是我的<a href="https://github.com/xxxkkw">代码仓库</a>。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
