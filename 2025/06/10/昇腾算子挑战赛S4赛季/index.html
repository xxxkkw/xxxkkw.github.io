<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>昇腾AI创新算子挑战赛S4赛季 | xxxkkw的妙妙屋</title><meta name="author" content="xxxkkw"><meta name="copyright" content="xxxkkw"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="昇腾AI创新算子挑战赛S4赛季本项目是昇腾AI创新算子挑战赛S4赛季的开源代码。 行业背景人工智能、云计算、边缘计算等领域的计算需求的爆发式增长带动了GPU计算能力的发展。这些领域都依赖高性能算法来实现特定的需求，而作为算法核心执行单元的算子，负责实现基础的数学运算和逻辑运算。算子的性能直接影响整个算法的性能。算子也是软件和硬件之间的桥梁，是算法得以落地的关键环节，已经成为推动计算机技术进步和算法"><meta property="og:type" content="article"><meta property="og:title" content="昇腾AI创新算子挑战赛S4赛季"><meta property="og:url" content="http://example.com/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/index.html"><meta property="og:site_name" content="xxxkkw的妙妙屋"><meta property="og:description" content="昇腾AI创新算子挑战赛S4赛季本项目是昇腾AI创新算子挑战赛S4赛季的开源代码。 行业背景人工智能、云计算、边缘计算等领域的计算需求的爆发式增长带动了GPU计算能力的发展。这些领域都依赖高性能算法来实现特定的需求，而作为算法核心执行单元的算子，负责实现基础的数学运算和逻辑运算。算子的性能直接影响整个算法的性能。算子也是软件和硬件之间的桥梁，是算法得以落地的关键环节，已经成为推动计算机技术进步和算法"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/img/head.jpg"><meta property="article:published_time" content="2025-06-10T13:00:00.000Z"><meta property="article:modified_time" content="2025-06-20T05:34:59.417Z"><meta property="article:author" content="xxxkkw"><meta property="article:tag" content="项目"><meta property="article:tag" content="Ascend"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/img/head.jpg"><link rel="shortcut icon" href="/img/wall.jpg"><link rel="canonical" href="http://example.com/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach(([e,t])=>n.setAttribute(e,t)),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),getCSS:(e,t)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),addGlobalFn:(e,t,o=!1,a=window)=>{if(e.startsWith("pjax"))return;const n=a.globalFn||{};n[e]=n[e]||{},o&&n[e][o]||(n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n)}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","ffffff")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"昇腾AI创新算子挑战赛S4赛季",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-06-20 13:34:59"}</script><link rel="stylesheet" href="/styles/main.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.3.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",o)})()</script><div id="web_bg" style="background-color:#efefef"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/head.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/wall.jpg)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">xxxkkw的妙妙屋</span></a><a class="nav-page-title" href="/"><span class="site-name">昇腾AI创新算子挑战赛S4赛季</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">昇腾AI创新算子挑战赛S4赛季</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-10T13:00:00.000Z" title="发表于 2025-06-10 21:00:00">2025-06-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-20T05:34:59.417Z" title="更新于 2025-06-20 13:34:59">2025-06-20</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2025/06/10/%E6%98%87%E8%85%BE%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3/" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="昇腾AI创新算子挑战赛S4赛季"><a href="#昇腾AI创新算子挑战赛S4赛季" class="headerlink" title="昇腾AI创新算子挑战赛S4赛季"></a>昇腾AI创新算子挑战赛S4赛季</h1><p>本项目是昇腾AI创新算子挑战赛S4赛季的开源代码。</p><h2 id="行业背景"><a href="#行业背景" class="headerlink" title="行业背景"></a>行业背景</h2><p>人工智能、云计算、边缘计算等领域的计算需求的爆发式增长带动了GPU计算能力的发展。这些领域都依赖高性能算法来实现特定的需求，而作为算法核心执行单元的算子，负责实现基础的数学运算和逻辑运算。算子的性能直接影响整个算法的性能。算子也是软件和硬件之间的桥梁，是算法得以落地的关键环节，已经成为推动计算机技术进步和算法产业应用发展的核心动力。<br><img src="/img/cuda.png" alt="image.png"><br>主流的PyTorch、TensorFlow、Caffe等人工智能框架中使用的算子已相当成熟，这些算子基于GPU算力的CUDA、cuDNN等平台实现。</p><h3 id="昇腾计算产业"><a href="#昇腾计算产业" class="headerlink" title="昇腾计算产业"></a>昇腾计算产业</h3><p>昇腾计算产业是华为公司推出的一系列人工智能解决方案，基于昇腾硬件处理器和配套软件设施所构建的全栈人工智能技术应用和服务，包括昇腾系列训练和推理芯片、CANN软件栈、深度学习计算框架、应用开发工具、应用管理运维工具、工业级服务等多种产业链，为国内人工智能的研究提供了强大的计算能力和全面的软硬件支持。<br><img src="/img/cann.png" alt="image.png"></p><h3 id="AscendC算子编程介绍"><a href="#AscendC算子编程介绍" class="headerlink" title="AscendC算子编程介绍"></a>AscendC算子编程介绍</h3><p>基于Ascend C方式实现基础矢量算子核函数的流程如下图所示。<br><img src="/img/con.png" alt="image.png"></p><ul><li>算子分析：分析算子的数学表达式、输入、输出以及计算逻辑的实现，明确需要调用的Ascend C接口。</li><li>核函数定义：定义Ascend C算子入口函数。</li><li>根据矢量编程范式实现算子类：完成核函数的内部实现，包括3个基本任务：CopyIn，Compute，CopyOut。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAdd</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAdd</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 不同核根据各自的block_idx设置数据地址</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)x + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)y + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ half*)z + BLOCK_LENGTH * AscendC::<span class="built_in">GetBlockIdx</span>(), BLOCK_LENGTH);</span><br><span class="line">        <span class="comment">// Queue初始化，单位为字节</span></span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueX, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(inQueueY, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(outQueueZ, BUFFER_NUM, TILE_LENGTH * <span class="built_in">sizeof</span>(half));</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">CopyIn</span>();</span><br><span class="line">        <span class="built_in">Compute</span>();</span><br><span class="line">        <span class="built_in">CopyOut</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现核函数</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_custom</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化算子类，算子类提供算子初始化和核心处理等方法</span></span><br><span class="line">    KernelAdd op;</span><br><span class="line">    <span class="comment">// 初始化函数，获取该核函数需要处理的输入输出地址，同时完成必要的内存初始化工作</span></span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, z);</span><br><span class="line">    <span class="comment">// 核心处理函数，完成算子的数据搬运与计算等核心逻辑</span></span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下图为AscendC编程过程中抽象表示的硬件架构图<br><img src="/img/vector.png" alt="image.png"></p><h2 id="赛题列表"><a href="#赛题列表" class="headerlink" title="赛题列表"></a>赛题列表</h2><p>以下是本次S4赛季的赛题列表：</p><ul><li>[x] Reshape (demo)</li><li>[x] RmsNorm (demo)</li><li>[x] SelectV2 (AC)</li><li>[x] Pows (AC)</li><li>[ ] Gather</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>针对已完成的算子，后续的优化方向包括：</p><ul><li><strong>SelectV2 &amp; Pows</strong>:<ul><li>细分广播与非广播场景的实现，进行针对性优化。</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li></ul><p>针对未完成的算子，后续的完善过程包括：</p><ul><li><strong>Reshape</strong>:<ul><li>重写输出shape函数，符合正常reshape函数逻辑</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li><li><strong>RmsNorm</strong>:<ul><li>解决数据未完全对齐的问题</li><li>细分各种数据类型的case，写到tilling key中。</li></ul></li></ul><hr><h1 id="Pows算子实现详解"><a href="#Pows算子实现详解" class="headerlink" title="Pows算子实现详解"></a>Pows算子实现详解</h1><h2 id="算子概述"><a href="#算子概述" class="headerlink" title="算子概述"></a>算子概述</h2><p>Pows算子实现了幂运算功能，即计算<code>y = x1^x2</code>，其中x1为底数，x2为指数。该算子需支持广播机制，能够处理不同形状的输入张量。</p><p>算法实现原理：<code>pow(x1, x2) = exp(x2 * ln(x1))</code></p><h2 id="kernel侧实现"><a href="#kernel侧实现" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><h3 id="1-完成pow-cpp文件-这里是算子的入口"><a href="#1-完成pow-cpp文件-这里是算子的入口" class="headerlink" title="1. 完成pow.cpp文件,这里是算子的入口"></a>1. 完成pow.cpp文件,这里是算子的入口</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 引入必要的头文件</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span>  <span class="comment">// AscendC核心算子开发框架</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pow.h&quot;</span>              <span class="comment">// 非广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;powb.h&quot;</span>             <span class="comment">// 广播场景的Pows算子实现</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 算子入口函数，使用extern &quot;C&quot;确保C++函数能被C代码调用</span></span><br><span class="line"><span class="comment">// __global__表示这是一个设备端函数，__aicore__表示运行在AI Core上</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">pows</span><span class="params">(GM_ADDR x1,GM_ADDR x2, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR y, GM_ADDR workspace, </span></span></span><br><span class="line"><span class="params"><span class="function">                                           GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;  <span class="comment">// 这里有个细节，建议在最开始就定义好pipe对象，然后通过传参数</span></span><br><span class="line">                 <span class="comment">//  再进到Init中，有一定性能优化</span></span><br><span class="line">    <span class="comment">// 根据tiling key选择不同的实现策略</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">1</span>))&#123; <span class="comment">// tiling key为1：非广播场景</span></span><br><span class="line">        KernelPows op;  <span class="comment">// 创建非广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">2</span>))&#123; <span class="comment">// tiling key为2：广播场景</span></span><br><span class="line">        KernelPowsBroadCast op;  <span class="comment">// 创建广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 以下是针对不同数据类型的扩展实现（当前注释掉）</span></span><br><span class="line">    <span class="comment">// 可以根据需要细分fp16和fp32的非广播和广播实现</span></span><br><span class="line">    <span class="comment">// if(TILING_KEY_IS(1))&#123; // fp16非广播</span></span><br><span class="line">    <span class="comment">//     KernelPows op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(2))&#123; // fp32非广播</span></span><br><span class="line">    <span class="comment">//      op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(3))&#123; // fp16广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastB op;</span></span><br><span class="line">    <span class="comment">//     op.Init(x1,x2, y, tiling,&amp;pipe);</span></span><br><span class="line">    <span class="comment">//     op.Process();</span></span><br><span class="line">    <span class="comment">// &#125;else if(TILING_KEY_IS(4))&#123; // fp32广播</span></span><br><span class="line">    <span class="comment">//     KernelPowsBroadCastBB op;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-非广播场景实现-pow-h"><a href="#2-非广播场景实现-pow-h" class="headerlink" title="2. 非广播场景实现 (pow.h)"></a>2. 非广播场景实现 (pow.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;  <span class="comment">// 双缓冲机制，提高数据传输效率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非广播场景的Pows算子实现类（tiling key 1）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPows</span>&#123; </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPows</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化tiling参数，从host侧传递的tiling数据中获取分块信息</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);  <span class="comment">// 获取tiling数据结构</span></span><br><span class="line">            totalLength = tiling_data.totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;    <span class="comment">// 每个tile的长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;      <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;          <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化算子，设置全局内存地址和缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);  <span class="comment">// 初始化tiling参数</span></span><br><span class="line">    </span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);  <span class="comment">// 确保block数量不为0</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，将GM地址转换为GlobalTensor</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;  <span class="comment">// 保存pipe指针</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化输入输出队列，使用双缓冲提高效率</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX1, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX2, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 对于half类型，把half转成float，要不然精度不够</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 主处理函数，按tile进行循环处理</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 处理完整的tile</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(i,  <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将数据从GM拷贝到UB</span></span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 在UB中进行计算</span></span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将结果从UB拷回GM</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余的不足一个tile的数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 数据输入函数：从全局内存拷贝数据到本地缓冲区</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 分配本地tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 从全局内存拷贝数据到本地tensor</span></span><br><span class="line">            <span class="built_in">DataCopy</span>(x1Local, x1Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            <span class="built_in">DataCopy</span>(x2Local, x2Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将tensor加入队列</span></span><br><span class="line">            inQueueX<span class="number">1.</span><span class="built_in">EnQue</span>(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.</span><span class="built_in">EnQue</span>(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算函数：执行幂运算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 从队列中取出输入tensor</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">DeQue</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">DeQue</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型选择不同的计算方法</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length);  <span class="comment">// float类型直接计算</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);     <span class="comment">// 半精度类型需要类型转换</span></span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 释放输入tensor</span></span><br><span class="line">            inQueueX<span class="number">1.F</span>reeTensor(x1Local);</span><br><span class="line">            inQueueX<span class="number">2.F</span>reeTensor(x2Local);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现：pow(x1, x2) = exp(x2 * ln(x1))</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// 计算ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// 计算x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// 计算exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现：需要先转换为float进行计算</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时float缓冲区</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将半精度数据转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 在float精度下进行幂运算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将结果转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 数据输出函数：将计算结果从本地缓冲区拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 队列和缓冲区定义</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX1;   <span class="comment">// 输入x1队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX2;   <span class="comment">// 输入x2队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;  <span class="comment">// 输出y队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时缓冲区（用于半精度计算）</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 管道和参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;   <span class="comment">// 每个tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;    <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;      <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-广播场景实现-powb-h"><a href="#3-广播场景实现-powb-h" class="headerlink" title="3. 广播场景实现 (powb.h)"></a>3. 广播场景实现 (powb.h)</h3><p>广播场景的实现更加复杂，需要处理不同形状的输入张量。主要特点：</p><ul><li>支持多维张量的广播机制</li><li>动态计算每个输出元素对应的输入元素索引</li><li>逐元素计算，适用于形状不匹配的情况</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 广播场景的Pows算子实现类（tiling key 2）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelPowsBroadCast</span>&#123;  </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelPowsBroadCast</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播相关的tiling参数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">            <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling); </span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输出张量的维度信息</span></span><br><span class="line">            y_dimensional = tiling_data.y_dimensional;  <span class="comment">// 输出张量维度数</span></span><br><span class="line">            y_ndarray = tiling_data.y_ndarray;          <span class="comment">// 输出张量各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 输入张量的维度信息</span></span><br><span class="line">            x1_ndarray = tiling_data.x1_ndarray;        <span class="comment">// 输入x1各维度大小</span></span><br><span class="line">            x2_ndarray = tiling_data.x2_ndarray;        <span class="comment">// 输入x2各维度大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 累积维度信息，用于索引计算</span></span><br><span class="line">            y_sumndarray = tiling_data.y_sumndarray;    <span class="comment">// 输出张量累积维度</span></span><br><span class="line">            x1_sumndarray = tiling_data.x1_sumndarray;  <span class="comment">// 输入x1累积维度</span></span><br><span class="line">            x2_sumndarray = tiling_data.x2_sumndarray;  <span class="comment">// 输入x2累积维度</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 张量长度信息</span></span><br><span class="line">            x1TotalLength = tiling_data.x1TotalLength;  <span class="comment">// x1总长度</span></span><br><span class="line">            x2TotalLength = tiling_data.x2TotalLength;  <span class="comment">// x2总长度</span></span><br><span class="line">            x1Size = tiling_data.x1Size;                <span class="comment">// x1大小</span></span><br><span class="line">            x2Size = tiling_data.x2Size;                <span class="comment">// x2大小</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 分块信息</span></span><br><span class="line">            totalLength = tiling_data.totalLength;      <span class="comment">// 输出总长度</span></span><br><span class="line">            tileLength = tiling_data.tileLength;        <span class="comment">// 每个tile长度</span></span><br><span class="line">            loopCount = tiling_data.loopCount;          <span class="comment">// 循环次数</span></span><br><span class="line">            leftNum = tiling_data.leftNum;              <span class="comment">// 剩余数据长度</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化广播算子</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">            <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">            <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 设置全局内存缓冲区，注意x1和x2的长度可能不同</span></span><br><span class="line">            x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1, x1TotalLength);  </span><br><span class="line">            x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X2*)x2, x2TotalLength); </span><br><span class="line">            yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y, totalLength);</span><br><span class="line">            </span><br><span class="line">            pipe = pipeIn;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 初始化临时缓冲区（广播场景不使用队列，而是直接使用缓冲区）</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 半精度类型需要额外的float缓冲区</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">                pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 广播场景的主处理函数</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 获取临时缓冲区用于存储广播后的数据</span></span><br><span class="line">            LocalTensor&lt;DTYPE_X1&gt; x1Local = tmpBufferX<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">            LocalTensor&lt;DTYPE_X2&gt; x2Local = tmpBufferX<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 按tile处理数据</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i++) &#123;                   </span><br><span class="line">                <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength,x1Local,x2Local);           </span><br><span class="line">                <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 处理剩余数据</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum,x1Local,x2Local);</span><br><span class="line">                <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 广播场景的计算函数：逐元素计算广播索引</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length,LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local)</span> </span>&#123; </span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 逐元素处理，计算每个输出元素对应的输入元素索引</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">uint32_t</span> j = <span class="number">0</span>;j &lt; length;j ++)&#123;</span><br><span class="line">                <span class="type">uint32_t</span> x1_start = <span class="number">0</span>;  <span class="comment">// x1的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> x2_start = <span class="number">0</span>;  <span class="comment">// x2的起始索引</span></span><br><span class="line">                <span class="type">uint32_t</span> index = j + progress * <span class="keyword">this</span>-&gt;tileLength;  <span class="comment">// 当前输出元素的全局索引</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 根据广播规则计算输入索引</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">uint32_t</span> k = <span class="number">0</span>; k &lt; <span class="keyword">this</span>-&gt;y_dimensional; k++)&#123;</span><br><span class="line">                    <span class="comment">// 如果x1在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;x1_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x1_start += <span class="keyword">this</span>-&gt;x1_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 如果x2在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                    <span class="keyword">if</span>(<span class="keyword">this</span>-&gt;x2_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                        x2_start += <span class="keyword">this</span>-&gt;x2_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);  </span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 从全局内存获取对应位置的值</span></span><br><span class="line">                <span class="keyword">auto</span> x1 = x1Gm.<span class="built_in">GetValue</span>(x1_start); </span><br><span class="line">                <span class="keyword">auto</span> x2 = x2Gm.<span class="built_in">GetValue</span>(x2_start);</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 将值设置到本地tensor中</span></span><br><span class="line">                x1Local.<span class="built_in">SetValue</span>(j,x1);</span><br><span class="line">                x2Local.<span class="built_in">SetValue</span>(j,x2);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据数据类型执行计算</span></span><br><span class="line">            <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt;)</span></span>&#123;</span><br><span class="line">                <span class="built_in">Cmpfp32</span>(x1Local,x2Local,yLocal,length); </span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">bfloat16_t</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)&#123;</span><br><span class="line">                <span class="built_in">Cmp</span>(x1Local,x2Local,yLocal,length);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// float类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmpfp32</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            <span class="built_in">Ln</span>(x1Local,x1Local,length);           <span class="comment">// ln(x1)</span></span><br><span class="line">            <span class="built_in">Mul</span>(yLocal,x1Local,x2Local,length);   <span class="comment">// x2 * ln(x1)</span></span><br><span class="line">            <span class="built_in">Exp</span>(yLocal,yLocal,length);             <span class="comment">// exp(x2 * ln(x1))</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 半精度类型的幂运算实现</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Cmp</span><span class="params">(LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local,LocalTensor&lt;DTYPE_Y&gt; yLocal,<span class="type">uint32_t</span> length)</span></span>&#123;</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换为float</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// float精度计算</span></span><br><span class="line">            <span class="built_in">Ln</span>(x1TmpLocal,x1TmpLocal,length);</span><br><span class="line">            <span class="built_in">Mul</span>(yTmpLocal,x1TmpLocal,x2TmpLocal,length);</span><br><span class="line">            <span class="built_in">Exp</span>(yTmpLocal,yTmpLocal,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始精度</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出函数：将结果拷贝到全局内存</span></span><br><span class="line">        <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">            LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">            <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">            outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 输出队列</span></span><br><span class="line">        TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 全局内存tensor</span></span><br><span class="line">        GlobalTensor&lt;DTYPE_X1&gt; x1Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_X2&gt; x2Gm;</span><br><span class="line">        GlobalTensor&lt;DTYPE_Y&gt; yGm;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 临时计算缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;</span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX1;  <span class="comment">// x1临时缓冲区</span></span><br><span class="line">        TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX2;  <span class="comment">// x2临时缓冲区</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 管道和基本参数</span></span><br><span class="line">        TPipe* pipe;</span><br><span class="line">        <span class="type">uint64_t</span> totalLength;   <span class="comment">// 输出总长度</span></span><br><span class="line">        <span class="type">uint64_t</span> tileLength;    <span class="comment">// tile长度</span></span><br><span class="line">        <span class="type">uint64_t</span> loopCount;     <span class="comment">// 循环次数</span></span><br><span class="line">        <span class="type">uint64_t</span> leftNum;       <span class="comment">// 剩余长度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 广播相关参数</span></span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional;     <span class="comment">// 输出维度数</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_sumndarray;    <span class="comment">// x1累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_sumndarray;    <span class="comment">// x2累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_ndarray;        <span class="comment">// 输出各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x1_ndarray;       <span class="comment">// x1各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *x2_ndarray;       <span class="comment">// x2各维度大小</span></span><br><span class="line">        <span class="type">uint32_t</span> *y_sumndarray;     <span class="comment">// 输出累积维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> x1TotalLength;     <span class="comment">// x1总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x2TotalLength;     <span class="comment">// x2总长度</span></span><br><span class="line">        <span class="type">uint32_t</span> x1Size;            <span class="comment">// x1大小</span></span><br><span class="line">        <span class="type">uint32_t</span> x2Size;            <span class="comment">// x2大小</span></span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><h2 id="host侧实现"><a href="#host侧实现" class="headerlink" title="host侧实现"></a>host侧实现</h2><p>host侧主要负责算子的注册、形状推理、tiling策略计算等功能。包含以下几个关键部分：</p><h3 id="1-Tiling数据结构定义-pows-tiling-h"><a href="#1-Tiling数据结构定义-pows-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (pows_tiling.h)"></a>1. Tiling数据结构定义 (pows_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">// 定义Pows算子的tiling数据结构</span></span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(PowsTilingData)</span><br><span class="line">  <span class="comment">// 基础分块参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);    <span class="comment">// 总数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);      <span class="comment">// 循环次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);        <span class="comment">// 剩余数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);     <span class="comment">// 每个tile的长度</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 广播相关参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, y_dimensional);  <span class="comment">// 输出张量维度数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1TotalLength);  <span class="comment">// x1总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2TotalLength);  <span class="comment">// x2总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1Size);         <span class="comment">// x1大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2Size);         <span class="comment">// x2大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 维度数组（最大支持20维）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_ndarray);   <span class="comment">// 输出各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_ndarray);  <span class="comment">// x1各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_ndarray);  <span class="comment">// x2各维度大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 累积维度数组（用于索引计算）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_sumndarray);  <span class="comment">// 输出累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_sumndarray); <span class="comment">// x1累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_sumndarray); <span class="comment">// x2累积维度</span></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册tiling数据类</span></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(Pows, PowsTilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-pows-cpp"><a href="#2-Tiling策略计算-pows-cpp" class="headerlink" title="2. Tiling策略计算 (pows.cpp)"></a>2. Tiling策略计算 (pows.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;pows_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向上32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32U</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">31</span>) &amp; ~<span class="number">31</span>) / DataType;  <span class="comment">// 向上对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向下32字节对齐函数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align32D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;                    <span class="comment">// 乘以数据类型大小</span></span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">31</span>) / DataType;      <span class="comment">// 向下对齐到32字节边界</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="type">const</span> <span class="type">uint32_t</span> BLOCK_SIZE = <span class="number">32</span>;      <span class="comment">// 块大小常量</span></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;    <span class="comment">// 双缓冲数量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PowsTilingData tiling;  <span class="comment">// 创建tiling数据结构</span></span><br><span class="line">    <span class="type">uint64_t</span> sizeofdatatype;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取平台信息</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> socVersion = ascendcPlatform.<span class="built_in">GetSocVersion</span>();  <span class="comment">// 获取SoC版本</span></span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);  <span class="comment">// 获取UB大小</span></span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNum</span>();  <span class="comment">// 获取核心数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入数据信息</span></span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// 数据总长度</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();  <span class="comment">// 获取数据类型</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 根据数据类型确定字节大小</span></span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;  <span class="comment">// 半精度类型占2字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;  <span class="comment">// 单精度类型占4字节</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取输入张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="type">uint32_t</span> x2Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();</span><br><span class="line">    <span class="keyword">if</span> (x1Size != x2Size)&#123;  <span class="comment">// 长度不一就广播，广播部分采用论坛中的广播样例</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(3);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(4);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 定义维度数组</span></span><br><span class="line">        <span class="type">uint32_t</span> y_ndarray[<span class="number">20</span>], x1_ndarray[<span class="number">20</span>], x2_ndarray[<span class="number">20</span>];</span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional, x1_dimensional, x2_dimensional;</span><br><span class="line">        <span class="comment">// 获取张量形状信息</span></span><br><span class="line">        <span class="keyword">auto</span> shape_y  = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x1 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x2 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="comment">// 获取各张量的维度数</span></span><br><span class="line">        y_dimensional  = shape_y.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        x1_dimensional = shape_x<span class="number">1.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        x2_dimensional = shape_x<span class="number">2.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> max_dimensional = y_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x1_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x1_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x2_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x2_dimensional;</span><br><span class="line">        <span class="comment">// 初始化维度数组，处理维度对齐</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; max_dimensional; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; y_dimensional) &#123;</span><br><span class="line">                y_ndarray[y_dimensional - i - <span class="number">1</span>] = shape_y.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                y_ndarray[i] = <span class="number">1</span>; <span class="comment">// 不足的维度补1</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x1_dimensional) &#123;</span><br><span class="line">                x1_ndarray[x1_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">1.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x1_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x2_dimensional) &#123;</span><br><span class="line">                x2_ndarray[x2_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">2.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x2_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_dimensional</span>(max_dimensional);</span><br><span class="line">        tiling.<span class="built_in">set_y_ndarray</span>(y_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_ndarray</span>(x1_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_ndarray</span>(x2_ndarray);</span><br><span class="line">        <span class="comment">// 计算累积维度数组（用于索引计算）</span></span><br><span class="line">        <span class="type">uint32_t</span> y_sumndarray[<span class="number">20</span>], x1_sumndarray[<span class="number">20</span>], x2_sumndarray[<span class="number">20</span>];</span><br><span class="line">        y_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x1_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x2_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">1</span>; i &lt;= max_dimensional; i++)&#123;</span><br><span class="line">            y_sumndarray[i]   = y_sumndarray[i - <span class="number">1</span>]   * y_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x1_sumndarray[i]  = x1_sumndarray[i - <span class="number">1</span>]  * x1_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x2_sumndarray[i]  = x2_sumndarray[i - <span class="number">1</span>]  * x2_ndarray[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        tiling.<span class="built_in">set_y_sumndarray</span>(y_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_sumndarray</span>(x1_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_sumndarray</span>(x2_sumndarray);</span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(y_sumndarray[max_dimensional],sizeofdatatype); </span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_x1TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x2TotalLength</span>(totalLength);</span><br><span class="line">        tiling.<span class="built_in">set_x1Size</span>(x1Size);</span><br><span class="line">        tiling.<span class="built_in">set_x2Size</span>(x2Size);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength);</span><br><span class="line">        <span class="comment">// 这里比较关键，这个24是通过实际需要使用多少块空间来计算的</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     </span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        </span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;y_dimensional: %d\n&quot;, max_dimensional);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2TotalLength: %u\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x1Size: %d\n&quot;, x1Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;x2Size: %d\n&quot;, x2Size);</span></span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123; <span class="comment">// 非广播场景</span></span><br><span class="line">        totalLength = <span class="built_in">align32U</span>(totalLength,sizeofdatatype);</span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// if(dt == ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(1);</span></span><br><span class="line">        <span class="comment">// &#125;else&#123;</span></span><br><span class="line">        <span class="comment">//     context-&gt;SetTilingKey(2);</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        <span class="comment">// 这里恰好half的分块数与float一致，感兴趣的可以自己算一下试试看</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength = <span class="built_in">align32D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);     <span class="comment">//向下32对齐的最大长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = totalLength % tileLength;</span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// Gm总地址32B对齐</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// printf(&quot;totalLength: %d\n&quot;, totalLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;tileLength: %d\n&quot;, tileLength);</span></span><br><span class="line">        <span class="comment">// printf(&quot;loopCount: %d\n&quot;, loopCount);</span></span><br><span class="line">        <span class="comment">// printf(&quot;leftNum: %d\n&quot;, leftNum);</span></span><br><span class="line">        <span class="comment">// printf(&quot;ubsize: %d\n&quot;,ub_size);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);  </span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);     </span><br><span class="line">    *y_shape = *x1_shape;  </span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pows</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Pows</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="comment">// 定义第一个输入x1（底数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)  <span class="comment">// 支持的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)  <span class="comment">// 支持的数据格式</span></span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);  </span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义第二个输入x2（指数）</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义输出y</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16, ge::DT_BF16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置形状推理函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置AI Core实现</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);  <span class="comment">// 设置tiling函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>);  <span class="comment">// 添加支持的硬件配置</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(Pows);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关键技术要点"><a href="#关键技术要点" class="headerlink" title="关键技术要点"></a>关键技术要点</h2><ol><li>内存对齐优化 ：使用32字节对齐确保内存访问效率</li><li>UB空间管理 ：根据数据类型和缓冲区数量动态计算tile大小</li><li>广播支持 ：通过维度数组和累积维度数组实现复杂的广播索引计算</li><li>Tiling Key分离 ：根据数据类型和是否广播设置不同的tiling key</li><li>平台适配 ：获取硬件平台信息进行针对性优化</li></ol><h2 id="性能优化策略"><a href="#性能优化策略" class="headerlink" title="性能优化策略"></a>性能优化策略</h2><ol><li>双缓冲机制 ：在非广播场景使用双缓冲提高数据传输效率</li><li>内存对齐 ：确保所有内存访问都是32字节对齐的</li><li>UB空间最大化利用 ：根据实际硬件UB大小动态计算最优tile长度</li><li>数据类型优化 ：针对不同精度类型采用不同的计算策略</li><li>广播优化 ：在广播场景下使用专门的索引计算逻辑</li></ol><h1 id="SelectV2算子实现详解"><a href="#SelectV2算子实现详解" class="headerlink" title="SelectV2算子实现详解"></a>SelectV2算子实现详解</h1><h2 id="算子概述-1"><a href="#算子概述-1" class="headerlink" title="算子概述"></a>算子概述</h2><p>SelectV2算子是一个条件选择算子，根据布尔条件张量从两个输入张量中选择对应元素。该算子支持广播机制，能够处理不同形状的输入张量。算子的核心功能是：当条件为True时选择x1中的元素，当条件为False时选择x2中的元素。</p><h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p>SelectV2算子的数学表达式为：<code>y[i] = condition[i] ? x1[i] : x2[i]</code></p><h2 id="kernel侧实现-1"><a href="#kernel侧实现-1" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><h3 id="1-完成select-v2-cpp文件-这里是算子的入口"><a href="#1-完成select-v2-cpp文件-这里是算子的入口" class="headerlink" title="1. 完成select_v2.cpp文件,这里是算子的入口"></a>1. 完成select_v2.cpp文件,这里是算子的入口</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span>  <span class="comment">// AscendC核心算子开发框架</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2.h&quot;</span>        <span class="comment">// 非广播场景的SelectV2算子实现</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2b.h&quot;</span>       <span class="comment">// 广播场景的SelectV2算子实现</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 算子入口函数，使用extern &quot;C&quot;确保C++函数能被C代码调用</span></span><br><span class="line"><span class="comment">// __global__表示这是一个设备端函数，__aicore__表示运行在AI Core上</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">select_v2</span><span class="params">(GM_ADDR c, GM_ADDR x1, GM_ADDR x2, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    TPipe pipe;  <span class="comment">// 这里有个细节，建议在最开始就定义好pipe对象，然后通过传参数</span></span><br><span class="line">                 <span class="comment">// 再进到Init中，有一定性能优化</span></span><br><span class="line">    <span class="comment">// 根据tiling key选择不同的实现策略</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">1</span>))&#123;  <span class="comment">// tiling key为1：非广播场景</span></span><br><span class="line">        KernelSelectV2 op;  <span class="comment">// 创建非广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(c,x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(<span class="built_in">TILING_KEY_IS</span>(<span class="number">2</span>))&#123;  <span class="comment">// tiling key为2：广播场景</span></span><br><span class="line">        KernelSelectV2BroadCast op;  <span class="comment">// 创建广播算子实例</span></span><br><span class="line">        op.<span class="built_in">Init</span>(c,x1,x2, y, tiling,&amp;pipe);  <span class="comment">// 初始化算子参数</span></span><br><span class="line">        op.<span class="built_in">Process</span>();  <span class="comment">// 执行算子计算</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-非广播场景实现-select-v2-h"><a href="#2-非广播场景实现-select-v2-h" class="headerlink" title="2. 非广播场景实现 (select_v2.h)"></a>2. 非广播场景实现 (select_v2.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;  <span class="comment">// 双缓冲机制，提高数据传输效率</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非广播场景的SelectV2算子实现类（tiling key 1）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSelectV2</span>&#123; <span class="comment">// tiling key 1 正常情况不用广播</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSelectV2</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化tiling参数，从host侧传递的tiling数据中获取分块信息</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);  <span class="comment">// 获取tiling数据结构</span></span><br><span class="line">        totalLength = tiling_data.totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;    <span class="comment">// 每个tile的长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;      <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;          <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化算子，设置全局内存地址和缓冲区</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR c,GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);  <span class="comment">// 初始化tiling参数</span></span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);  <span class="comment">// 确保block数量不为0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置全局内存缓冲区，将GM地址转换为GlobalTensor</span></span><br><span class="line">        cGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">bool</span>*)c, <span class="keyword">this</span>-&gt;totalLength);      <span class="comment">// 条件张量</span></span><br><span class="line">        x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;totalLength); <span class="comment">// 输入张量x1</span></span><br><span class="line">        x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;totalLength); <span class="comment">// 输入张量x2</span></span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);    <span class="comment">// 输出张量y</span></span><br><span class="line">        </span><br><span class="line">        pipe = pipeIn;  <span class="comment">// 保存pipe指针</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化输入输出队列，使用双缓冲提高效率</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueC, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">bool</span>));      <span class="comment">// 条件队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX1, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X1)); <span class="comment">// x1输入队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(inQueueX2, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_X2)); <span class="comment">// x2输入队列</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));  <span class="comment">// 输出队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化临时缓冲区，用于条件处理</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(zeroBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));  <span class="comment">// 零值缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(cBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));     <span class="comment">// 条件转换缓冲区</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型初始化不同的临时缓冲区</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int32类型需要转换为float进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int8类型需要转换为half进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 主处理函数，按tile进行循环处理</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 处理完整的tile</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; ++ i) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i,  <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将数据从GM拷贝到UB（32B对齐后的长度）</span></span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 在UB中进行计算</span></span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);   <span class="comment">// 将结果从UB拷回GM</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理剩余的不足一个tile的数据</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据输入函数：从全局内存拷贝数据到本地缓冲区</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 分配本地tensor</span></span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">AllocTensor</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = inQueueC.<span class="built_in">AllocTensor</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 从全局内存拷贝数据到本地tensor</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(cLocal, cGm[progress * <span class="keyword">this</span>-&gt;tileLength], length);   <span class="comment">// 拷贝条件数据</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(x1Local, x1Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length); <span class="comment">// 拷贝x1数据</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(x2Local, x2Gm[progress * <span class="keyword">this</span>-&gt;tileLength], length); <span class="comment">// 拷贝x2数据</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将tensor加入队列</span></span><br><span class="line">        inQueueC.<span class="built_in">EnQue</span>(cLocal);</span><br><span class="line">        inQueueX<span class="number">1.</span><span class="built_in">EnQue</span>(x1Local);</span><br><span class="line">        inQueueX<span class="number">2.</span><span class="built_in">EnQue</span>(x2Local);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算函数：执行条件选择运算</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从队列中取出输入tensor</span></span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = inQueueC.<span class="built_in">DeQue</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = inQueueX<span class="number">1.</span><span class="built_in">DeQue</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = inQueueX<span class="number">2.</span><span class="built_in">DeQue</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 条件处理：将bool类型转换为可用于Select操作的格式</span></span><br><span class="line">        LocalTensor&lt;half&gt; cTmpLocal = cBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        <span class="keyword">auto</span> intc = cLocal.<span class="keyword">template</span> <span class="built_in">ReinterpretCast</span>&lt;<span class="type">uint8_t</span>&gt;();  <span class="comment">// 将bool重新解释为uint8_t</span></span><br><span class="line">        LocalTensor&lt;half&gt; zeroLocal = zeroBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将uint8_t转换为half，然后与0比较生成选择掩码，这里是因为select的掩码只能是half类型</span></span><br><span class="line">        <span class="built_in">Cast</span>(cTmpLocal,intc,RoundMode::CAST_NONE,length);</span><br><span class="line">        <span class="built_in">Duplicate</span>(zeroLocal, <span class="built_in">half</span>(<span class="number">0</span>), length);  <span class="comment">// 填充零值</span></span><br><span class="line">        <span class="built_in">Compare</span>(zeroLocal,cTmpLocal, zeroLocal, CMPMODE::NE, length);  <span class="comment">// 生成选择掩码</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型执行不同的选择操作</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// float和half类型可以直接使用Select操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yLocal,zeroLocal,x1Local,x2Local,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int8类型需要先转换为half进行Select操作</span></span><br><span class="line">            LocalTensor&lt;half&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int32类型需要先转换为float进行Select操作</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 释放输入tensor</span></span><br><span class="line">        inQueueC.<span class="built_in">FreeTensor</span>(cLocal);</span><br><span class="line">        inQueueX<span class="number">1.F</span>reeTensor(x1Local);</span><br><span class="line">        inQueueX<span class="number">2.F</span>reeTensor(x2Local);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 数据输出函数：将计算结果从本地缓冲区拷贝到全局内存</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">        outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 队列和缓冲区定义</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueC;   <span class="comment">// 条件输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX1;  <span class="comment">// x1输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX2;  <span class="comment">// x2输入队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY; <span class="comment">// 输出队列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 全局内存tensor</span></span><br><span class="line">    GlobalTensor&lt;<span class="type">bool</span>&gt; cGm;      <span class="comment">// 条件张量</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X1&gt; x1Gm; <span class="comment">// 输入张量x1</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X2&gt; x2Gm; <span class="comment">// 输入张量x2</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_Y&gt; yGm;   <span class="comment">// 输出张量y</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 临时缓冲区（用于类型转换和条件处理）</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;  <span class="comment">// 临时缓冲区1</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;  <span class="comment">// 临时缓冲区2</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;  <span class="comment">// 临时缓冲区3</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; zeroBuffer;  <span class="comment">// 零值缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; cBuffer;     <span class="comment">// 条件转换缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 管道和参数</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    <span class="type">uint64_t</span> totalLength;  <span class="comment">// 总数据长度</span></span><br><span class="line">    <span class="type">uint64_t</span> tileLength;   <span class="comment">// 每个tile长度</span></span><br><span class="line">    <span class="type">uint64_t</span> loopCount;    <span class="comment">// 循环次数</span></span><br><span class="line">    <span class="type">uint64_t</span> leftNum;      <span class="comment">// 剩余数据长度</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="3-广播场景实现-select-v2b-h"><a href="#3-广播场景实现-select-v2b-h" class="headerlink" title="3. 广播场景实现 (select_v2b.h)"></a>3. 广播场景实现 (select_v2b.h)</h3><p>广播场景的实现更加复杂，需要处理不同形状的输入张量。主要特点：</p><ul><li>支持多维张量的广播机制</li><li>动态计算每个输出元素对应的输入元素索引</li><li>逐元素计算，适用于形状不匹配的情况</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 广播场景的SelectV2算子实现类（tiling key 2）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelSelectV2BroadCast</span>&#123;  <span class="comment">// 非对齐 广播case</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelSelectV2BroadCast</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化广播相关的tiling参数</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling); </span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出张量的维度信息</span></span><br><span class="line">        y_dimensional = tiling_data.y_dimensional;  <span class="comment">// 输出张量维度数</span></span><br><span class="line">        y_ndarray = tiling_data.y_ndarray;          <span class="comment">// 输出张量各维度大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输入张量的维度信息</span></span><br><span class="line">        c_ndarray = tiling_data.c_ndarray;          <span class="comment">// 条件张量各维度大小</span></span><br><span class="line">        x1_ndarray = tiling_data.x1_ndarray;        <span class="comment">// 输入x1各维度大小</span></span><br><span class="line">        x2_ndarray = tiling_data.x2_ndarray;        <span class="comment">// 输入x2各维度大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 累积维度信息，用于索引计算</span></span><br><span class="line">        y_sumndarray = tiling_data.y_sumndarray;    <span class="comment">// 输出张量累积维度</span></span><br><span class="line">        c_sumndarray = tiling_data.c_sumndarray;    <span class="comment">// 条件张量累积维度</span></span><br><span class="line">        x1_sumndarray = tiling_data.x1_sumndarray;  <span class="comment">// 输入x1累积维度</span></span><br><span class="line">        x2_sumndarray = tiling_data.x2_sumndarray;  <span class="comment">// 输入x2累积维度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 张量长度信息</span></span><br><span class="line">        cSize = tiling_data.cSize;                  <span class="comment">// 条件张量大小</span></span><br><span class="line">        x1Size = tiling_data.x1Size;                <span class="comment">// x1张量大小</span></span><br><span class="line">        x2Size = tiling_data.x2Size;                <span class="comment">// x2张量大小</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 分块信息</span></span><br><span class="line">        totalLength = tiling_data.totalLength;      <span class="comment">// 输出总长度</span></span><br><span class="line">        tileLength = tiling_data.tileLength;        <span class="comment">// 每个tile长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;          <span class="comment">// 循环次数</span></span><br><span class="line">        leftNum = tiling_data.leftNum;              <span class="comment">// 剩余数据长度</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化广播算子</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR c,GM_ADDR x1,GM_ADDR x2, GM_ADDR y,GM_ADDR tiling,TPipe* pipeIn)</span></span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置全局内存缓冲区，注意各张量的长度可能不同</span></span><br><span class="line">        cGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ <span class="type">bool</span>*)c, <span class="keyword">this</span>-&gt;cSize);           <span class="comment">// 条件张量</span></span><br><span class="line">        x1Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x1,<span class="keyword">this</span>-&gt;x1Size);    <span class="comment">// 输入x1张量</span></span><br><span class="line">        x2Gm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_X1*)x2,<span class="keyword">this</span>-&gt;x2Size);    <span class="comment">// 输入x2张量</span></span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_Y*)y,<span class="keyword">this</span>-&gt;totalLength);  <span class="comment">// 输出张量</span></span><br><span class="line">        </span><br><span class="line">        pipe = pipeIn;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 初始化临时缓冲区（广播场景不使用队列，而是直接使用缓冲区）</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(outQueueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));</span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(zeroBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));   <span class="comment">// 零值缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(cBuffer,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));      <span class="comment">// 条件转换缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferC,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y)); <span class="comment">// 条件临时缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX1,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));<span class="comment">// x1临时缓冲区</span></span><br><span class="line">        pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBufferX2,<span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_Y));<span class="comment">// x2临时缓冲区</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型初始化不同的临时缓冲区</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int32类型需要转换为float进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int8类型需要转换为half进行Select操作</span></span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">            pipe-&gt;<span class="built_in">InitBuffer</span>(tmpBuffer3, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(half));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 广播场景的主处理函数</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取临时缓冲区用于存储广播后的数据</span></span><br><span class="line">        LocalTensor&lt;<span class="type">bool</span>&gt; cLocal = tmpBufferC.<span class="built_in">Get</span>&lt;<span class="type">bool</span>&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X1&gt; x1Local = tmpBufferX<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_X1&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_X2&gt; x2Local = tmpBufferX<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_X2&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 按tile处理数据</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; i ++) &#123;               </span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLength,cLocal,x1Local,x2Local);           </span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理剩余数据</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftNum &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum,cLocal,x1Local,x2Local);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftNum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 广播场景的计算函数：逐元素计算广播索引</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">uint32_t</span> progress, <span class="type">uint32_t</span> length,LocalTensor&lt;<span class="type">bool</span>&gt; cLocal,LocalTensor&lt;DTYPE_X1&gt; x1Local,LocalTensor&lt;DTYPE_X2&gt; x2Local)</span> </span>&#123; </span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="type">uint32_t</span> offset = progress * <span class="keyword">this</span>-&gt;tileLength;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 逐元素处理，计算每个输出元素对应的输入元素索引</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">uint32_t</span> j = <span class="number">0</span>;j &lt; length;j ++)&#123;</span><br><span class="line">            <span class="type">uint32_t</span> c_start = <span class="number">0</span>;   <span class="comment">// 条件张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> x1_start = <span class="number">0</span>;  <span class="comment">// x1张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> x2_start = <span class="number">0</span>;  <span class="comment">// x2张量的起始索引</span></span><br><span class="line">            <span class="type">uint32_t</span> index = j + offset;  <span class="comment">// 当前输出元素的全局索引</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 根据广播规则计算输入索引</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">uint32_t</span> k = <span class="number">0</span>; k &lt; <span class="keyword">this</span>-&gt;y_dimensional;k ++)&#123;</span><br><span class="line">                <span class="comment">// 如果条件张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;c_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    c_start += <span class="keyword">this</span>-&gt;c_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果x1张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;x1_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    x1_start += <span class="keyword">this</span>-&gt;x1_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果x2张量在第k维不为1，则需要计算对应的索引</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">this</span>-&gt;x2_ndarray[k] != <span class="number">1</span>)&#123;</span><br><span class="line">                    x2_start += <span class="keyword">this</span>-&gt;x2_sumndarray[k] * (index / <span class="keyword">this</span>-&gt;y_sumndarray[k] % <span class="keyword">this</span>-&gt;y_ndarray[k]);  </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 从全局内存获取对应位置的值</span></span><br><span class="line">            <span class="keyword">auto</span> c = cGm.<span class="built_in">GetValue</span>(c_start);   <span class="comment">// 获取条件值</span></span><br><span class="line">            <span class="keyword">auto</span> x1 = x1Gm.<span class="built_in">GetValue</span>(x1_start); <span class="comment">// 获取x1值</span></span><br><span class="line">            <span class="keyword">auto</span> x2 = x2Gm.<span class="built_in">GetValue</span>(x2_start); <span class="comment">// 获取x2值</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将值设置到本地tensor中</span></span><br><span class="line">            cLocal.<span class="built_in">SetValue</span>(j,c);</span><br><span class="line">            x1Local.<span class="built_in">SetValue</span>(j,x1);</span><br><span class="line">            x2Local.<span class="built_in">SetValue</span>(j,x2);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 条件处理：将bool类型转换为可用于Select操作的格式</span></span><br><span class="line">        LocalTensor&lt;half&gt; cTmpLocal = cBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        <span class="keyword">auto</span> intc = cLocal.<span class="keyword">template</span> <span class="built_in">ReinterpretCast</span>&lt;<span class="type">uint8_t</span>&gt;();  <span class="comment">// 将bool重新解释为uint8_t</span></span><br><span class="line">        LocalTensor&lt;half&gt; zeroLocal = zeroBuffer.<span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将uint8_t转换为half，然后与0比较生成选择掩码</span></span><br><span class="line">        <span class="built_in">Cast</span>(cTmpLocal,intc,RoundMode::CAST_NONE,length);</span><br><span class="line">        <span class="built_in">Duplicate</span>(zeroLocal, <span class="built_in">half</span>(<span class="number">0</span>), length);  <span class="comment">// 填充零值</span></span><br><span class="line">        <span class="built_in">Compare</span>(zeroLocal,cTmpLocal, zeroLocal, CMPMODE::NE, length);  <span class="comment">// 生成选择掩码</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型执行不同的选择操作</span></span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">float</span>&gt; || std::is_same_v&lt;DTYPE_X1, half&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// float和half类型可以直接使用Select操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yLocal,zeroLocal,x1Local,x2Local,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="function"><span class="keyword">if</span> <span class="title">constexpr</span> <span class="params">(std::is_same_v&lt;DTYPE_X1, <span class="type">int8_t</span>&gt;)</span></span>&#123;</span><br><span class="line">            <span class="comment">// int8类型需要先转换为half进行Select操作</span></span><br><span class="line">            LocalTensor&lt;half&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            LocalTensor&lt;half&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;half&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> <span class="built_in">constexpr</span> (std::is_same_v&lt;DTYPE_X1, <span class="type">int32_t</span>&gt;)&#123;</span><br><span class="line">            <span class="comment">// int32类型需要先转换为float进行Select操作</span></span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x1TmpLocal = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; x2TmpLocal = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            LocalTensor&lt;<span class="type">float</span>&gt; yTmpLocal = tmpBuffer<span class="number">3.</span><span class="built_in">Get</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 类型转换</span></span><br><span class="line">            <span class="built_in">Cast</span>(x1TmpLocal,x1Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            <span class="built_in">Cast</span>(x2TmpLocal,x2Local,RoundMode::CAST_NONE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 执行选择操作</span></span><br><span class="line">            <span class="built_in">Select</span>(yTmpLocal,zeroLocal,x1TmpLocal,x2TmpLocal,SELMODE::VSEL_TENSOR_TENSOR_MODE,length);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 转换回原始类型</span></span><br><span class="line">            <span class="built_in">Cast</span>(yLocal,yTmpLocal,RoundMode::CAST_RINT,length);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        outQueueY.<span class="built_in">EnQue</span>&lt;DTYPE_Y&gt;(yLocal);  <span class="comment">// 将结果加入输出队列</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出函数：将结果拷贝到全局内存</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">uint32_t</span> length)</span> </span>&#123;  <span class="comment">// 原始地址 输出</span></span><br><span class="line">        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.<span class="built_in">DeQue</span>&lt;DTYPE_Y&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(yGm[progress * <span class="keyword">this</span>-&gt;tileLength], yLocal, length);</span><br><span class="line">        outQueueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 输出队列</span></span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 全局内存tensor</span></span><br><span class="line">    GlobalTensor&lt;<span class="type">bool</span>&gt; cGm;      <span class="comment">// 条件张量</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X1&gt; x1Gm; <span class="comment">// 输入张量x1</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_X2&gt; x2Gm; <span class="comment">// 输入张量x2</span></span><br><span class="line">    GlobalTensor&lt;DTYPE_Y&gt; yGm;   <span class="comment">// 输出张量y</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 临时计算缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1;   <span class="comment">// 临时缓冲区1</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer2;   <span class="comment">// 临时缓冲区2</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer3;   <span class="comment">// 临时缓冲区3</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferC;   <span class="comment">// 条件临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX1;  <span class="comment">// x1临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBufferX2;  <span class="comment">// x2临时缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; zeroBuffer;   <span class="comment">// 零值缓冲区</span></span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; cBuffer;      <span class="comment">// 条件转换缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 管道和基本参数</span></span><br><span class="line">    TPipe* pipe;</span><br><span class="line">    <span class="type">uint64_t</span> totalLength;   <span class="comment">// 输出总长度</span></span><br><span class="line">    <span class="type">uint64_t</span> tileLength;    <span class="comment">// tile长度</span></span><br><span class="line">    <span class="type">uint64_t</span> loopCount;     <span class="comment">// 循环次数</span></span><br><span class="line">    <span class="type">uint64_t</span> leftNum;       <span class="comment">// 剩余长度</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 广播相关参数</span></span><br><span class="line">    <span class="type">uint32_t</span> y_dimensional;     <span class="comment">// 输出维度数</span></span><br><span class="line">    <span class="type">uint32_t</span> *c_sumndarray;     <span class="comment">// 条件张量累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *x1_sumndarray;    <span class="comment">// x1累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *x2_sumndarray;    <span class="comment">// x2累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> *y_ndarray;        <span class="comment">// 输出各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *c_ndarray;        <span class="comment">// 条件张量各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *x1_ndarray;       <span class="comment">// x1各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *x2_ndarray;       <span class="comment">// x2各维度大小</span></span><br><span class="line">    <span class="type">uint32_t</span> *y_sumndarray;     <span class="comment">// 输出累积维度数组</span></span><br><span class="line">    <span class="type">uint32_t</span> cSize;             <span class="comment">// 条件张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size;            <span class="comment">// x1张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x2Size;            <span class="comment">// x2张量大小</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="host侧实现-1"><a href="#host侧实现-1" class="headerlink" title="host侧实现"></a>host侧实现</h2><p>host侧主要负责算子的注册、形状推理、tiling策略计算等功能。包含以下几个关键部分：</p><h3 id="1-Tiling数据结构定义-select-v2-tiling-h"><a href="#1-Tiling数据结构定义-select-v2-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (select_v2_tiling.h)"></a>1. Tiling数据结构定义 (select_v2_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(SelectV2TilingData)</span><br><span class="line">   <span class="comment">// 基础分块参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, totalLength);    <span class="comment">// 总数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, loopCount);      <span class="comment">// 循环次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, leftNum);        <span class="comment">// 剩余数据长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint64_t</span>, tileLength);     <span class="comment">// 每个tile的长度</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 广播相关参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, y_dimensional);  <span class="comment">// 输出张量维度数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1TotalLength);  <span class="comment">// x1总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2TotalLength);  <span class="comment">// x2总长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x1Size);         <span class="comment">// x1大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, x2Size);         <span class="comment">// x2大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 维度数组（最大支持20维）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_ndarray);   <span class="comment">// 输出各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_ndarray);  <span class="comment">// x1各维度大小</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_ndarray);  <span class="comment">// x2各维度大小</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 累积维度数组（用于索引计算）</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, y_sumndarray);  <span class="comment">// 输出累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x1_sumndarray); <span class="comment">// x1累积维度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF_ARR</span>(<span class="type">uint32_t</span>, <span class="number">20</span>, x2_sumndarray); <span class="comment">// x2累积维度</span></span><br><span class="line"></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(SelectV2, SelectV2TilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-select-v2-cpp"><a href="#2-Tiling策略计算-select-v2-cpp" class="headerlink" title="2. Tiling策略计算 (select_v2.cpp)"></a>2. Tiling策略计算 (select_v2.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SelectV2算子的host侧实现文件</span></span><br><span class="line"><span class="comment">// 功能：根据条件张量condition选择x1或x2中的元素</span></span><br><span class="line"><span class="comment">// 支持广播机制和多种数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;select_v2_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 向上128字节对齐函数</span></span><br><span class="line"><span class="comment">// 参数：n - 元素个数，DataType - 数据类型字节数</span></span><br><span class="line"><span class="comment">// 返回：对齐后的元素个数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align128U</span><span class="params">(<span class="type">uint32_t</span> n,<span class="type">uint32_t</span> DataType)</span></span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> ((n + <span class="number">127</span>) &amp; ~<span class="number">127</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向下128字节对齐函数</span></span><br><span class="line"><span class="comment">// 参数：n - 元素个数，DataType - 数据类型字节数</span></span><br><span class="line"><span class="comment">// 返回：对齐后的元素个数</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">uint32_t</span> <span class="title">align128D</span><span class="params">(<span class="type">uint32_t</span> n, <span class="type">uint32_t</span> DataType)</span> </span>&#123;</span><br><span class="line">    n *= DataType;</span><br><span class="line">    <span class="keyword">return</span> (n &amp; ~<span class="number">127</span>) / DataType;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">// SelectV2算子的Tiling函数</span></span><br><span class="line"><span class="comment">// 功能：计算算子执行所需的tiling参数，包括内存分配、循环次数等</span></span><br><span class="line"><span class="comment">// 支持两种模式：1-非广播模式，2-广播模式</span></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 初始化tiling数据结构</span></span><br><span class="line">    SelectV2TilingData tiling;</span><br><span class="line">    <span class="type">uint64_t</span> sizeofdatatype;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取平台信息和硬件资源</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> socVersion = ascendcPlatform.<span class="built_in">GetSocVersion</span>();</span><br><span class="line">    <span class="type">uint64_t</span> ub_size;</span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNum</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取输入张量的总长度（以x1为基准）</span></span><br><span class="line">    <span class="type">uint64_t</span> totalLength = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 根据数据类型确定每个元素的字节数</span></span><br><span class="line">    <span class="keyword">auto</span> dt = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">1</span>;  <span class="comment">// int8: 1字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt== ge::DT_FLOAT16 || dt == ge::DT_BF16)&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">2</span>;  <span class="comment">// float16/bfloat16: 2字节</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        sizeofdatatype = <span class="number">4</span>;  <span class="comment">// float32/int32: 4字节</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取三个输入张量的大小</span></span><br><span class="line">    <span class="type">uint32_t</span> cSize  = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>();  <span class="comment">// condition张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x1Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// x1张量大小</span></span><br><span class="line">    <span class="type">uint32_t</span> x2Size = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">2</span>)-&gt;<span class="built_in">GetStorageShape</span>().<span class="built_in">GetShapeSize</span>(); <span class="comment">// x2张量大小</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 判断是否需要广播：如果三个张量大小不完全相等，则进入广播模式</span></span><br><span class="line">    <span class="keyword">if</span> (x1Size != x2Size || cSize != x1Size || cSize != x2Size)&#123;  </span><br><span class="line">        <span class="comment">// 设置tiling key为2，表示广播模式</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 定义各张量的维度数组（最大支持20维）</span></span><br><span class="line">        <span class="type">uint32_t</span> y_ndarray[<span class="number">20</span>], c_ndarray[<span class="number">20</span>], x1_ndarray[<span class="number">20</span>], x2_ndarray[<span class="number">20</span>];</span><br><span class="line">        <span class="type">uint32_t</span> y_dimensional, c_dimensional, x1_dimensional, x2_dimensional;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 获取各张量的原始形状信息</span></span><br><span class="line">        <span class="keyword">auto</span> shape_y  = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_c = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x1 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        <span class="keyword">auto</span> shape_x2 = context-&gt;<span class="built_in">GetInputTensor</span>(<span class="number">2</span>)-&gt;<span class="built_in">GetOriginShape</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 获取各张量的维度数</span></span><br><span class="line">        y_dimensional = shape_y.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        c_dimensional = shape_c.<span class="built_in">GetDimNum</span>();</span><br><span class="line">        x1_dimensional = shape_x<span class="number">1.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line">        x2_dimensional = shape_x<span class="number">2.</span><span class="built_in">GetDimNum</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到最大维度数，用于统一处理</span></span><br><span class="line">        <span class="type">uint32_t</span> max_dimensional = y_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (c_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = c_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x1_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x1_dimensional;</span><br><span class="line">        <span class="keyword">if</span> (x2_dimensional &gt; max_dimensional)</span><br><span class="line">            max_dimensional = x2_dimensional;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">// 将各张量的维度信息填充到统一长度的数组中</span></span><br><span class="line">        <span class="comment">// 不足的维度用1填充，实现维度对齐</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; max_dimensional; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; y_dimensional) &#123;</span><br><span class="line">                y_ndarray[y_dimensional - i - <span class="number">1</span>] = shape_y.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                y_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt;c_dimensional) &#123;</span><br><span class="line">                c_ndarray[c_dimensional - i - <span class="number">1</span>] = shape_c.<span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                c_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x1_dimensional) &#123;</span><br><span class="line">                x1_ndarray[x1_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">1.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x1_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i &lt; x2_dimensional) &#123;</span><br><span class="line">                x2_ndarray[x2_dimensional - i - <span class="number">1</span>] = shape_x<span class="number">2.</span><span class="built_in">GetDim</span>(i);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                x2_ndarray[i] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置维度信息到tiling数据中</span></span><br><span class="line">        tiling.<span class="built_in">set_y_dimensional</span>(max_dimensional);</span><br><span class="line">        tiling.<span class="built_in">set_y_ndarray</span>(y_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_c_ndarray</span>(c_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_ndarray</span>(x1_ndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_ndarray</span>(x2_ndarray);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算各张量的累积维度数组，用于广播时的索引计算</span></span><br><span class="line">        <span class="type">uint32_t</span> y_sumndarray[<span class="number">20</span>], c_sumndarray[<span class="number">20</span>],x1_sumndarray[<span class="number">20</span>], x2_sumndarray[<span class="number">20</span>];</span><br><span class="line">        y_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        c_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x1_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        x2_sumndarray[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算累积乘积，用于多维索引转换为一维索引</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">1</span>; i &lt;= max_dimensional; i++)&#123;</span><br><span class="line">            y_sumndarray[i] = y_sumndarray[i - <span class="number">1</span>] * y_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            c_sumndarray[i] = c_sumndarray[i - <span class="number">1</span>] * c_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x1_sumndarray[i] = x1_sumndarray[i - <span class="number">1</span>] * x1_ndarray[i - <span class="number">1</span>];</span><br><span class="line">            x2_sumndarray[i] = x2_sumndarray[i - <span class="number">1</span>] * x2_ndarray[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置累积维度数组到tiling数据中</span></span><br><span class="line">        tiling.<span class="built_in">set_y_sumndarray</span>(y_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_c_sumndarray</span>(c_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x1_sumndarray</span>(x1_sumndarray);</span><br><span class="line">        tiling.<span class="built_in">set_x2_sumndarray</span>(x2_sumndarray);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算对齐后的总长度</span></span><br><span class="line">        totalLength = <span class="built_in">align128U</span>(y_sumndarray[max_dimensional],sizeofdatatype); </span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置各张量的对齐大小</span></span><br><span class="line">        tiling.<span class="built_in">set_cSize</span>(<span class="built_in">align128U</span>(cSize,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_x1Size</span>(<span class="built_in">align128U</span>(x1Size,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_x2Size</span>(<span class="built_in">align128U</span>(x2Size,sizeofdatatype));</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据数据类型计算每个tile的长度</span></span><br><span class="line">        <span class="comment">// 考虑UB内存限制和不同数据类型的内存占用</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength;</span><br><span class="line">        <span class="keyword">if</span>(dt == ge::DT_FLOAT16)&#123;        <span class="comment">// fp16: 需要更少的内存</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">14</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT)&#123;    <span class="comment">// fp32: 需要更多内存</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT32)&#123;     <span class="comment">// int32: 转换为fp32处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">36</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;      <span class="comment">// int8: 转换为fp16处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">20</span>,sizeofdatatype);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保tile长度不超过总长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 计算循环次数和剩余元素数量</span></span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = <span class="built_in">align128U</span>(totalLength % tileLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置tiling参数</span></span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        </span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">// 非广播模式：所有张量大小相等</span></span><br><span class="line">        context-&gt;<span class="built_in">SetTilingKey</span>(<span class="number">1</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对总长度进行128字节对齐</span></span><br><span class="line">        totalLength = <span class="built_in">align128U</span>(totalLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 根据数据类型计算tile长度</span></span><br><span class="line">        <span class="type">uint32_t</span> tileLength;</span><br><span class="line">        <span class="keyword">if</span>(dt == ge::DT_FLOAT16)&#123;        <span class="comment">// fp16: 内存占用较少</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">18</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_FLOAT)&#123;    <span class="comment">// fp32: 内存占用较多</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">30</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT32)&#123;     <span class="comment">// int32: 转换为fp32处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">42</span>,sizeofdatatype);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(dt == ge::DT_INT8)&#123;      <span class="comment">// int8: 转换为fp16处理</span></span><br><span class="line">            tileLength = <span class="built_in">align128D</span>(ub_size / <span class="number">24</span>,sizeofdatatype);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确保tile长度不超过总长度</span></span><br><span class="line">        tileLength = std::<span class="built_in">min</span>((<span class="type">int</span>)tileLength,<span class="built_in">int</span>(totalLength));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算循环次数和剩余元素数量</span></span><br><span class="line">        <span class="type">uint32_t</span> loopCount = totalLength / tileLength;</span><br><span class="line">        <span class="type">uint32_t</span> leftNum = <span class="built_in">align128U</span>(totalLength % tileLength,sizeofdatatype);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置tiling参数</span></span><br><span class="line">        tiling.<span class="built_in">set_tileLength</span>(tileLength);</span><br><span class="line">        tiling.<span class="built_in">set_loopCount</span>(loopCount);</span><br><span class="line">        tiling.<span class="built_in">set_leftNum</span>(leftNum);</span><br><span class="line">        tiling.<span class="built_in">set_totalLength</span>(totalLength); <span class="comment">// GM总地址128B对齐</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置单核执行</span></span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(<span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 保存tiling数据到上下文</span></span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(), context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置工作空间大小（SelectV2不需要额外工作空间）</span></span><br><span class="line">    <span class="type">size_t</span>* currentWorkspace = context-&gt;<span class="built_in">GetWorkspaceSizes</span>(<span class="number">1</span>);</span><br><span class="line">    currentWorkspace[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="comment">// SelectV2算子的形状推理函数</span></span><br><span class="line"><span class="comment">// 功能：根据输入张量的形状推导输出张量的形状</span></span><br><span class="line"><span class="comment">// SelectV2的输出形状与x1的形状相同</span></span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 获取x1张量的形状</span></span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 获取输出张量的形状指针</span></span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 设置输出形状与x1相同</span></span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="comment">// SelectV2算子定义类</span></span><br><span class="line"><span class="comment">// 功能：定义算子的输入输出规格、数据类型、格式等信息</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelectV2</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">SelectV2</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name)</span></span><br><span class="line"><span class="function">    &#123;</span></span><br><span class="line">        <span class="comment">// 定义condition输入：布尔类型的条件张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;condition&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_BOOL, ge::DT_BOOL, ge::DT_BOOL, ge::DT_BOOL&#125;)  <span class="comment">// 支持布尔类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)  <span class="comment">// 支持ND格式</span></span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义x1输入：第一个选择张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 支持多种数值类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义x2输入：第二个选择张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 与x1相同的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">            </span><br><span class="line">        <span class="comment">// 定义y输出：选择结果张量</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)  <span class="comment">// 必需参数</span></span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT16, ge::DT_FLOAT, ge::DT_INT32, ge::DT_INT8&#125;)  <span class="comment">// 与输入相同的数据类型</span></span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置形状推理函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置AI Core执行参数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>()</span><br><span class="line">            .<span class="built_in">SetTiling</span>(optiling::TilingFunc);  <span class="comment">// 设置tiling函数</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend310b&quot;</span>);  <span class="comment">// 支持ascend310b芯片</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册SelectV2算子</span></span><br><span class="line"><span class="built_in">OP_ADD</span>(SelectV2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="关键技术要点-1"><a href="#关键技术要点-1" class="headerlink" title="关键技术要点"></a>关键技术要点</h2><h3 id="1-条件处理机制-："><a href="#1-条件处理机制-：" class="headerlink" title="1.条件处理机制 ："></a>1.条件处理机制 ：</h3><ul><li>将bool类型的条件重新解释为uint8_t</li><li>转换为half类型后与零值比较生成选择掩码</li><li>使用Compare操作生成适用于Select的掩码</li></ul><h3 id="2-数据类型适配-："><a href="#2-数据类型适配-：" class="headerlink" title="2.数据类型适配 ："></a>2.数据类型适配 ：</h3><ul><li>float和half类型直接支持Select操作</li><li>int8_t和int32_t需要先转换为half/float，执行Select后再转换回原类型</li></ul><h3 id="3-广播索引计算-："><a href="#3-广播索引计算-：" class="headerlink" title="3.广播索引计算 ："></a>3.广播索引计算 ：</h3><ul><li>根据输出索引和各维度信息计算对应的输入索引</li><li>支持任意维度的广播规则</li><li>逐元素处理确保广播语义正确</li></ul><h3 id="4-内存管理优化-："><a href="#4-内存管理优化-：" class="headerlink" title="4.内存管理优化 ："></a>4.内存管理优化 ：</h3><ul><li>非广播场景使用双缓冲队列提高数据传输效率</li><li>广播场景使用临时缓冲区减少内存拷贝开销</li><li>根据数据类型动态分配临时缓冲区</li></ul><h1 id="AddLayerNorm算子实现详解"><a href="#AddLayerNorm算子实现详解" class="headerlink" title="AddLayerNorm算子实现详解"></a>AddLayerNorm算子实现详解</h1><p>LayerNorm算子在深度学习，以及大语言模型中的应用及其广泛，其主要作用是对输入进行归一化处理，以提高模型的泛化能力和训练效率。而AddLayerNorm算子的应用场景与其类似，在进行LayerNorm操作前，有些时候会使用一些残差连接，这个时候就可以进行算子的融合，来提升模型在整网中的性能</p><h2 id="算法原理-1"><a href="#算法原理-1" class="headerlink" title="算法原理"></a>算法原理</h2><p>AddLayerNorm算子的数学表达式为：<br><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>z</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>x</mi><mo>+</mo><mtext>y</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>μ</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>C</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>z</mi><mi>i</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>σ</mi><mn>2</mn></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>C</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>y</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>z</mi><mo>−</mo><mi>μ</mi></mrow><msqrt><mrow><msup><mi>σ</mi><mn>2</mn></msup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mo>⊙</mo><mi>γ</mi><mo>+</mo><mi>β</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} z &amp;= x + \text{y} \\ \mu &amp;= \frac{1}{C} \sum_{i=1}^{C} z_i \\ \sigma^2 &amp;= \frac{1}{C} \sum_{i=1}^{C} (z_i - \mu)^2 \\ y &amp;= \frac{z - \mu}{\sqrt{\sigma^2 + \epsilon}} \odot \gamma + \beta \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:10.8023em;vertical-align:-5.1512em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6512em"><span style="top:-8.6395em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span></span></span><span style="top:-6.1512em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal">μ</span></span></span><span style="top:-2.7452em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:.0928em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.1512em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6512em"><span style="top:-8.6395em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord text"><span class="mord">y</span></span></span></span><span style="top:-6.1512em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.044em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.7452em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.044em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:.0928em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603em"><span style="top:-2.1966em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9134em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7401em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.8734em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1266em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.04398em">z</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord mathnormal" style="margin-right:.05556em">γ</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord mathnormal" style="margin-right:.05278em">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.1512em"><span></span></span></span></span></span></span></span></span></span></span></p><h2 id="算子实现"><a href="#算子实现" class="headerlink" title="算子实现"></a>算子实现</h2><h2 id="kernel侧实现-2"><a href="#kernel侧实现-2" class="headerlink" title="kernel侧实现"></a>kernel侧实现</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel_operator.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> AscendC;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DTYPE_IN&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KernelAddLayerNorm</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="title">KernelAddLayerNorm</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">InitTiling</span><span class="params">(GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">GET_TILING_DATA</span>(tiling_data, tiling);</span><br><span class="line">        rowNum = tiling_data.rowNum;        <span class="comment">// 单核处理的 行数 小块</span></span><br><span class="line">        rowNumSp = tiling_data.rowNumSp;    <span class="comment">// 大块行数</span></span><br><span class="line">        rowLength = tiling_data.rowLength;  <span class="comment">// 每行长度</span></span><br><span class="line">        blockPivot = tiling_data.blockPivot;<span class="comment">// 大核数量</span></span><br><span class="line">        tileLoop = tiling_data.tileLoop;    <span class="comment">// 核内分块 每小块行数</span></span><br><span class="line">        tileLength = tiling_data.tileLength;<span class="comment">// 单块数据长度</span></span><br><span class="line">        loopCount = tiling_data.loopCount;  <span class="comment">// 单核 循环执行的次数</span></span><br><span class="line">        factor = tiling_data.factor;</span><br><span class="line">        mfactor = tiling_data.mfactor;      <span class="comment">// -1 / n  求均值系数</span></span><br><span class="line">        eps = tiling_data.eps;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Init</span><span class="params">(GM_ADDR x, GM_ADDR y, GM_ADDR gamma, GM_ADDR beta, GM_ADDR z,</span></span></span><br><span class="line"><span class="params"><span class="function">                                GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">InitTiling</span>(tiling);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">ASSERT</span>(<span class="built_in">GetBlockNum</span>() != <span class="number">0</span> &amp;&amp; <span class="string">&quot;block dim can not be zero!&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;leftRow = <span class="keyword">this</span>-&gt;rowNum % <span class="keyword">this</span>-&gt;tileLoop;<span class="comment">// 尾块行数</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetBlockIdx</span>() &lt; <span class="keyword">this</span>-&gt;blockPivot) &#123;</span><br><span class="line">            <span class="comment">// 大核多处理一行</span></span><br><span class="line">            <span class="keyword">this</span>-&gt;rowNum = <span class="keyword">this</span>-&gt;rowNumSp;</span><br><span class="line">            <span class="keyword">this</span>-&gt;leftRow += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;blockLength = <span class="keyword">this</span>-&gt;rowNum * <span class="keyword">this</span>-&gt;rowLength; <span class="comment">// 单核处理的数据量</span></span><br><span class="line">        <span class="type">uint32_t</span> offset = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetBlockIdx</span>() &lt; <span class="keyword">this</span>-&gt;blockPivot) &#123;</span><br><span class="line">            <span class="comment">// 大块 核</span></span><br><span class="line">            offset = <span class="keyword">this</span>-&gt;blockLength * <span class="built_in">GetBlockIdx</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 小核的数据偏移量</span></span><br><span class="line">            <span class="comment">// 每个大核多处理一行，总共 blockPivot 个大核，每行长度 rowLength</span></span><br><span class="line">            <span class="comment">// 大核总共多处理了 this-&gt;rowLength * this-&gt;blockPivot 数据量</span></span><br><span class="line">            offset = <span class="keyword">this</span>-&gt;blockLength * <span class="built_in">GetBlockIdx</span>() +</span><br><span class="line">            <span class="keyword">this</span>-&gt;rowLength * <span class="keyword">this</span>-&gt;blockPivot;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 当前核 输入输出数据偏移</span></span><br><span class="line">        xGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)x + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        yGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)y + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        zGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)z + offset, <span class="keyword">this</span>-&gt;blockLength);</span><br><span class="line">        </span><br><span class="line">        gammaGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)gamma, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        betaGm.<span class="built_in">SetGlobalBuffer</span>((__gm__ DTYPE_IN *)beta, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueX, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueY, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueZ, BUFFER_NUM, <span class="keyword">this</span>-&gt;tileLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(tmpBuffer1, <span class="number">64</span> * <span class="built_in">sizeof</span>(DTYPE_IN)); <span class="comment">// 存每行均值 这里最大 128 行</span></span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(tmpBuffer2, <span class="number">64</span> * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueGamma, BUFFER_NUM, <span class="keyword">this</span>-&gt;rowLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        pipe.<span class="built_in">InitBuffer</span>(queueBeta, BUFFER_NUM, <span class="keyword">this</span>-&gt;rowLength * <span class="built_in">sizeof</span>(DTYPE_IN));</span><br><span class="line">        tmpTensor1 = tmpBuffer<span class="number">1.</span><span class="built_in">Get</span>&lt;DTYPE_IN&gt;(); <span class="comment">//提前申请，避免多次申请带来性能开销</span></span><br><span class="line">        tmpTensor2 = tmpBuffer<span class="number">2.</span><span class="built_in">Get</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 同理，gamma与beta是相同的，就长期留在核心内</span></span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; GammaLocal = queueGamma.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; BetaLocal = queueBeta.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="built_in">DataCopy</span>(GammaLocal, gammaGm[<span class="number">0</span>], <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        <span class="built_in">DataCopy</span>(BetaLocal, betaGm[<span class="number">0</span>], <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        queueGamma.<span class="built_in">EnQue</span>(GammaLocal);</span><br><span class="line">        queueBeta.<span class="built_in">EnQue</span>(BetaLocal);</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; gammaLocal = queueGamma.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; betaLocal = queueBeta.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;loopCount; ++i) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(i, <span class="keyword">this</span>-&gt;tileLoop); <span class="comment">// 每次处理 tileLoop 行</span></span><br><span class="line">            <span class="built_in">Compute</span>(i, <span class="keyword">this</span>-&gt;tileLoop, gammaLocal, betaLocal);</span><br><span class="line">            <span class="built_in">CopyOut</span>(i, <span class="keyword">this</span>-&gt;tileLoop);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 尾块行数</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leftRow &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">CopyIn</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow); <span class="comment">// 最后一次处理 leftRow 行</span></span><br><span class="line">            <span class="built_in">Compute</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow, gammaLocal, betaLocal);</span><br><span class="line">            <span class="built_in">CopyOut</span>(<span class="keyword">this</span>-&gt;loopCount, <span class="keyword">this</span>-&gt;leftRow);</span><br><span class="line">        &#125;</span><br><span class="line">        queueGamma.<span class="built_in">FreeTensor</span>(gammaLocal);</span><br><span class="line">        queueBeta.<span class="built_in">FreeTensor</span>(betaLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 数据拷贝</span></span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyIn</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; xLocal = queueX.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; yLocal = queueY.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">DataCopy</span>(xLocal, xGm[progress * <span class="keyword">this</span>-&gt;tileLength],</span><br><span class="line">                 <span class="keyword">this</span>-&gt;rowLength * rowNum); <span class="comment">// 行数rowNum 每行长度 this-&gt;rowLength</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(yLocal, yGm[progress * <span class="keyword">this</span>-&gt;tileLength],</span><br><span class="line">                 <span class="keyword">this</span>-&gt;rowLength * rowNum);</span><br><span class="line"></span><br><span class="line">        queueX.<span class="built_in">EnQue</span>(xLocal);</span><br><span class="line">        queueY.<span class="built_in">EnQue</span>(yLocal);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum, LocalTensor&lt;DTYPE_IN&gt; gammaLocal, LocalTensor&lt;DTYPE_IN&gt; betaLocal)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; xLocal = queueX.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; yLocal = queueY.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; zLocal = queueZ.<span class="built_in">AllocTensor</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// x = x+y</span></span><br><span class="line">        <span class="built_in">Add</span>(xLocal, xLocal, yLocal, rowNum * <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// t = sum(x)</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="comment">// 求每一行数据的和</span></span><br><span class="line">            <span class="built_in">ReduceSum</span>&lt;DTYPE_IN&gt;(tmpTensor2[j], xLocal[buffIndex], tmpTensor1, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// z = sum * -1/rowLength</span></span><br><span class="line">        <span class="built_in">Muls</span>(zLocal, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;mfactor, rowNum); <span class="comment">// 求 均值 * -1</span></span><br><span class="line">        <span class="comment">// x = x - mean(x)</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="comment">// 减去 均值</span></span><br><span class="line">            <span class="built_in">Adds</span>(xLocal[buffIndex], xLocal[buffIndex], zLocal.<span class="built_in">GetValue</span>(j), <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 平方 z = (x - mean(x)) * (x - mean(x))</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">Mul</span>(zLocal, xLocal, xLocal, <span class="keyword">this</span>-&gt;tileLength);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="comment">// 每行 求 差平方和</span></span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="built_in">ReduceSum</span>&lt;DTYPE_IN&gt;(tmpTensor2[j], zLocal[buffIndex], tmpTensor1, <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">Muls</span>(tmpTensor2, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;factor, rowNum);<span class="comment">// 均值</span></span><br><span class="line">        <span class="built_in">Adds</span>(tmpTensor2, tmpTensor2, (DTYPE_IN)<span class="keyword">this</span>-&gt;eps, rowNum);   <span class="comment">// + eps</span></span><br><span class="line">        <span class="built_in">Sqrt</span>(tmpTensor2, tmpTensor2, rowNum);              <span class="comment">// 开平方</span></span><br><span class="line">        <span class="comment">// 上面得到 均方差  std</span></span><br><span class="line">        <span class="built_in">Duplicate</span>&lt;DTYPE_IN&gt;(tmpTensor1, <span class="number">1.0f</span>, <span class="keyword">this</span>-&gt;tileLoop);</span><br><span class="line">        <span class="built_in">Div</span>(tmpTensor2, tmpTensor1, tmpTensor2, rowNum);    <span class="comment">// 倒数</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 乘倒数 归一化 缩放 平移</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">uint32_t</span> j = <span class="number">0</span>; j &lt; rowNum; ++j) &#123;</span><br><span class="line">            <span class="type">uint32_t</span> buffIndex = j * <span class="keyword">this</span>-&gt;rowLength;</span><br><span class="line">            <span class="built_in">Muls</span>(zLocal[buffIndex], xLocal[buffIndex], tmpTensor<span class="number">2.</span><span class="built_in">GetValue</span>(j), <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">            <span class="built_in">FusedMulAdd</span>(z[buffIndex],gammaLocal,zLocal[buffIndex],betaLocal,<span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        &#125;</span><br><span class="line">        queueZ.<span class="built_in">EnQue</span>&lt;DTYPE_IN&gt;(zLocal);</span><br><span class="line">        queueX.<span class="built_in">FreeTensor</span>(xLocal);</span><br><span class="line">        queueY.<span class="built_in">FreeTensor</span>(yLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">__aicore__ <span class="keyword">inline</span> <span class="type">void</span> <span class="title">CopyOut</span><span class="params">(<span class="type">int32_t</span> progress, <span class="type">int32_t</span> rowNum)</span> </span>&#123;</span><br><span class="line">        LocalTensor&lt;DTYPE_IN&gt; zLocal = queueZ.<span class="built_in">DeQue</span>&lt;DTYPE_IN&gt;();</span><br><span class="line">        <span class="comment">// 拷贝输出</span></span><br><span class="line">        <span class="built_in">DataCopy</span>(zGm[progress * <span class="keyword">this</span>-&gt;tileLength], zLocal, rowNum * <span class="keyword">this</span>-&gt;rowLength);</span><br><span class="line">        queueZ.<span class="built_in">FreeTensor</span>(zLocal);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TPipe pipe;</span><br><span class="line">    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1, tmpBuffer2;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueX;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueY;</span><br><span class="line">    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; queueGamma, queueBeta;</span><br><span class="line">    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; queueZ;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; xGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; yGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; gammaGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; betaGm;</span><br><span class="line">    GlobalTensor&lt;DTYPE_IN&gt; zGm;</span><br><span class="line">    LocalTensor&lt;DTYPE_IN&gt; tmpTensor1 ;</span><br><span class="line">    LocalTensor&lt;DTYPE_IN&gt; tmpTensor2;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint32_t</span> blockLength = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint32_t</span> leftRow = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowNum = <span class="number">341</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowNumSp = <span class="number">342</span>;</span><br><span class="line">    <span class="type">uint32_t</span> rowLength = <span class="number">1024</span>;      <span class="comment">// 每行 1024</span></span><br><span class="line">    <span class="type">uint32_t</span> blockPivot = <span class="number">16</span>;       <span class="comment">// 大核数量</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLoop = <span class="number">8</span>;          <span class="comment">// 每块 8 行</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLength = <span class="number">8</span> * <span class="number">1024</span>; <span class="comment">// 每块数据量  8*1024</span></span><br><span class="line">    <span class="type">uint32_t</span> loopCount = <span class="number">42</span>;</span><br><span class="line">    <span class="type">float</span> factor = <span class="number">0.0009765625</span>;</span><br><span class="line">    <span class="type">float</span> mfactor = <span class="number">-0.0009765625</span>;</span><br><span class="line">    <span class="type">float</span> eps = <span class="number">1e-5</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint32_t</span> coreDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> tileNum;</span><br><span class="line">    <span class="type">uint32_t</span> tileDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> tailDataNum;</span><br><span class="line">    <span class="type">uint32_t</span> processDataNum;</span><br><span class="line">    </span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">__global__ __aicore__ <span class="type">void</span> <span class="title">add_layer_norm_custom</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">                                                            GM_ADDR x, GM_ADDR y, GM_ADDR gamma, GM_ADDR beta, GM_ADDR res_out, GM_ADDR workspace,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                            GM_ADDR tiling)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 编译器会传入参数 DTYPE_X DTYPE_Y DTYPE_GEMMA DTYPE_BETA</span></span><br><span class="line">    KernelAddLayerNorm&lt;DTYPE_X&gt; op;</span><br><span class="line">    op.<span class="built_in">Init</span>(x, y, gamma, beta, res_out, tiling);</span><br><span class="line">    op.<span class="built_in">Process</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="host侧实现-2"><a href="#host侧实现-2" class="headerlink" title="host侧实现"></a>host侧实现</h2><h3 id="1-Tiling数据结构定义-add-layer-norm-tiling-h"><a href="#1-Tiling数据结构定义-add-layer-norm-tiling-h" class="headerlink" title="1. Tiling数据结构定义 (add_layer_norm_tiling.h)"></a>1. Tiling数据结构定义 (add_layer_norm_tiling.h)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/tilingdata_base.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="built_in">BEGIN_TILING_DATA_DEF</span>(AddLayerNormCustomTilingData)</span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowNum);     <span class="comment">// 小块核行数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowNumSp);   <span class="comment">// 大块核行数 = rowNum+1</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, rowLength);  <span class="comment">// 每行长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, blockPivot); <span class="comment">// 大块核心数量</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, tileLoop);   <span class="comment">// 核内分块 每块 行数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, tileLength); <span class="comment">// 核内分块 每块 数据总 长度</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">uint32_t</span>, loopCount);  <span class="comment">// 核内分块 次数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, factor); <span class="comment">// 列数倒数 // 算子参数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, mfactor);<span class="comment">// 负 列数倒数</span></span><br><span class="line">  <span class="built_in">TILING_DATA_FIELD_DEF</span>(<span class="type">float</span>, eps);    <span class="comment">// epsilon</span></span><br><span class="line">END_TILING_DATA_DEF;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_TILING_DATA_CLASS</span>(AddLayerNormCustom, AddLayerNormCustomTilingData)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-Tiling策略计算-add-layer-norm-cpp"><a href="#2-Tiling策略计算-add-layer-norm-cpp" class="headerlink" title="2. Tiling策略计算 (add_layer_norm.cpp)"></a>2. Tiling策略计算 (add_layer_norm.cpp)</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;add_layer_norm_custom_tiling.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;register/op_def_registry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/platform/platform_ascendc.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tiling/tiling_api.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> matmul_tiling;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int32_t</span> BUFFER_NUM = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">namespace</span> optiling &#123;</span><br><span class="line"><span class="comment">//const uint32_t BLOCK_DIM = 48; // 48核 需要自适应</span></span><br><span class="line"><span class="type">const</span> <span class="type">uint32_t</span> BLOCK_SIZE = <span class="number">32</span>;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">TilingFunc</span><span class="params">(gert::TilingContext* context)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    AddLayerNormCustomTilingData tiling;</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape = x1_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* x2_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape2 = x2_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="type">const</span> gert::StorageShape* gamma_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="type">const</span> gert::Shape shape3 = gamma_shape-&gt;<span class="built_in">GetStorageShape</span>();</span><br><span class="line">    <span class="comment">// 维度校验</span></span><br><span class="line">    <span class="keyword">if</span> ((shape.<span class="built_in">GetDimNum</span>() != <span class="number">2</span>) || (shape<span class="number">2.</span><span class="built_in">GetDimNum</span>() != <span class="number">2</span>)) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input data dim error, only support 2 dims&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> ((shape.<span class="built_in">GetDim</span>(<span class="number">0</span>) != shape<span class="number">2.</span><span class="built_in">GetDim</span>(<span class="number">0</span>)) || (shape.<span class="built_in">GetDim</span>(<span class="number">1</span>) != shape<span class="number">2.</span><span class="built_in">GetDim</span>(<span class="number">1</span>))) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input data shape error.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 数据类型校验</span></span><br><span class="line">    <span class="keyword">auto</span> x1_dtype = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">auto</span> x2_dtype = context-&gt;<span class="built_in">GetInputDesc</span>(<span class="number">1</span>)-&gt;<span class="built_in">GetDataType</span>();</span><br><span class="line">    <span class="keyword">if</span> (((x1_dtype != ge::DT_FLOAT) &amp;&amp; (x2_dtype != ge::DT_FLOAT)) &amp;&amp;</span><br><span class="line">        ((x1_dtype != ge::DT_FLOAT16) &amp;&amp; (x2_dtype != ge::DT_FLOAT16))) &#123;</span><br><span class="line">        <span class="comment">// 支持 DT_FLOAT 和 DT_FLOAT16</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;input type error, only support float or float16.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ge::GRAPH_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> rowNum = shape.<span class="built_in">GetDim</span>(<span class="number">0</span>); <span class="comment">// 矩阵总行数</span></span><br><span class="line">    <span class="keyword">auto</span> colNum = shape.<span class="built_in">GetDim</span>(<span class="number">1</span>); <span class="comment">// 每行数据量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核数 自适应</span></span><br><span class="line">    <span class="keyword">auto</span> ascendcPlatform = platform_ascendc::<span class="built_in">PlatformAscendC</span>(context-&gt;<span class="built_in">GetPlatformInfo</span>());</span><br><span class="line">    <span class="keyword">auto</span> aivNum = ascendcPlatform.<span class="built_in">GetCoreNumAiv</span>();</span><br><span class="line">    <span class="type">uint32_t</span> BLOCK_DIM = std::<span class="built_in">min</span>((<span class="type">int</span>)rowNum, (<span class="type">int</span>)aivNum);</span><br><span class="line">    <span class="type">uint32_t</span> SIZE_OF_DT = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (x1_dtype == ge::DataType::DT_FLOAT) SIZE_OF_DT = <span class="number">4</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">uint64_t</span> ub_size; <span class="comment">// 192kb = 192*1024byte</span></span><br><span class="line">    ascendcPlatform.<span class="built_in">GetCoreMemSize</span>(platform_ascendc::CoreMemType::UB, ub_size);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> coreRowNum = rowNum / BLOCK_DIM; <span class="comment">// 单核 总 行数</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">float</span>* epsilonAttr = context-&gt;<span class="built_in">GetAttrs</span>()-&gt;<span class="built_in">GetAttrPointer</span>&lt;<span class="type">float</span>&gt;(<span class="number">0</span>);</span><br><span class="line">    tiling.<span class="built_in">set_eps</span>(*epsilonAttr);</span><br><span class="line">    <span class="comment">// 核间分块</span></span><br><span class="line">    tiling.<span class="built_in">set_rowNum</span>(coreRowNum);<span class="comment">// 小块 行数</span></span><br><span class="line">    tiling.<span class="built_in">set_rowNumSp</span>(coreRowNum + <span class="number">1</span>); <span class="comment">// 大块行数</span></span><br><span class="line">    tiling.<span class="built_in">set_rowLength</span>(colNum);<span class="comment">// 每行长度</span></span><br><span class="line">    tiling.<span class="built_in">set_blockPivot</span>(rowNum - coreRowNum * BLOCK_DIM);<span class="comment">// 大核数量，余数行分配到大核上</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 核内分块 自适应</span></span><br><span class="line">    <span class="comment">//uint32_t tileLoop = 18;// 每块长度，应该按照ub尺寸和每行数据量计算一次可以计算多少行</span></span><br><span class="line">    <span class="type">uint32_t</span> tileLoop = (<span class="type">uint32_t</span>)(ub_size / colNum / BUFFER_NUM / SIZE_OF_DT / <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    tiling.<span class="built_in">set_tileLoop</span>(tileLoop);<span class="comment">// 核类单次单块计算 行数</span></span><br><span class="line">    tiling.<span class="built_in">set_tileLength</span>(tileLoop * colNum);  <span class="comment">// 核类单次单块计算数据量</span></span><br><span class="line">    tiling.<span class="built_in">set_loopCount</span>(coreRowNum / tileLoop); <span class="comment">// 核内需要循环执行次数，尾块单独执行下</span></span><br><span class="line">    tiling.<span class="built_in">set_factor</span>(<span class="number">1.0f</span> / colNum);   <span class="comment">// 列数倒数</span></span><br><span class="line">    tiling.<span class="built_in">set_mfactor</span>(<span class="number">-1.0f</span> / colNum); <span class="comment">// 负 列数倒数</span></span><br><span class="line">    </span><br><span class="line">    context-&gt;<span class="built_in">SetBlockDim</span>(BLOCK_DIM);</span><br><span class="line">    tiling.<span class="built_in">SaveToBuffer</span>(context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetData</span>(),</span><br><span class="line">                        context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">GetCapacity</span>());</span><br><span class="line">    context-&gt;<span class="built_in">GetRawTilingData</span>()-&gt;<span class="built_in">SetDataSize</span>(tiling.<span class="built_in">GetDataSize</span>());</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// context-&gt;SetTilingKey(1);</span></span><br><span class="line">    <span class="comment">//printf(&quot;=========core_num: %d tile_loop:%d \n&quot;, BLOCK_DIM, tileLoop);</span></span><br><span class="line">    <span class="keyword">return</span> ge::GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;  <span class="comment">// namespace optiling</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ge &#123;</span><br><span class="line"><span class="function"><span class="type">static</span> ge::graphStatus <span class="title">InferShape</span><span class="params">(gert::InferShapeContext* context)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> gert::Shape* x1_shape = context-&gt;<span class="built_in">GetInputShape</span>(<span class="number">0</span>);</span><br><span class="line">    gert::Shape* y_shape = context-&gt;<span class="built_in">GetOutputShape</span>(<span class="number">0</span>);</span><br><span class="line">    *y_shape = *x1_shape;</span><br><span class="line">    <span class="keyword">return</span> GRAPH_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line">&#125;  <span class="comment">// namespace ge</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> ops &#123;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AddLayerNormCustom</span> : <span class="keyword">public</span> OpDef &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">AddLayerNormCustom</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* name)</span> : OpDef(name) &#123;</span></span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;gamma&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Input</span>(<span class="string">&quot;beta&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Output</span>(<span class="string">&quot;res_out&quot;</span>)</span><br><span class="line">            .<span class="built_in">ParamType</span>(REQUIRED)</span><br><span class="line">            .<span class="built_in">DataType</span>(&#123;ge::DT_FLOAT, ge::DT_FLOAT16&#125;)</span><br><span class="line">            .<span class="built_in">Format</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;)</span><br><span class="line">            .<span class="built_in">UnknownShapeFormat</span>(&#123;ge::FORMAT_ND, ge::FORMAT_ND&#125;);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">Attr</span>(<span class="string">&quot;epsilon&quot;</span>).<span class="built_in">AttrType</span>(OPTIONAL).<span class="built_in">Float</span>(<span class="number">1e-05</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">SetInferShape</span>(ge::InferShape);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">SetTiling</span>(optiling::TilingFunc);</span><br><span class="line">        <span class="keyword">this</span>-&gt;<span class="built_in">AICore</span>().<span class="built_in">AddConfig</span>(<span class="string">&quot;ascend910b&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">OP_ADD</span>(AddLayerNormCustom);</span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%A1%B9%E7%9B%AE/">项目</a><a class="post-meta__tags" href="/tags/Ascend/">Ascend</a></div><div class="post-share"><div class="social-share" data-image="/img/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="prev-post pull-left" href="/2025/06/19/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/" title="多模态智能体的睡眠分析平台"><div class="cover" style="background:var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">多模态智能体的睡眠分析平台</div></div></a><a class="next-post pull-right" href="/2025/06/07/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A52.0/" title="项目汇报2.0"><div class="cover" style="background:var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">项目汇报2.0</div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a href="/2024/10/20/AscendC%E7%AE%97%E5%AD%90/" title="AscendC算子"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-20</div><div class="title">AscendC算子</div></div></a><a href="/2024/10/21/AscendC%E7%AE%97%E5%AD%90%E4%B8%AD%E7%BA%A7%E8%AE%A4%E8%AF%81--%E6%8C%87%E5%AF%BC%E5%90%91/" title="AscendC算子中级认证--指导向"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-21</div><div class="title">AscendC算子中级认证--指导向</div></div></a><a href="/2025/06/19/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E7%9D%A1%E7%9C%A0%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%93%BE/" title="多模态智能体的睡眠分析平台"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-19</div><div class="title">多模态智能体的睡眠分析平台</div></div></a><a href="/2025/05/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A51.0/" title="项目汇报1.0"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-09</div><div class="title">项目汇报1.0</div></div></a><a href="/2025/06/28/%E9%A1%B9%E7%9B%AE%E5%91%A8%E8%AE%B0/" title="项目周记录"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-28</div><div class="title">项目周记录</div></div></a><a href="/2025/07/14/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A53.0/" title="项目汇报3.0"><div class="cover" style="background:var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-14</div><div class="title">项目汇报3.0</div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src="/img/head.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">xxxkkw</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxkkw"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">我的小站</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%98%87%E8%85%BEAI%E5%88%9B%E6%96%B0%E7%AE%97%E5%AD%90%E6%8C%91%E6%88%98%E8%B5%9BS4%E8%B5%9B%E5%AD%A3"><span class="toc-number">1.</span> <span class="toc-text">昇腾AI创新算子挑战赛S4赛季</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E4%B8%9A%E8%83%8C%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">行业背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%87%E8%85%BE%E8%AE%A1%E7%AE%97%E4%BA%A7%E4%B8%9A"><span class="toc-number">1.1.1.</span> <span class="toc-text">昇腾计算产业</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AscendC%E7%AE%97%E5%AD%90%E7%BC%96%E7%A8%8B%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.2.</span> <span class="toc-text">AscendC算子编程介绍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%9B%E9%A2%98%E5%88%97%E8%A1%A8"><span class="toc-number">1.2.</span> <span class="toc-text">赛题列表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TODO"><span class="toc-number">1.3.</span> <span class="toc-text">TODO</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Pows%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text">Pows算子实现详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">算子概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kernel%E4%BE%A7%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.</span> <span class="toc-text">kernel侧实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%8C%E6%88%90pow-cpp%E6%96%87%E4%BB%B6-%E8%BF%99%E9%87%8C%E6%98%AF%E7%AE%97%E5%AD%90%E7%9A%84%E5%85%A5%E5%8F%A3"><span class="toc-number">2.2.1.</span> <span class="toc-text">1. 完成pow.cpp文件,这里是算子的入口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%9D%9E%E5%B9%BF%E6%92%AD%E5%9C%BA%E6%99%AF%E5%AE%9E%E7%8E%B0-pow-h"><span class="toc-number">2.2.2.</span> <span class="toc-text">2. 非广播场景实现 (pow.h)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B9%BF%E6%92%AD%E5%9C%BA%E6%99%AF%E5%AE%9E%E7%8E%B0-powb-h"><span class="toc-number">2.2.3.</span> <span class="toc-text">3. 广播场景实现 (powb.h)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#host%E4%BE%A7%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.</span> <span class="toc-text">host侧实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Tiling%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9A%E4%B9%89-pows-tiling-h"><span class="toc-number">2.3.1.</span> <span class="toc-text">1. Tiling数据结构定义 (pows_tiling.h)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Tiling%E7%AD%96%E7%95%A5%E8%AE%A1%E7%AE%97-pows-cpp"><span class="toc-number">2.3.2.</span> <span class="toc-text">2. Tiling策略计算 (pows.cpp)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9"><span class="toc-number">2.4.</span> <span class="toc-text">关键技术要点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">2.5.</span> <span class="toc-text">性能优化策略</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SelectV2%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.</span> <span class="toc-text">SelectV2算子实现详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0-1"><span class="toc-number">3.1.</span> <span class="toc-text">算子概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">3.2.</span> <span class="toc-text">算法原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kernel%E4%BE%A7%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">3.3.</span> <span class="toc-text">kernel侧实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%8C%E6%88%90select-v2-cpp%E6%96%87%E4%BB%B6-%E8%BF%99%E9%87%8C%E6%98%AF%E7%AE%97%E5%AD%90%E7%9A%84%E5%85%A5%E5%8F%A3"><span class="toc-number">3.3.1.</span> <span class="toc-text">1. 完成select_v2.cpp文件,这里是算子的入口</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%9D%9E%E5%B9%BF%E6%92%AD%E5%9C%BA%E6%99%AF%E5%AE%9E%E7%8E%B0-select-v2-h"><span class="toc-number">3.3.2.</span> <span class="toc-text">2. 非广播场景实现 (select_v2.h)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B9%BF%E6%92%AD%E5%9C%BA%E6%99%AF%E5%AE%9E%E7%8E%B0-select-v2b-h"><span class="toc-number">3.3.3.</span> <span class="toc-text">3. 广播场景实现 (select_v2b.h)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#host%E4%BE%A7%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">3.4.</span> <span class="toc-text">host侧实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Tiling%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9A%E4%B9%89-select-v2-tiling-h"><span class="toc-number">3.4.1.</span> <span class="toc-text">1. Tiling数据结构定义 (select_v2_tiling.h)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Tiling%E7%AD%96%E7%95%A5%E8%AE%A1%E7%AE%97-select-v2-cpp"><span class="toc-number">3.4.2.</span> <span class="toc-text">2. Tiling策略计算 (select_v2.cpp)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9-1"><span class="toc-number">3.5.</span> <span class="toc-text">关键技术要点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9D%A1%E4%BB%B6%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6-%EF%BC%9A"><span class="toc-number">3.5.1.</span> <span class="toc-text">1.条件处理机制 ：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E9%80%82%E9%85%8D-%EF%BC%9A"><span class="toc-number">3.5.2.</span> <span class="toc-text">2.数据类型适配 ：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B9%BF%E6%92%AD%E7%B4%A2%E5%BC%95%E8%AE%A1%E7%AE%97-%EF%BC%9A"><span class="toc-number">3.5.3.</span> <span class="toc-text">3.广播索引计算 ：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%BC%98%E5%8C%96-%EF%BC%9A"><span class="toc-number">3.5.4.</span> <span class="toc-text">4.内存管理优化 ：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#AddLayerNorm%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3"><span class="toc-number">4.</span> <span class="toc-text">AddLayerNorm算子实现详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86-1"><span class="toc-number">4.1.</span> <span class="toc-text">算法原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.2.</span> <span class="toc-text">算子实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kernel%E4%BE%A7%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">4.3.</span> <span class="toc-text">kernel侧实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#host%E4%BE%A7%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">4.4.</span> <span class="toc-text">host侧实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Tiling%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9A%E4%B9%89-add-layer-norm-tiling-h"><span class="toc-number">4.4.1.</span> <span class="toc-text">1. Tiling数据结构定义 (add_layer_norm_tiling.h)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Tiling%E7%AD%96%E7%95%A5%E8%AE%A1%E7%AE%97-add-layer-norm-cpp"><span class="toc-number">4.4.2.</span> <span class="toc-text">2. Tiling策略计算 (add_layer_norm.cpp)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/18/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A56.0/" title="项目汇报6.0">项目汇报6.0</a><time datetime="2025-08-18T11:00:00.000Z" title="发表于 2025-08-18 19:00:00">2025-08-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/09/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A55.0/" title="项目汇报5.0">项目汇报5.0</a><time datetime="2025-08-09T06:00:00.000Z" title="发表于 2025-08-09 14:00:00">2025-08-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A54.0/" title="项目汇报4.0">项目汇报4.0</a><time datetime="2025-07-17T12:00:00.000Z" title="发表于 2025-07-17 20:00:00">2025-07-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/14/%E9%A1%B9%E7%9B%AE%E6%B1%87%E6%8A%A53.0/" title="项目汇报3.0">项目汇报3.0</a><time datetime="2025-07-14T05:30:00.000Z" title="发表于 2025-07-14 13:30:00">2025-07-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/28/%E9%A1%B9%E7%9B%AE%E5%91%A8%E8%AE%B0/" title="项目周记录">项目周记录</a><time datetime="2025-06-28T07:00:00.000Z" title="发表于 2025-06-28 15:00:00">2025-06-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By xxxkkw</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(()=>{const t=()=>{new Valine(Object.assign({el:"#vcomment",appId:"NuwmhVS9BmgOpiVJWroZWSWW-gzGzoHsz",appKey:"NJWb1pCdV9rcU5odlHizyxsJ",avatar:"monsterid",serverURLs:"",emojiMaps:"",path:window.location.pathname,visitor:!1},null))},e=async()=>{"function"==typeof Valine||await btf.getScript("https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"),t()};setTimeout(e,0)})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>